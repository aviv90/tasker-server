const express = require('express');
const router = express.Router();
const { sendTextMessage, sendFileByUrl, downloadFile, getChatHistory } = require('../services/greenApiService');
const { getStaticFileUrl } = require('../utils/urlUtils');
const { generateTextResponse: generateOpenAIResponse, generateImageForWhatsApp: generateOpenAIImage, editImageForWhatsApp: editOpenAIImage } = require('../services/openaiService');
const { generateTextResponse: generateGeminiResponse, generateImageForWhatsApp, editImageForWhatsApp, generateVideoForWhatsApp, generateVideoFromImageForWhatsApp, generateChatSummary } = require('../services/geminiService');
const { generateTextResponse: generateGrokResponse } = require('../services/grokService');
const { generateVideoFromImageForWhatsApp: generateKlingVideoFromImage, generateVideoFromVideoForWhatsApp: generateRunwayVideoFromVideo, generateVideoWithTextForWhatsApp: generateKlingVideoFromText } = require('../services/replicateService');
const { generateMusicWithLyrics } = require('../services/musicService');
const speechService = require('../services/speechService');
const { voiceService } = require('../services/voiceService');
const { audioConverterService } = require('../services/audioConverterService');
const { creativeAudioService } = require('../services/creativeAudioService');
const conversationManager = require('../services/conversationManager');
const { routeIntent } = require('../services/intentRouter');
const authStore = require('../store/authStore');
const fs = require('fs');
const path = require('path');

// Message deduplication cache - prevent processing duplicate messages
const processedMessages = new Set();

// Voice transcription and media authorization are managed through PostgreSQL database

/**
 * Check if user is authorized for media creation (images, videos, music)
 * @param {Object} senderData - WhatsApp sender data from Green API
 * @returns {Promise<boolean>} - True if user is authorized
 */
async function isAuthorizedForMediaCreation(senderData) {
  return await authStore.isAuthorizedForMediaCreation(senderData);
}

/**
 * Check if command requires media creation authorization
 * @param {string} commandType - Command type
 * @returns {boolean} - True if command requires authorization
 */
function requiresMediaAuthorization(commandType) {
  const mediaCommands = [
    'gemini_image',
    'openai_image',
    'grok_image', 
    'veo3_video',
    'kling_text_to_video',
    'kling_image_to_video',
    'veo3_image_to_video',
    'runway_video_to_video',
    'music_generation',
    'text_to_speech',
    'gemini_image_edit',
    'openai_image_edit'
  ];
  return mediaCommands.includes(commandType);
}

/**
 * Check if a command is an admin/management command (should only work from outgoing messages)
 * @param {string} commandType - Command type
 * @returns {boolean} - True if command is admin-only
 */
function isAdminCommand(commandType) {
  const adminCommands = [
    'include_in_transcription',
    'exclude_from_transcription',
    'add_media_authorization',
    'remove_media_authorization',
    'voice_transcription_status',
    'clear_all_conversations',
    // New admin shortcuts without explicit name
    'add_media_authorization_current',
    'include_in_transcription_current'
  ];
  return adminCommands.includes(commandType);
}

/**
 * Send unauthorized access message
 * @param {string} chatId - WhatsApp chat ID
 * @param {string} feature - Feature name (for logging)
 */
async function sendUnauthorizedMessage(chatId, feature) {
  const message = 'ğŸ”’ ×¡×œ×™×—×”, ××™×Ÿ ×œ×š ×”×¨×©××” ×œ×”×©×ª××© ×‘×ª×›×•× ×” ×–×•. ×¤× ×” ×œ×× ×”×œ ×”××¢×¨×›×ª.';
  await sendTextMessage(chatId, message);
  console.log(`ğŸš« Unauthorized access attempt to ${feature}`);
}

// Clean up old processed messages every 30 minutes
setInterval(() => {
  if (processedMessages.size > 1000) {
    processedMessages.clear();
    console.log('ğŸ§¹ Cleared processed messages cache');
  }
}, 30 * 60 * 1000);

/**
 * Send immediate acknowledgment for long-running commands
 */
async function sendAck(chatId, command) {
  let ackMessage = '';
  
  switch (command.type) {
    case 'gemini_image':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™. ××™×“ ××¢×‘×“ ×¢× Gemini...';
      break;
    case 'openai_image':
      ackMessage = 'ğŸ–¼ï¸ ×§×™×‘×œ×ª×™. ××™×“ ××¢×‘×“ ×¢× OpenAI...';
      break;
    case 'veo3_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...';
      break;
    case 'veo3_image_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...';
      break;
    case 'kling_image_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Kling 2.1...';
      break;
    case 'voice_processing':
      ackMessage = 'ğŸ¤ ×§×™×‘×œ×ª×™ ××ª ×”×”×§×œ×˜×”. ××ª×—×™×œ ×¢×™×‘×•×“ ×§×•×œ×™ ×¢× ElevenLabs + Gemini...';
      break;
    case 'runway_video_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×•×•×™×“××•. ××™×“ ×¢×•×‘×“ ×¢×œ×™×• ×¢× RunwayML Gen4...';
      break;
    case 'kling_text_to_video':
      ackMessage = 'ğŸ¬ ××ª×—×™×œ ×™×¦×™×¨×ª ×•×™×“××• ×¢× Kling 2.1 Master...';
      break;
    case 'chat_summary':
      ackMessage = 'ğŸ“ ××›×™×Ÿ ×¡×™×›×•× ×©×œ ×”×©×™×—×” ×¢× Gemini...';
      break;
    case 'voice_generation':
      ackMessage = 'ğŸ¤ ×§×™×‘×œ×ª×™. ××™×“ ×™×•×¦×¨ ×§×•×œ ×¢× ElevenLabs...';
      break;
    case 'music_generation':
      ackMessage = 'ğŸµ ×§×™×‘×œ×ª×™. ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× Suno...';
      break;
    case 'text_to_speech':
      ackMessage = 'ğŸ—£ï¸ ×§×™×‘×œ×ª×™. ××™×“ ×™×•×¦×¨ ×“×™×‘×•×¨ ×¢× ElevenLabs...';
      break;
    case 'grok_image':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™. ××™×“ ×™×•×¦×¨ ×ª××•× ×” ×¢× Grok...';
      break;
    case 'creative_voice_processing':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™ ××ª ×”×”×§×œ×˜×”. ××ª×—×™×œ ×¢×™×‘×•×“ ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™× ×•××•×–×™×§×”...';
      break;
    default:
      return; // No ACK needed for this command
  }
  
  try {
    await sendTextMessage(chatId, ackMessage);
    console.log(`âœ… ACK sent for ${command.type}`);
  } catch (error) {
    console.error('âŒ Error sending ACK:', error.message || error);
  }
}

/**
 * WhatsApp Green API Integration Routes
 * 
 * ğŸš¨ BACKWARD COMPATIBILITY RULE:
 * Any new WhatsApp functionality MUST maintain backward compatibility
 * with Tasker Android polling system (/api/start-task + /api/task-status).
 */

/**
 * Webhook endpoint for receiving WhatsApp messages from Green API
 */
router.post('/webhook', async (req, res) => {
  try {
    // Security check: Verify webhook token
    const token = req.headers['authorization']?.replace('Bearer ', '') ||
                  req.query.token || 
                  req.body.token;
    
    const expectedToken = process.env.GREEN_API_WEBHOOK_TOKEN;
    
    if (!expectedToken) {
      console.error('âŒ GREEN_API_WEBHOOK_TOKEN not configured in environment');
      return res.status(500).json({ error: 'Webhook token not configured' });
    }
    
    if (token !== expectedToken) {
      console.error('âŒ Unauthorized webhook request - invalid token');
      return res.status(401).json({ error: 'Unauthorized' });
    }

    const webhookData = req.body;
    // Log full webhook payload (all fields)
    try {
      console.log('ğŸ“± Green API webhook received (full payload):');
      console.log(`ğŸ“± Webhook received: ${webhookData.typeMessage || 'unknown'}`);
    } catch (e) {
      console.log('ğŸ“± Green API webhook received (payload logging failed), raw object follows:');
      console.log(webhookData);
    }

    // Handle different webhook types asynchronously
    if (webhookData.typeWebhook === 'incomingMessageReceived') {
      // Process in background - don't await
      handleIncomingMessage(webhookData).catch(error => {
        console.error('âŒ Error in async webhook processing:', error.message || error);
      });
    } else if (webhookData.typeWebhook === 'outgoingMessageReceived') {
      // Process outgoing messages (commands sent by you)
      handleOutgoingMessage(webhookData).catch(error => {
        console.error('âŒ Error in async outgoing message processing:', error.message || error);
      });
    }

    // Return 200 OK immediately
    res.status(200).json({ status: 'ok' });
  } catch (error) {
    console.error('âŒ Error processing webhook:', error.message || error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

/**
 * Handle incoming WhatsApp message
 */
async function handleIncomingMessage(webhookData) {
  try {
    const messageData = webhookData.messageData;
    const senderData = webhookData.senderData;
    
    // Extract message ID for deduplication
    const messageId = webhookData.idMessage;
    
    // Check if we already processed this message
    if (processedMessages.has(messageId)) {
      console.log(`ğŸ”„ Duplicate message detected, skipping: ${messageId}`);
      return;
    }
    
    // Mark message as processed
    processedMessages.add(messageId);
    
    const chatId = senderData.chatId;
    const senderId = senderData.sender;
    const senderName = senderData.senderName || senderId;
    const senderContactName = senderData.senderContactName || "";
    const chatName = senderData.chatName || "";
    
    console.log(`ğŸ“± ${senderName}: ${messageData.typeMessage}`);
    
    // Handle text messages (both regular and extended)
    let messageText = null;
    
    if (messageData.typeMessage === 'textMessage') {
      messageText = messageData.textMessageData?.textMessage;
    } else if (messageData.typeMessage === 'extendedTextMessage') {
      messageText = messageData.extendedTextMessageData?.text;
    }
    
    // Unified intent router for commands that start with "# "
    if (messageText && /^#\s+/.test(messageText.trim())) {
      try {
        const normalized = {
          userText: messageText.trim(),
          hasImage: messageData.typeMessage === 'imageMessage',
          hasVideo: messageData.typeMessage === 'videoMessage',
          hasAudio: messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage',
          chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
          language: 'he',
          authorizations: {
            media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
            voice_allowed: await conversationManager.isInVoiceAllowList((() => {
              const isGroupChat = chatId && chatId.endsWith('@g.us');
              const isPrivateChat = chatId && chatId.endsWith('@c.us');
              if (isGroupChat) return chatName || senderName;
              if (isPrivateChat) return (senderContactName && senderContactName.trim()) ? senderContactName : (chatName && chatName.trim()) ? chatName : senderName;
              return senderContactName || chatName || senderName;
            })())
          }
        };

        const decision = await routeIntent(normalized);

        // Map router output to existing flow for backward compatibility
        const prompt = normalized.userText.replace(/^#\s+/, '').trim();
        switch (decision.tool) {
          case 'ask_clarification':
            await sendTextMessage(chatId, 'â„¹ï¸ ×œ× ×‘×¨×•×¨ ××” ×œ×‘×¦×¢. ×ª×•×›×œ ×œ×—×“×“ ×‘×‘×§×©×”?');
            return;
          case 'deny_unauthorized':
            // ×©××™×¨×” ×¢×œ ×”×ª× ×”×’×•×ª ×“×™×¡×§×¨×˜×™×ª: ×‘××“×™×” × ×—×–×™×¨ ×”×•×“×¢×ª ×”×¨×©××”; ×‘×§×•×œ ×›×‘×¨ ×©×™× ×™× ×• ×œ×©×§×˜
            if (decision.args?.feature && decision.args.feature !== 'voice') {
              await sendUnauthorizedMessage(chatId, decision.args.feature);
            }
            return;
          case 'gemini_chat':
          case 'openai_chat':
          case 'grok_chat':
            processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: prompt });
            return;
          case 'gemini_image':
          case 'openai_image':
          case 'grok_image': {
            // ×©×™××•×© ×‘×¤×§×•×“×•×ª ×˜×§×¡×˜ ×§×™×™××•×ª, ×”××™×¤×•×™ ×™×§×¨×” ×‘×ª×•×š handleTextMessage
            processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'gemini_image' ? '** ' : decision.tool === 'openai_image' ? '## ' : '++ ') + prompt });
            return;
          }
          case 'veo3_video':
          case 'kling_text_to_video': {
            processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'veo3_video' ? '#### ' : '### ') + prompt });
            return;
          }
          case 'image_edit': {
            // ×›×“×™ ×œ×”×™×©××¨ ×ª××™××™× ×œ××—×•×¨, × ×©×ª××© ×‘×§×™×“×•××•×ª ×”×¢×¨×™×›×” ×¢×œ ×ª××•× ×” ××¦×•×¨×¤×ª
            if (messageData.typeMessage === 'imageMessage') {
              const prefix = decision.args?.service === 'gemini' ? '* ' : '# ';
              const imageData = messageData.fileMessageData || messageData.imageMessageData;
              // ××™×—×–×•×¨ ×”×œ×•×’×™×§×” ×”×§×™×™××ª: ×”×•×¡×¤×ª ×›×™×ª×•×‘ ××œ××›×•×ª×™ ×•×”××©×š ×‘× ×ª×™×‘ ×”×¨×’×™×œ
              imageData.caption = prefix + decision.args.prompt;
              messageData.imageMessageData = imageData;
              // × ×¤×œ ×“×¨×š ×œ×‘×œ×•×§ ×”×§×™×™× ×©×œ ×ª××•× ×•×ª ×‘×¢×™×‘×•×“ ×‘×”××©×š
            }
            break; // × ××©×™×š ×œ×¢×™×‘×•×“ ×”×ª××•× ×•×ª ×”×§×™×™× ×‘×”××©×š ×”×¤×•× ×§×¦×™×”
          }
          case 'video_to_video': {
            if (messageData.typeMessage === 'videoMessage') {
              const videoData = messageData.fileMessageData || messageData.videoMessageData;
              videoData.caption = '## ' + decision.args.prompt;
              messageData.videoMessageData = videoData;
            }
            break; // × ××©×™×š ×œ×¢×™×‘×•×“ ×”×•×•×™×“××• ×”×§×™×™×
          }
          case 'text_to_speech':
            processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '*** ' + (decision.args?.text || prompt) });
            return;
          case 'chat_summary':
            processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '×¡×›× ×©×™×—×”' });
            return;
          case 'creative_voice_processing':
            // ×× ×–×• ×”×•×“×¢×” ×§×•×œ×™×ª, ×”×‘×œ×•×§ ×©×œ ×”×§×•×œ ×‘×”××©×š ×›×‘×¨ ×™×˜×¤×œ
            break;
          default:
            // ×œ× ××–×•×”×” â€“ × ×©××•×¨ ×¢×œ ××¡×œ×•×œ ×™×©×Ÿ
            break;
        }
      } catch (routerError) {
        console.error('âŒ Intent router error:', routerError.message || routerError);
        // ×‘×©×’×™××”, × ××©×™×š ×œ× ×ª×™×‘ ×”×™×©×Ÿ
      }
    }

    // Handle image messages for image-to-image editing
    if (messageData.typeMessage === 'imageMessage') {
      const imageData = messageData.fileMessageData || messageData.imageMessageData;
      const caption = imageData?.caption || '';
      
      console.log(`ğŸ–¼ï¸ Image message received with caption: "${caption}"`);

      // Intent router for image captions starting with "# "
      if (/^#\s+/.test(caption.trim())) {
        try {
          const normalized = {
            userText: caption.trim(),
            hasImage: true,
            hasVideo: false,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: {
              media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
              voice_allowed: false
            }
          };

          const decision = await routeIntent(normalized);
          const routedPrompt = normalized.userText.replace(/^#\s+/, '').trim();

          switch (decision.tool) {
            case 'deny_unauthorized':
              await sendUnauthorizedMessage(chatId, decision.args?.feature || 'media');
              return;
            case 'gemini_image':
            case 'openai_image':
            case 'grok_image':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'gemini_image' ? '** ' : decision.tool === 'openai_image' ? '## ' : '++ ') + routedPrompt });
              return;
            case 'veo3_video':
            case 'kling_text_to_video':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'veo3_video' ? '#### ' : '### ') + routedPrompt });
              return;
            case 'image_edit': {
              const prefix = decision.args?.service === 'gemini' ? '* ' : '# ';
              imageData.caption = prefix + decision.args.prompt;
              messageData.imageMessageData = imageData;
              // Fall through to legacy handlers below
              break;
            }
            case 'video_to_video':
              // For image message this doesn't apply; ask clarification
              await sendTextMessage(chatId, 'â„¹ï¸ × ×©×œ×—×” ×ª××•× ×”, ×œ× ×•×™×“××•. ×ª×¨×¦×” ×œ×¢×¨×•×š ××ª ×”×ª××•× ×” ××• ×œ×™×¦×•×¨ ×ª××•× ×”/×•×™×“××• ×—×“×©?');
              return;
            case 'text_to_speech':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '*** ' + (decision.args?.text || routedPrompt) });
              return;
            case 'chat_summary':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '×¡×›× ×©×™×—×”' });
              return;
            case 'gemini_chat':
            case 'openai_chat':
            case 'grok_chat':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: routedPrompt });
              return;
            case 'ask_clarification':
            default:
              await sendTextMessage(chatId, 'â„¹ï¸ ×œ× ×‘×¨×•×¨ ××” ×œ×‘×¦×¢ ×¢× ×”×ª××•× ×”. ×ª×•×›×œ ×œ×—×“×“ ×‘×‘×§×©×”?');
              return;
          }
        } catch (routerError) {
          console.error('âŒ Intent router (image caption) error:', routerError.message || routerError);
          // Continue to legacy handling below
        }
      }
      
      // Check if caption starts with "### " for Veo 3 image-to-video
      if (caption.startsWith('### ')) {
        const prompt = caption.substring(4).trim(); // Remove "### "
        console.log(`ğŸ¬ Veo 3 image-to-video request with prompt: "${prompt}"`);
        
        // Check authorization for media creation
        if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }))) {
          await sendUnauthorizedMessage(chatId, 'video creation');
          return;
        }
        
        // Process Veo 3 image-to-video asynchronously
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'veo3'
        });
      }
      // Check if caption starts with "## " for Kling image-to-video
      else if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`ğŸ¬ Kling 2.1 image-to-video request with prompt: "${prompt}"`);
        
        // Check authorization for media creation
        if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }))) {
          await sendUnauthorizedMessage(chatId, 'video creation');
          return;
        }
        
        // Process Kling image-to-video asynchronously
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'kling'
        });
      }
      // Check if caption starts with "*" for Gemini image editing
      else if (caption.startsWith('* ')) {
        const prompt = caption.substring(2).trim(); // Remove "* "
        console.log(`ğŸ¨ Gemini image edit request with prompt: "${prompt}"`);
        
        // Check authorization for media creation
        if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }))) {
          await sendUnauthorizedMessage(chatId, 'image editing');
          return;
        }
        
        // Process Gemini image editing asynchronously
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'gemini'
        });
      } 
      // Check if caption starts with "#" for OpenAI image editing
      else if (caption.startsWith('# ')) {
        const prompt = caption.substring(2).trim(); // Remove "# "
        console.log(`ğŸ–¼ï¸ OpenAI image edit request with prompt: "${prompt}"`);
        
        // Check authorization for media creation
        if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }))) {
          await sendUnauthorizedMessage(chatId, 'image editing');
          return;
        }
        
        // Process OpenAI image editing asynchronously
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'openai'
        });
      } else {
        console.log(`â„¹ï¸ Image received but no command (use "### " for Veo 3 video, "## " for Kling video, "* " for Gemini edit, or "# " for OpenAI edit)`);
      }
    }
    // Handle video messages for video-to-video processing
    else if (messageData.typeMessage === 'videoMessage') {
      const videoData = messageData.fileMessageData || messageData.videoMessageData;
      const caption = videoData?.caption || '';
      
      console.log(`ğŸ¬ Video message received with caption: "${caption}"`);

      // Intent router for video captions starting with "# "
      if (/^#\s+/.test(caption.trim())) {
        try {
          const normalized = {
            userText: caption.trim(),
            hasImage: false,
            hasVideo: true,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: {
              media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
              voice_allowed: false
            }
          };

          const decision = await routeIntent(normalized);
          const routedPrompt = normalized.userText.replace(/^#\s+/, '').trim();

          switch (decision.tool) {
            case 'deny_unauthorized':
              await sendUnauthorizedMessage(chatId, decision.args?.feature || 'media');
              return;
            case 'video_to_video':
              // Rewrite caption to legacy prefix and fall through to legacy handlers
              videoData.caption = '## ' + routedPrompt;
              messageData.videoMessageData = videoData;
              break;
            case 'veo3_video':
            case 'kling_text_to_video':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'veo3_video' ? '#### ' : '### ') + routedPrompt });
              return;
            case 'image_edit':
              await sendTextMessage(chatId, 'â„¹ï¸ × ×©×œ×— ×•×™×“××•, ×œ× ×ª××•× ×”. ×ª×¨×¦×” ×œ×‘×¦×¢ ×¢×™×‘×•×“ ×•×™×“××•?');
              return;
            case 'gemini_image':
            case 'openai_image':
            case 'grok_image':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: (decision.tool === 'gemini_image' ? '** ' : decision.tool === 'openai_image' ? '## ' : '++ ') + routedPrompt });
              return;
            case 'text_to_speech':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '*** ' + (decision.args?.text || routedPrompt) });
              return;
            case 'chat_summary':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: '×¡×›× ×©×™×—×”' });
              return;
            case 'gemini_chat':
            case 'openai_chat':
            case 'grok_chat':
              processTextMessageAsync({ chatId, senderId, senderName, senderContactName, chatName, messageText: routedPrompt });
              return;
            case 'ask_clarification':
            default:
              await sendTextMessage(chatId, 'â„¹ï¸ ×œ× ×‘×¨×•×¨ ××” ×œ×‘×¦×¢ ×¢× ×”×•×•×™×“××•. ×ª×•×›×œ ×œ×—×“×“ ×‘×‘×§×©×”?');
              return;
          }
        } catch (routerError) {
          console.error('âŒ Intent router (video caption) error:', routerError.message || routerError);
          // Continue to legacy handling below
        }
      }
      
      // Check if caption starts with "## " for RunwayML Gen4 video-to-video
      if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`ğŸ¬ RunwayML Gen4 video-to-video request with prompt: "${prompt}"`);
        
        // Check authorization for media creation
        if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }))) {
          await sendUnauthorizedMessage(chatId, 'video editing');
          return;
        }
        
        // Process RunwayML video-to-video asynchronously
        processVideoToVideoAsync({
          chatId,
          senderId,
          senderName,
          videoUrl: videoData.downloadUrl,
          prompt: prompt
        });
      } else {
        console.log(`â„¹ï¸ Video received but no command (use "## " for RunwayML Gen4 video-to-video)`);
      }
    }
    // Handle voice messages for creative audio processing
    else if (messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage') {
      const audioData = messageData.fileMessageData || messageData.audioMessageData;
      
      console.log(`ğŸ¤ Voice message received`);
      
      // Priority logic based on chat type:
      // Group chat (@g.us): only check chatName
      // Private chat (@c.us): check senderContactName first, then chatName, then senderName as fallback
      let contactName = "";
      const isGroupChat = chatId && chatId.endsWith('@g.us');
      const isPrivateChat = chatId && chatId.endsWith('@c.us');
      
      if (isGroupChat) {
        // Group chat - only use chatName
        contactName = chatName || senderName;
      } else if (isPrivateChat) {
        // Private chat - priority: senderContactName â†’ chatName â†’ senderName
        if (senderContactName && senderContactName.trim()) {
          contactName = senderContactName;
        } else if (chatName && chatName.trim()) {
          contactName = chatName;
        } else {
          contactName = senderName;
        }
      } else {
        // Fallback for unknown chat types
        contactName = senderContactName || chatName || senderName;
      }
      
      const chatType = isGroupChat ? 'group' : isPrivateChat ? 'private' : 'unknown';
      console.log(`ğŸ” Checking voice transcription for: "${contactName}" (chatType: ${chatType}, chatId: "${chatId}", senderContactName: "${senderContactName}", chatName: "${chatName}", senderName: "${senderName}")`);
      
      try {
        // Check if sender is in allow list (new logic: must be in allow list to process, like media creation)
        const isInAllowList = await conversationManager.isInVoiceAllowList(contactName);
        if (!isInAllowList) {
        console.log(`ğŸš« Creative voice processing not allowed for ${contactName} (not in allow list)`);
        // Silently ignore unauthorized voice messages (no reply)
        return;
        }
        
        console.log(`âœ… Creative voice processing allowed for ${contactName} - proceeding with processing`);
      } catch (dbError) {
        console.error('âŒ Error checking voice transcription settings:', dbError);
        console.log(`ğŸ”‡ Skipping creative voice processing due to database error`);
        return;
      }
      
      // Process creative voice asynchronously
      processCreativeVoiceAsync({
        chatId,
        senderId,
        senderName,
        audioUrl: audioData.downloadUrl
      });
    } else if (messageText) {
      // Process text message asynchronously - don't await
      processTextMessageAsync({
        chatId,
        senderId,
        senderName,
        senderContactName,
        chatName,
        messageText: messageText.trim()
      });
    } else {
      console.log(`â„¹ï¸ Unsupported message type: ${messageData.typeMessage}`);
    }
  } catch (error) {
    console.error('âŒ Error handling incoming message:', error.message || error);
  }
}

/**
 * Handle outgoing WhatsApp message (commands sent by you)
 */
async function handleOutgoingMessage(webhookData) {
  try {
    const messageData = webhookData.messageData;
    const senderData = webhookData.senderData;
    
    // Extract message ID for deduplication
    const messageId = webhookData.idMessage;
    
    // Check if we already processed this message
    if (processedMessages.has(messageId)) {
      console.log(`ğŸ”„ Duplicate outgoing message detected, skipping: ${messageId}`);
      return;
    }
    
    // Mark message as processed
    processedMessages.add(messageId);
    
    const chatId = senderData.chatId;
    const senderId = senderData.sender;
    const senderName = senderData.senderName || senderId;
    const senderContactName = senderData.senderContactName || "";
    const chatName = senderData.chatName || "";
    
    console.log(`ğŸ“¤ ${senderName}: ${messageData.typeMessage}`);
    
    // Handle text messages (both regular and extended)
    let messageText = null;
    
    if (messageData.typeMessage === 'textMessage') {
      messageText = messageData.textMessageData?.textMessage;
    } else if (messageData.typeMessage === 'extendedTextMessage') {
      messageText = messageData.extendedTextMessageData?.text;
    }
    
    // Handle image messages for image-to-image editing
    if (messageData.typeMessage === 'imageMessage') {
      const imageData = messageData.fileMessageData || messageData.imageMessageData;
      const caption = imageData?.caption || '';
      
      console.log(`ğŸ–¼ï¸ Outgoing image message received with caption: "${caption}"`);
      
      // Check if caption starts with "### " for Veo 3 image-to-video
      if (caption.startsWith('### ')) {
        const prompt = caption.substring(4).trim(); // Remove "### "
        console.log(`ğŸ¬ Outgoing Veo 3 image-to-video request with prompt: "${prompt}" (bypassing authorization)`);
        
        // Process Veo 3 image-to-video asynchronously (no authorization check for outgoing messages)
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'veo3'
        });
      }
      // Check if caption starts with "## " for Kling image-to-video
      else if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`ğŸ¬ Outgoing Kling 2.1 image-to-video request with prompt: "${prompt}" (bypassing authorization)`);
        
        // Process Kling image-to-video asynchronously (no authorization check for outgoing messages)
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'kling'
        });
      }
      // Check if caption starts with "*" for Gemini image editing
      else if (caption.startsWith('* ')) {
        const prompt = caption.substring(2).trim(); // Remove "* "
        console.log(`ğŸ¨ Outgoing Gemini image edit request with prompt: "${prompt}" (bypassing authorization)`);
        
        // Process Gemini image editing asynchronously (no authorization check for outgoing messages)
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'gemini'
        });
      } 
      // Check if caption starts with "#" for OpenAI image editing
      else if (caption.startsWith('# ')) {
        const prompt = caption.substring(2).trim(); // Remove "# "
        console.log(`ğŸ–¼ï¸ Outgoing OpenAI image edit request with prompt: "${prompt}" (bypassing authorization)`);
        
        // Process OpenAI image editing asynchronously (no authorization check for outgoing messages)
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'openai'
        });
      } else {
        console.log(`â„¹ï¸ Outgoing image received but no command (use "### " for Veo 3 video, "## " for Kling video, "* " for Gemini edit, or "# " for OpenAI edit)`);
      }
    }
    // Handle video messages for video-to-video processing
    else if (messageData.typeMessage === 'videoMessage') {
      const videoData = messageData.fileMessageData || messageData.videoMessageData;
      const caption = videoData?.caption || '';
      
      console.log(`ğŸ¬ Outgoing video message received with caption: "${caption}"`);
      
      // Check if caption starts with "## " for RunwayML Gen4 video-to-video
      if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`ğŸ¬ Outgoing RunwayML Gen4 video-to-video request with prompt: "${prompt}" (bypassing authorization)`);
        
        // Process RunwayML video-to-video asynchronously (no authorization check for outgoing messages)
        processVideoToVideoAsync({
          chatId,
          senderId,
          senderName,
          videoUrl: videoData.downloadUrl,
          prompt: prompt
        });
      } else {
        console.log(`â„¹ï¸ Outgoing video received but no command (use "## " for RunwayML Gen4 video-to-video)`);
      }
    }
    // Handle voice messages - but skip processing for outgoing messages
    else if (messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage') {
      const audioData = messageData.fileMessageData || messageData.audioMessageData;
      
      console.log(`ğŸ¤ Outgoing voice message received - skipping voice processing (only process incoming voice messages)`);
      // Don't process outgoing voice messages to avoid unwanted transcription
    } else if (messageText) {
      // Handle admin shortcut commands that use current contact (no explicit name)
      const trimmed = messageText.trim();
      if (trimmed === '×”×•×¡×£ ×œ×™×¦×™×¨×”') {
        // Resolve current contact name using same priority logic as auth store
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for add to media authorization');
        } else {
          const wasAdded = await authStore.addAuthorizedUser(contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Added ${contactName} to media creation authorization (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×•×¡×£ ×œ×ª××œ×•×œ') {
        // Resolve current contact name as above
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for add to transcription');
        } else {
          const wasAdded = await conversationManager.addToVoiceAllowList(contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Added ${contactName} to voice allow list (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×¡×¨ ××™×¦×™×¨×”') {
        // Resolve current contact name
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for remove from media authorization');
        } else {
          const wasRemoved = await authStore.removeAuthorizedUser(contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Removed ${contactName} from media creation authorization (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×¡×¨ ××ª××œ×•×œ') {
        // Resolve current contact name
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for remove from transcription');
        } else {
          const wasRemoved = await conversationManager.removeFromVoiceAllowList(contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Removed ${contactName} from voice allow list (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        }
        return; // Stop further processing for this message
      }

      // Process text message asynchronously - don't await
      processTextMessageAsync({
        chatId,
        senderId,
        senderName,
        senderContactName,
        chatName,
        messageText: messageText.trim()
      }, true); // isOutgoing = true
    } else {
      console.log(`â„¹ï¸ Unsupported outgoing message type: ${messageData.typeMessage}`);
    }
  } catch (error) {
    console.error('âŒ Error handling outgoing message:', error.message || error);
  }
}

/**
 * Process text message asynchronously (no await from webhook)
 */
function processTextMessageAsync(messageData, isOutgoing = false) {
  // Run in background without blocking webhook response
  handleTextMessage(messageData, isOutgoing).catch(error => {
    console.error('âŒ Error in async message processing:', error.message || error);
  });
}

/**
 * Process image edit message asynchronously (no await from webhook)
 */
function processImageEditAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageEdit(imageData).catch(error => {
    console.error('âŒ Error in async image edit processing:', error.message || error);
  });
}

/**
 * Process image-to-video message asynchronously (no await from webhook)
 */
function processImageToVideoAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageToVideo(imageData).catch(error => {
    console.error('âŒ Error in async image-to-video processing:', error.message || error);
  });
}

/**
 * Process creative voice message asynchronously (no await from webhook)
 */
function processCreativeVoiceAsync(voiceData) {
  // Run in background without blocking webhook response
  handleCreativeVoiceMessage(voiceData).catch(error => {
    console.error('âŒ Error in async creative voice processing:', error.message || error);
  });
}

/**
 * Process voice message asynchronously (no await from webhook) - COMMENTED OUT FOR CREATIVE PROCESSING
 */
/*
function processVoiceMessageAsync(voiceData) {
  // Run in background without blocking webhook response
  handleVoiceMessage(voiceData).catch(error => {
    console.error('âŒ Error in async voice processing:', error.message || error);
  });
}
*/

/**
 * Process video-to-video message asynchronously (no await from webhook)
 */
function processVideoToVideoAsync(videoData) {
  // Run in background without blocking webhook response
  handleVideoToVideo(videoData).catch(error => {
    console.error('âŒ Error in async video-to-video processing:', error.message || error);
  });
}

/**
 * Handle image edit with AI (Gemini or OpenAI)
 */
async function handleImageEdit({ chatId, senderId, senderName, imageUrl, prompt, service }) {
  console.log(`ğŸ¨ Processing ${service} image edit request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    const ackMessage = service === 'gemini' 
      ? 'ğŸ¨ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ××¢×‘×“ ××•×ª×” ×¢× Gemini...'
      : 'ğŸ–¼ï¸ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ××¢×‘×“ ××•×ª×” ×¢× OpenAI...';
    await sendTextMessage(chatId, ackMessage);
    
    // Note: Image editing commands do NOT add to conversation history
    
    // Download the image first
    const imageBuffer = await downloadFile(imageUrl);
    const base64Image = imageBuffer.toString('base64');
    
    // Edit image with selected AI service
    let editResult;
    if (service === 'gemini') {
      editResult = await editImageForWhatsApp(prompt, base64Image);
    } else if (service === 'openai') {
      editResult = await editOpenAIImage(prompt, base64Image);
    }
    
    if (editResult.success) {
      let sentSomething = false;
      
      // Send text response if available
      if (editResult.description && editResult.description.trim()) {
        await sendTextMessage(chatId, editResult.description);
        
        // Note: Image editing results do NOT add to conversation history
        
        console.log(`âœ… ${service} edit text response sent to ${senderName}: ${editResult.description}`);
        sentSomething = true;
      }
      
      // Send image if available (even if we already sent text)
      if (editResult.imageUrl) {
        const fileName = `${service}_edit_${Date.now()}.png`;
        
        await sendFileByUrl(chatId, editResult.imageUrl, fileName, '');
        
        console.log(`âœ… ${service} edited image sent to ${senderName}`);
        sentSomething = true;
      }
      
      // If nothing was sent, it means we have success but no content
      if (!sentSomething) {
        await sendTextMessage(chatId, 'âœ… ×”×¢×™×‘×•×“ ×”×•×©×œ× ×‘×”×¦×œ×—×”');
        console.log(`âœ… ${service} edit completed but no content to send to ${senderName}`);
      }
    } else {
      const errorMsg = editResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×¨×•×š ××ª ×”×ª××•× ×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ ${service} image edit failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`âŒ Error in ${service} image editing:`, error.message || error);
    await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×¢×¨×™×›×ª ×”×ª××•× ×”.');
  }
}

/**
 * Handle image-to-video with Veo 3 or Kling
 */
async function handleImageToVideo({ chatId, senderId, senderName, imageUrl, prompt, service = 'veo3' }) {
  const serviceName = service === 'veo3' ? 'Veo 3' : 'Kling 2.1 Master';
  console.log(`ğŸ¬ Processing ${serviceName} image-to-video request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    const ackMessage = service === 'veo3' 
      ? 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...'
      : 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Kling 2.1...';
    await sendTextMessage(chatId, ackMessage);
    
    // Note: Image-to-video commands do NOT add to conversation history
    
    // Download the image first
    const imageBuffer = await downloadFile(imageUrl);
    
    // Generate video with selected service
    let videoResult;
    if (service === 'veo3') {
      videoResult = await generateVideoFromImageForWhatsApp(prompt, imageBuffer);
    } else {
      videoResult = await generateKlingVideoFromImage(imageBuffer, prompt);
    }
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `${service}_image_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Add AI response to conversation history
      await conversationManager.addMessage(chatId, 'assistant', `×•×™×“××• × ×•×¦×¨ ××ª××•× ×” (${serviceName}): ${videoResult.description || '×•×™×“××• ×—×“×©'}`);
      
      console.log(`âœ… ${serviceName} image-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || `×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××• ××”×ª××•× ×” ×¢× ${serviceName}. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.`;
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ ${serviceName} image-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`âŒ Error in ${serviceName} image-to-video:`, error.message || error);
    await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×•×™×“××• ××”×ª××•× ×” ×¢× ${serviceName}.`);
  }
}

/**
 * Handle video-to-video with RunwayML Gen4
 */
async function handleVideoToVideo({ chatId, senderId, senderName, videoUrl, prompt }) {
  console.log(`ğŸ¬ Processing RunwayML Gen4 video-to-video request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'runway_video_to_video' });
    
    // Note: Video-to-video commands do NOT add to conversation history
    
    // Download the video first
    const videoBuffer = await downloadFile(videoUrl);
    
    // Generate video with RunwayML Gen4
    const videoResult = await generateRunwayVideoFromVideo(videoBuffer, prompt);
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `runway_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Note: Video-to-video results do NOT add to conversation history
      
      console.log(`âœ… RunwayML Gen4 video-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×‘×“ ××ª ×”×•×•×™×“××•. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ RunwayML Gen4 video-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error('âŒ Error in RunwayML Gen4 video-to-video:', error.message || error);
    await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×•×™×“××•.');
  }
}

/**
 * Handle creative voice message processing
 * Flow: Download â†’ Creative Effects â†’ Convert to Opus â†’ Send
 */
async function handleCreativeVoiceMessage({ chatId, senderId, senderName, audioUrl }) {
  console.log(`ğŸ¨ Processing creative voice request from ${senderName}`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'creative_voice_processing' });
    
    // Step 1: Download audio file
    console.log(`ğŸ“¥ Step 1: Downloading audio file...`);
    const audioBuffer = await downloadFile(audioUrl);
    console.log(`âœ… Step 1 complete: Downloaded ${audioBuffer.length} bytes`);
    
    // Step 2: Apply creative effects
    console.log(`ğŸ¨ Step 2: Applying creative effects...`);
    const creativeResult = await creativeAudioService.processVoiceCreatively(audioBuffer, 'mp3');
    
    if (!creativeResult.success) {
      console.error('âŒ Creative processing failed:', creativeResult.error);
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×¢×‘×“ ××ª ×”×”×§×œ×˜×”: ${creativeResult.error}`);
      return;
    }
    
    console.log(`âœ… Step 2 complete: Applied ${creativeResult.description}`);
    
    // Step 3: Convert to Opus and save
    console.log(`ğŸ”„ Step 3: Converting to Opus format...`);
    const conversionResult = await audioConverterService.convertAndSaveAsOpus(creativeResult.audioBuffer, 'mp3');
    
    if (!conversionResult.success) {
      console.error('âŒ Opus conversion failed:', conversionResult.error);
      // Fallback: send as regular MP3
      const fileName = `creative_${Date.now()}.mp3`;
      const tempPath = path.join(__dirname, '..', 'public', 'tmp', fileName);
      fs.writeFileSync(tempPath, creativeResult.audioBuffer);
      const fullAudioUrl = getStaticFileUrl(fileName);
      await sendFileByUrl(chatId, fullAudioUrl, fileName, '');
    } else {
      // Send as voice note with Opus format
      const fullAudioUrl = getStaticFileUrl(conversionResult.fileName);
      
      // Verify file exists before sending
      const filePath = path.join(__dirname, '..', 'public', 'tmp', conversionResult.fileName);
      if (!fs.existsSync(filePath)) {
        console.error(`âŒ Opus file not found: ${filePath}`);
        await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×§×•×‘×¥ ×”××•×“×™×• ×œ× × ××¦×. × ×¡×” ×©×•×‘.`);
        return;
      }
      
      console.log(`ğŸ“ Opus file verified: ${filePath} (${fs.statSync(filePath).size} bytes)`);
      console.log(`ğŸ”— Full URL: ${fullAudioUrl}`);
      
      await sendFileByUrl(chatId, fullAudioUrl, conversionResult.fileName, '');
      console.log(`âœ… Creative voice sent as voice note: ${conversionResult.fileName}`);
    }
    
    // Send effect description
    await sendTextMessage(chatId, `ğŸ¨ ×¢×™×‘×•×“ ×™×¦×™×¨×ª×™ ×”×•×©×œ×!\n\n${creativeResult.description}`);
    
    console.log(`âœ… Creative voice processing complete for ${senderName}`);

  } catch (error) {
    console.error('âŒ Error in creative voice processing:', error.message || error);
    await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×™×¦×™×¨×ª×™ ×©×œ ×”×”×§×œ×˜×”.');
  }
}

/**
 * Handle voice message with full voice-to-voice processing - COMMENTED OUT FOR CREATIVE PROCESSING
 * Flow: Speech-to-Text â†’ Voice Clone â†’ Gemini Response â†’ Text-to-Speech
 */
/*
async function handleVoiceMessage({ chatId, senderId, senderName, audioUrl }) {
  console.log(`ğŸ¤ Processing voice-to-voice request from ${senderName}`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'voice_processing' });
    
    // Step 1: Download audio file
    const audioBuffer = await downloadFile(audioUrl);
    
    // Step 2: Speech-to-Text transcription
    console.log(`ğŸ”„ Step 1: Transcribing speech...`);
    const transcriptionOptions = {
      model: 'scribe_v1',
      language: null, // Auto-detect
      removeNoise: true,
      removeFiller: true,
      optimizeLatency: 0,
      format: 'ogg' // WhatsApp audio format
    };
    
    const transcriptionResult = await speechService.speechToText(audioBuffer, transcriptionOptions);
    
    if (transcriptionResult.error) {
      console.error('âŒ Transcription failed:', transcriptionResult.error);
      // We don't know the language yet, so use Hebrew as default for error messages
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×”: ${transcriptionResult.error}`);
      return;
    }

    const transcribedText = transcriptionResult.text;
    console.log(`âœ… Step 1 complete: Transcribed ${transcribedText.length} characters`);
    console.log(`ğŸ“ Transcribed: "${transcribedText}"`);

    // Use our own language detection on the transcribed text for consistency
    const originalLanguage = voiceService.detectLanguage(transcribedText);
    console.log(`ğŸŒ STT detected: ${transcriptionResult.detectedLanguage}, Our detection: ${originalLanguage}`);

    // Send transcription to user first - always in Hebrew for consistency
    const transcriptionMessage = `ğŸ“ ×ª××œ×•×œ ×”×”×•×“×¢×” ×©×œ ${senderName}: "${transcribedText}"`;
    
    await sendTextMessage(chatId, transcriptionMessage);

    // Step 2: Create Instant Voice Clone
    console.log(`ğŸ”„ Step 2: Creating voice clone...`);
    
    const voiceCloneOptions = {
      name: `WhatsApp Voice Clone ${Date.now()}`,
      description: `Voice clone from WhatsApp audio`,
      removeBackgroundNoise: true,
      labels: JSON.stringify({
        accent: originalLanguage === 'he' ? 'hebrew' : 'natural',
        use_case: 'conversational',
        quality: 'high',
        style: 'natural',
        language: originalLanguage
      })
    };
    
    const voiceCloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
    
    if (voiceCloneResult.error) {
      console.error('âŒ Voice cloning failed:', voiceCloneResult.error);
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×©×™×‘×•×˜ ×§×•×œ: ${voiceCloneResult.error}`);
      return;
    }

    const voiceId = voiceCloneResult.voiceId;
    const detectedLanguage = transcriptionResult.detectedLanguage || 'he';
    console.log(`âœ… Step 2 complete: Voice cloned (ID: ${voiceId}), Language: ${detectedLanguage}`);

    // Step 3: Generate Gemini response in the same language as the original
    console.log(`ğŸ”„ Step 3: Generating Gemini response in ${originalLanguage}...`);
    
    // Create language-aware prompt for Gemini
    const languageInstruction = originalLanguage === 'he' 
      ? '' // Hebrew is default, no need for special instruction
      : originalLanguage === 'en' 
        ? 'Please respond in English. ' 
        : originalLanguage === 'ar' 
          ? 'ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. '
          : originalLanguage === 'ru' 
            ? 'ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹Ñ‚Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. '
            : originalLanguage === 'es' 
              ? 'Por favor responde en espaÃ±ol. '
              : originalLanguage === 'fr' 
                ? 'Veuillez rÃ©pondre en franÃ§ais. '
                : originalLanguage === 'de' 
                  ? 'Bitte antworten Sie auf Deutsch. '
                  : `Please respond in the same language as this message. `;
    
    const geminiPrompt = languageInstruction + transcribedText;
    // Voice processing doesn't need conversation history - treat each voice message independently
    const geminiResult = await generateGeminiResponse(geminiPrompt, []);
    
    // Add user message to conversation AFTER getting Gemini response to avoid duplication
    await conversationManager.addMessage(chatId, 'user', `×”×§×œ×˜×” ×§×•×œ×™×ª: ${transcribedText}`);
    
    if (geminiResult.error) {
      console.error('âŒ Gemini generation failed:', geminiResult.error);
      const errorMessage = originalLanguage === 'he' 
        ? `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª×’×•×‘×”: ${geminiResult.error}`
        : `âŒ Sorry, I couldn't generate a response: ${geminiResult.error}`;
      await sendTextMessage(chatId, errorMessage);
      
      // Clean up voice clone before returning
      try {
        await voiceService.deleteVoice(voiceId);
        console.log(`ğŸ§¹ Voice clone ${voiceId} deleted (cleanup after Gemini error)`);
      } catch (cleanupError) {
        console.warn('âš ï¸ Could not delete voice clone:', cleanupError.message);
      }
      return;
    }

    const geminiResponse = geminiResult.text;
    console.log(`âœ… Step 3 complete: Gemini generated ${geminiResponse.length} characters`);
    console.log(`ğŸ’¬ Gemini response: "${geminiResponse.substring(0, 100)}..."`);
    
    // Add AI response to conversation history
    await conversationManager.addMessage(chatId, 'assistant', geminiResponse);

    // Step 4: Text-to-Speech with cloned voice
    console.log(`ğŸ”„ Step 4: Converting text to speech with cloned voice...`);
    
    // Use the original language for TTS to maintain consistency throughout the flow
    const responseLanguage = originalLanguage; // Force same language as original
    console.log(`ğŸŒ Language consistency enforced:`);
    console.log(`   - Original (from user): ${originalLanguage}`);
    console.log(`   - TTS (forced same): ${responseLanguage}`);
    
    const ttsOptions = {
      modelId: 'eleven_v3', // Use the most advanced model
      outputFormat: 'mp3_44100_128', // ElevenLabs doesn't support ogg_vorbis
      languageCode: responseLanguage
    };

    const ttsResult = await voiceService.textToSpeech(voiceId, geminiResponse, ttsOptions);
    
    if (ttsResult.error) {
      console.error('âŒ Text-to-speech failed:', ttsResult.error);
      // If TTS fails, send error message (don't send the Gemini response as text)
      const errorMessage = originalLanguage === 'he' 
        ? 'âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª×’×•×‘×” ×§×•×œ×™×ª. × ×¡×” ×©×•×‘.'
        : 'âŒ Sorry, I couldn\'t generate voice response. Please try again.';
      await sendTextMessage(chatId, errorMessage);
      
      // Clean up voice clone before returning
      try {
        await voiceService.deleteVoice(voiceId);
        console.log(`ğŸ§¹ Voice clone ${voiceId} deleted (cleanup after TTS error)`);
      } catch (cleanupError) {
        console.warn('âš ï¸ Could not delete voice clone:', cleanupError.message);
      }
      return;
    }

    console.log(`âœ… Step 4 complete: Audio generated at ${ttsResult.audioUrl}`);

    // Step 5: Convert and send voice response back to user as voice note
    console.log(`ğŸ”„ Converting voice-to-voice to Opus format for voice note...`);
    const conversionResult = await audioConverterService.convertUrlToOpus(ttsResult.audioUrl, 'mp3');
    
    if (!conversionResult.success) {
      console.error('âŒ Audio conversion failed:', conversionResult.error);
      // Fallback: send as regular MP3 file
      const fullAudioUrl = ttsResult.audioUrl.startsWith('http') 
        ? ttsResult.audioUrl 
        : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
      await sendFileByUrl(chatId, fullAudioUrl, `voice_${Date.now()}.mp3`, '');
    } else {
      // Send as voice note with Opus format
      const fullAudioUrl = getStaticFileUrl(conversionResult.fileName);
      await sendFileByUrl(chatId, fullAudioUrl, conversionResult.fileName, '');
      console.log(`âœ… Voice-to-voice sent as voice note: ${conversionResult.fileName}`);
    }
    
    console.log(`âœ… Voice-to-voice processing complete for ${senderName}`);

    // Cleanup: Delete the cloned voice (optional - ElevenLabs has limits)
    try {
      await voiceService.deleteVoice(voiceId);
      console.log(`ğŸ§¹ Cleanup: Voice ${voiceId} deleted`);
    } catch (cleanupError) {
      console.warn('âš ï¸ Voice cleanup failed:', cleanupError.message);
    }

  } catch (error) {
    console.error('âŒ Error in voice-to-voice processing:', error.message || error);
    await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×”×§×œ×˜×” ×”×§×•×œ×™×ª.');
  }
}
*/

/**
 * Handle text message with AI chat functionality
 */
async function handleTextMessage({ chatId, senderId, senderName, senderContactName, chatName, messageText }, isOutgoing = false) {
  console.log(`ğŸ’¬ ${messageText.substring(0, 50)}${messageText.length > 50 ? '...' : ''} ${isOutgoing ? '(outgoing)' : ''}`);
  
  const command = parseTextCommand(messageText);
  
  if (!command) {
    return;
  }

  console.log(`ğŸ¤– ${command.type} ${isOutgoing ? '(outgoing)' : ''}`);

  // SECURITY: Admin commands can only be executed from outgoing messages (sent by you)
  if (isAdminCommand(command.type) && !isOutgoing) {
    console.log(`ğŸš« Admin command ${command.type} blocked - only works from outgoing messages`);
    // Silently ignore admin commands from incoming messages (no error message to user)
    return;
  }

  // Check authorization for media commands BEFORE sending ACK (skip for outgoing messages)
  // Management commands (transcription, media creation status, etc.) should work from outgoing messages
  if (!isOutgoing && requiresMediaAuthorization(command.type)) {
    if (!(await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, sender: senderId, chatId }))) {
      await sendUnauthorizedMessage(chatId, command.type);
      return;
    }
  }

  // Send immediate ACK for long-running commands (skip chat commands)
  if (command.type !== 'gemini_chat' && command.type !== 'openai_chat') {
    await sendAck(chatId, command);
  }

  try {
    switch (command.type) {
      case 'gemini_chat':
        console.log(`ğŸ¤– Processing Gemini chat request from ${senderName}`);
        
        try {
          // Add user message to conversation
          await conversationManager.addMessage(chatId, 'user', command.prompt);
          
          // Get conversation history for context
          const history = await conversationManager.getConversationHistory(chatId);
          
          // Generate Gemini response with history
          const geminiResponse = await generateGeminiResponse(command.prompt, history);
          
          if (geminiResponse.error) {
            await sendTextMessage(chatId, geminiResponse.error);
            console.log(`âŒ Gemini error for ${senderName}: ${geminiResponse.error}`);
          } else {
            // Add AI response to conversation
            await conversationManager.addMessage(chatId, 'assistant', geminiResponse.text);
            await sendTextMessage(chatId, geminiResponse.text);
            console.log(`âœ… Gemini chat completed for ${senderName} with history context (${history.length} messages)`);
          }
        } catch (geminiError) {
          console.error('âŒ Error in Gemini chat:', geminiError.message || geminiError);
          await sendTextMessage(chatId, `âŒ ${geminiError.message || geminiError}`);
        }
        break;

      case 'openai_chat':
        console.log(`ğŸ¤– Processing OpenAI chat request from ${senderName}`);
        
        try {
          // Add user message to conversation
          await conversationManager.addMessage(chatId, 'user', command.prompt);
          
          // Get conversation history for context
          const openaiHistory = await conversationManager.getConversationHistory(chatId);
          
          // Generate OpenAI response with history
          const openaiResponse = await generateOpenAIResponse(command.prompt, openaiHistory);
          
          if (openaiResponse.error) {
            await sendTextMessage(chatId, openaiResponse.error);
            console.log(`âŒ OpenAI error for ${senderName}: ${openaiResponse.error}`);
          } else {
            // Add AI response to conversation
            await conversationManager.addMessage(chatId, 'assistant', openaiResponse.text);
            await sendTextMessage(chatId, openaiResponse.text);
            console.log(`âœ… OpenAI chat completed for ${senderName} with history context (${openaiHistory.length} messages)`);
          }
        } catch (openaiError) {
          console.error('âŒ Error in OpenAI chat:', openaiError.message || openaiError);
          await sendTextMessage(chatId, `âŒ ${openaiError.message || openaiError}`);
        }
        break;

      case 'grok_chat':
        console.log(`ğŸ¤– Processing Grok chat request from ${senderName}`);
        
        try {
          // Add user message to conversation
          await conversationManager.addMessage(chatId, 'user', command.prompt);
          
          // Get conversation history for context
          const grokHistory = await conversationManager.getConversationHistory(chatId);
          
          // Generate Grok response with history
          const grokResponse = await generateGrokResponse(command.prompt, grokHistory);
          
          if (grokResponse.error) {
            await sendTextMessage(chatId, grokResponse.error);
            console.log(`âŒ Grok error for ${senderName}: ${grokResponse.error}`);
          } else {
            // Add AI response to conversation
            await conversationManager.addMessage(chatId, 'assistant', grokResponse.text);
            await sendTextMessage(chatId, grokResponse.text);
            console.log(`âœ… Grok chat completed for ${senderName} with history context (${grokHistory.length} messages)`);
          }
        } catch (grokError) {
          console.error('âŒ Error in Grok chat:', grokError.message || grokError);
          await sendTextMessage(chatId, `âŒ ${grokError.message || grokError}`);
        }
        break;

      case 'grok_image':
        console.log(`ğŸ–¼ï¸ Processing Grok image generation request from ${senderName}`);
        
        try {
          // Note: Image generation commands do NOT add to conversation history
          
          const { generateImageForWhatsApp: generateGrokImage } = require('../services/grokService');
          const grokImageResult = await generateGrokImage(command.prompt);
          
          if (!grokImageResult.success) {
            await sendTextMessage(chatId, grokImageResult.error || '×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×” ×¢× Grok');
          } else {
            // Send both image and text if available
            if (grokImageResult.imageUrl && grokImageResult.description) {
              await sendFileByUrl(chatId, grokImageResult.imageUrl, 'grok_image.png', '');
              await sendTextMessage(chatId, grokImageResult.description);
            } else if (grokImageResult.imageUrl) {
              await sendFileByUrl(chatId, grokImageResult.imageUrl, 'grok_image.png', '');
            } else if (grokImageResult.description) {
              await sendTextMessage(chatId, grokImageResult.description);
            } else {
              await sendTextMessage(chatId, 'âœ… ×”×ª××•× ×” × ×•×¦×¨×” ×‘×”×¦×œ×—×” ×¢× Grok');
            }
            
            console.log(`âœ… Grok image sent to ${senderName}`);
          }
        } catch (grokImageError) {
          console.error('âŒ Error in Grok image generation:', grokImageError.message || grokImageError);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×ª××•× ×” ×¢× Grok: ${grokImageError.message || grokImageError}`);
        }
        break;

      case 'openai_image':
        console.log(`ğŸ–¼ï¸ Processing OpenAI image generation request from ${senderName}`);
        
        try {
          // Note: Image generation commands do NOT add to conversation history
          
          // Generate image with OpenAI (WhatsApp format)
          const openaiImageResult = await generateOpenAIImage(command.prompt);
          
          if (openaiImageResult.success && openaiImageResult.imageUrl) {
            // Send the generated image with text as caption (if exists)
            const fileName = `openai_image_${Date.now()}.png`;
            const caption = openaiImageResult.description && openaiImageResult.description.length > 0 
              ? openaiImageResult.description 
              : '';
            
              await sendFileByUrl(chatId, openaiImageResult.imageUrl, fileName, caption);
              
              // Note: Image generation results do NOT add to conversation history
            
            console.log(`âœ… OpenAI image sent to ${senderName}${caption ? ' with caption: ' + caption : ''}`);
          } else {
            const errorMsg = openaiImageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ OpenAI image generation failed for ${senderName}: ${errorMsg}`);
          }
        } catch (openaiImageError) {
          console.error('âŒ Error in OpenAI image generation:', openaiImageError.message || openaiImageError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”.');
        }
        break;

      case 'gemini_image':
        console.log(`ğŸ¨ Processing Gemini image generation request from ${senderName}`);
        
        try {
          // Note: Image generation commands do NOT add to conversation history
          
          // Generate image with Gemini (WhatsApp format)
          const imageResult = await generateImageForWhatsApp(command.prompt);
          
          if (imageResult.success && imageResult.imageUrl) {
            // Send the generated image with text as caption
            const fileName = `gemini_image_${Date.now()}.png`;
            const caption = imageResult.description && imageResult.description.length > 0 
              ? imageResult.description 
              : '';
            
              await sendFileByUrl(chatId, imageResult.imageUrl, fileName, caption);
              
              // Note: Image generation results do NOT add to conversation history
            
            console.log(`âœ… Gemini image sent to ${senderName}${caption ? ' with caption: ' + caption : ''}`);
          } else {
            // Check if Gemini returned text instead of image
            if (imageResult.textResponse) {
              console.log('ğŸ“ Gemini returned text instead of image, sending text response');
                await sendTextMessage(chatId, imageResult.textResponse);
                
                // Note: Image generation text responses do NOT add to conversation history
            } else {
              const errorMsg = imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
              await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
              console.log(`âŒ Gemini image generation failed for ${senderName}: ${errorMsg}`);
            }
          }
        } catch (imageError) {
          console.error('âŒ Error in Gemini image generation:', imageError.message || imageError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”.');
        }
        break;

      case 'veo3_video':
        console.log(`ğŸ¬ Processing Veo 3 video generation request from ${senderName}`);
        
        try {
          // Note: Video generation commands do NOT add to conversation history
          
          // Generate video with Veo 3 (WhatsApp format)
          const videoResult = await generateVideoForWhatsApp(command.prompt);
          
          if (videoResult.success && videoResult.videoUrl) {
            // Send the generated video without caption
            const fileName = `veo3_video_${Date.now()}.mp4`;
            
            await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
            
            // Note: Video generation results do NOT add to conversation history
            
            console.log(`âœ… Veo 3 video sent to ${senderName}`);
          } else {
            const errorMsg = videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ Veo 3 video generation failed for ${senderName}: ${errorMsg}`);
          }
        } catch (videoError) {
          console.error('âŒ Error in Veo 3 video generation:', videoError.message || videoError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×•×™×“××•.');
        }
        break;

      case 'kling_text_to_video':
        console.log(`ğŸ¬ Processing Kling text-to-video generation request from ${senderName}`);
        
        try {
          // Note: Video generation commands do NOT add to conversation history
          
          // Generate video with Kling 2.1 Master (WhatsApp format)
          const videoResult = await generateKlingVideoFromText(command.prompt);
          
          if (videoResult.success && videoResult.videoUrl) {
            // Send the generated video without caption
            const fileName = videoResult.fileName || `kling_video_${Date.now()}.mp4`;
            
            await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
            
            // Note: Video generation results do NOT add to conversation history
            
            console.log(`âœ… Kling text-to-video sent to ${senderName}`);
          } else {
            const errorMsg = videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ××ª ×”×•×•×™×“××•. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ Kling text-to-video failed for ${senderName}: ${errorMsg}`);
          }
        } catch (videoError) {
          console.error('âŒ Error in Kling text-to-video generation:', videoError.message || videoError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×•×•×™×“××• ×¢× Kling.');
        }
        break;

      case 'chat_summary':
        console.log(`ğŸ“ Processing chat summary request from ${senderName}`);
        
        try {
          // Get last 10 messages from Green API
          const chatHistory = await getChatHistory(chatId, 30);
          
          if (!chatHistory || chatHistory.length === 0) {
            await sendTextMessage(chatId, 'ğŸ“ ××™×Ÿ ××¡×¤×™×§ ×”×•×“×¢×•×ª ×‘×©×™×—×” ×›×“×™ ×œ×™×¦×•×¨ ×¡×™×›×•×.');
            break;
          }
          
          // Generate summary with Gemini
          const summaryResult = await generateChatSummary(chatHistory);
          
          if (summaryResult.success && summaryResult.summary) {
            // Send the summary back to the chat
            await sendTextMessage(chatId, `ğŸ“ **×¡×™×›×•× ×”×©×™×—×”:**\n\n${summaryResult.summary}`);
            
            // Add to conversation history
            await conversationManager.addMessage(chatId, 'user', '×‘×§×©×” ×œ×¡×™×›×•× ×©×™×—×”');
            await conversationManager.addMessage(chatId, 'assistant', `×¡×™×›×•× ×”×©×™×—×”: ${summaryResult.summary}`);
            
            console.log(`âœ… Chat summary sent to ${senderName}`);
          } else {
            const errorMsg = summaryResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×¡×™×›×•× ×©×œ ×”×©×™×—×”.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ Chat summary failed for ${senderName}: ${errorMsg}`);
          }
        } catch (summaryError) {
          console.error('âŒ Error in chat summary:', summaryError.message || summaryError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×¡×™×›×•× ×”×©×™×—×”.');
        }
        break;

      case 'command_list':
        console.log(`ğŸ“œ Processing command list request from ${senderName}`);
        
        try {
          // Define path to the command list file
          const COMMAND_LIST_FILE = path.join(__dirname, '..', 'store', 'commandList.txt');
          
          // Check if file exists
          if (fs.existsSync(COMMAND_LIST_FILE)) {
            // Read the command list file
            const commandListContent = fs.readFileSync(COMMAND_LIST_FILE, 'utf8');
            
            // Send the command list to the user
            await sendTextMessage(chatId, commandListContent);
            console.log(`âœ… Command list sent to ${senderName}`);
          } else {
            await sendTextMessage(chatId, 'âŒ ×¨×©×™××ª ×”×¤×§×•×“×•×ª ×œ× × ××¦××”. ×¤× ×” ×œ×× ×”×œ ×”××¢×¨×›×ª.');
            console.log(`âŒ Command list file not found: ${COMMAND_LIST_FILE}`);
          }
        } catch (commandListError) {
          console.error('âŒ Error reading command list:', commandListError.message || commandListError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×˜×¢×™× ×ª ×¨×©×™××ª ×”×¤×§×•×“×•×ª.');
        }
        break;

      case 'clear_all_conversations':
        console.log(`ğŸ—‘ï¸ Processing clear all conversations request from ${senderName}`);
        
        try {
          const deletedCount = await conversationManager.clearAllConversations();
          if (deletedCount > 0) {
            await sendTextMessage(chatId, `ğŸ—‘ï¸ ×›×œ ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×•×ª × ××—×§×” ×‘×”×¦×œ×—×” (${deletedCount} ×”×•×“×¢×•×ª × ××—×§×•)`);
            console.log(`âœ… All conversations cleared by ${senderName}: ${deletedCount} messages deleted`);
          } else {
            await sendTextMessage(chatId, 'â„¹ï¸ ×œ× × ××¦××” ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×•×ª ×œ××—×™×§×”');
            console.log(`â„¹ï¸ No conversations to clear (requested by ${senderName})`);
          }
        } catch (error) {
          console.error('âŒ Error clearing all conversations:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘××—×™×§×ª ×›×œ ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×•×ª');
        }
        break;

      case 'show_history':
        const history = await conversationManager.getConversationHistory(chatId);
        if (history.length === 0) {
          await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”');
        } else {
          let historyText = 'ğŸ“‹ ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:\n\n';
          history.forEach((msg, index) => {
            const role = msg.role === 'user' ? 'ğŸ‘¤ ××ª×”' : 'ğŸ¤– AI';
            historyText += `${index + 1}. ${role}: ${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}\n\n`;
          });
          await sendTextMessage(chatId, historyText);
        }
        break;

      case 'music_generation':
        console.log(`ğŸµ Processing music generation request from ${senderName}`);
        
        try {
          // Note: Music generation commands do NOT add to conversation history
          
          // Generate music with Suno (WhatsApp format)
          const musicResult = await generateMusicWithLyrics(command.prompt);
          
          // Debug: Log full metadata structure
          if (musicResult.metadata) {
            console.log('ğŸµ Suno metadata available:', musicResult.metadata ? 'yes' : 'no');
          }
          
          if (musicResult.error) {
            const errorMsg = musicResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×©×™×¨. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ Music generation failed for ${senderName}: ${errorMsg}`);
          } else if (musicResult.audioBuffer && musicResult.result) {
            // Convert MP3 to Opus for voice note
            console.log(`ğŸ”„ Converting music to Opus format for voice note...`);
            const conversionResult = await audioConverterService.convertAndSaveAsOpus(musicResult.audioBuffer, 'mp3');
            
            if (!conversionResult.success) {
              console.error('âŒ Audio conversion failed:', conversionResult.error);
              // Fallback: send as regular MP3 file
              const fileName = `suno_music_${Date.now()}.mp3`;
              const fullAudioUrl = musicResult.result.startsWith('http') 
                ? musicResult.result 
                : getStaticFileUrl(musicResult.result.replace('/static/', ''));
              await sendFileByUrl(chatId, fullAudioUrl, fileName, '');
            } else {
              // Send as voice note with Opus format
              const fullAudioUrl = getStaticFileUrl(conversionResult.fileName);
              await sendFileByUrl(chatId, fullAudioUrl, conversionResult.fileName, '');
              console.log(`âœ… Music sent as voice note: ${conversionResult.fileName}`);
            }
            
            // Send song information and lyrics as separate text message
            let songInfo = '';
            if (musicResult.metadata) {
              const meta = musicResult.metadata;
              
              songInfo = `ğŸµ **${meta.title || '×©×™×¨ ×—×“×©'}**\n`;
              if (meta.duration) songInfo += `â±ï¸ ××©×š: ${Math.round(meta.duration)}s\n`;
              if (meta.model) songInfo += `ğŸ¤– ××•×“×œ: ${meta.model}\n`;
              
              // Add lyrics if available - with better fallback logic
              if (meta.lyrics && meta.lyrics.trim()) {
                songInfo += `\nğŸ“ **××™×œ×•×ª ×”×©×™×¨:**\n${meta.lyrics}`;
              } else if (meta.lyric && meta.lyric.trim()) {
                songInfo += `\nğŸ“ **××™×œ×•×ª ×”×©×™×¨:**\n${meta.lyric}`;
              } else if (meta.prompt && meta.prompt.trim()) {
                songInfo += `\nğŸ“ **××™×œ×•×ª ×”×©×™×¨:**\n${meta.prompt}`;
              } else if (meta.gptDescriptionPrompt && meta.gptDescriptionPrompt.trim()) {
                songInfo += `\nğŸ“ **×ª×™××•×¨ ×”×©×™×¨:**\n${meta.gptDescriptionPrompt}`;
              } else {
                songInfo += `\nğŸ“ **××™×œ×•×ª ×”×©×™×¨:** ×œ× ×–××™× ×•×ª`;
              }
            } else {
              songInfo = `ğŸµ ×”×©×™×¨ ××•×›×Ÿ!`;
              console.log('âš ï¸ No metadata available for song');
            }
            
            await sendTextMessage(chatId, songInfo);
            
            // Note: Music generation results do NOT add to conversation history
            
            console.log(`âœ… Music sent to ${senderName}: ${musicResult.metadata?.title || 'Generated Music'}`);
          } else {
            await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×©×™×¨.');
            console.log(`âŒ Music generation failed for ${senderName}: No audio buffer or result path`);
          }
        } catch (musicError) {
          console.error('âŒ Error in music generation:', musicError.message || musicError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×©×™×¨.');
        }
        break;

      case 'text_to_speech':
        console.log(`ğŸ—£ï¸ Processing text-to-speech request from ${senderName}`);
        
        try {
          // Note: Text-to-speech commands do NOT add to conversation history
          
          // Generate speech with random voice
          const ttsResult = await voiceService.textToSpeechWithRandomVoice(command.prompt);
          
          if (ttsResult.error) {
            const errorMsg = ttsResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×“×™×‘×•×¨. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
            await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
            console.log(`âŒ TTS failed for ${senderName}: ${errorMsg}`);
          } else if (ttsResult.audioUrl) {
            // Convert TTS audio to Opus for voice note
            console.log(`ğŸ”„ Converting TTS to Opus format for voice note...`);
            const conversionResult = await audioConverterService.convertUrlToOpus(ttsResult.audioUrl, 'mp3');
            
            if (!conversionResult.success) {
              console.error('âŒ Audio conversion failed:', conversionResult.error);
              // Fallback: send as regular MP3 file
              const fileName = `tts_${Date.now()}.mp3`;
              const fullAudioUrl = ttsResult.audioUrl.startsWith('http') 
                ? ttsResult.audioUrl 
                : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
              await sendFileByUrl(chatId, fullAudioUrl, fileName, '');
            } else {
              // Send as voice note with Opus format
              const fullAudioUrl = getStaticFileUrl(conversionResult.fileName);
              await sendFileByUrl(chatId, fullAudioUrl, conversionResult.fileName, '');
              console.log(`âœ… TTS sent as voice note: ${conversionResult.fileName}`);
            }
            
            // Note: Text-to-speech results do NOT add to conversation history
            
            console.log(`âœ… TTS sent to ${senderName}: ${ttsResult.voiceInfo?.voiceName || 'Unknown voice'}`);
          } else {
            await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×™×‘×•×¨.');
            console.log(`âŒ TTS failed for ${senderName}: No audio URL in result`);
          }
        } catch (ttsError) {
          console.error('âŒ Error in text-to-speech:', ttsError.message || ttsError);
          await sendTextMessage(chatId, 'âŒ ×¡×œ×™×—×”, ×”×™×™×ª×” ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×™×‘×•×¨.');
        }
        break;

      case 'help':
        const helpMessage = 'ğŸ¤– Green API Bot Commands:\n\nâœ¨ **×”×¤×§×•×“×•×ª ×¢×•×‘×“×•×ª ×’× ×›×©××ª×” ×©×•×œ×— ××•×ª×Ÿ!**\nğŸ’¬ ×›×œ ×¤×§×•×“×” ×©×ª×©×œ×— ×ª×¢×‘×“ ×•×”×”×ª×©×•×‘×” ×ª×—×–×•×¨ ×œ××•×ª×” ×©×™×—×”\n\nğŸ’¬ AI Chat:\nğŸ”® * [×©××œ×”] - Gemini Chat\nğŸ¤– # [×©××œ×”] - OpenAI Chat\nğŸš€ + [×©××œ×”] - Grok Chat\n\nğŸ¨ ×™×¦×™×¨×ª ×ª××•× ×•×ª:\nğŸ–¼ï¸ ** [×ª×™××•×¨] - ×™×¦×™×¨×ª ×ª××•× ×” ×¢× Gemini\nğŸ–¼ï¸ ## [×ª×™××•×¨] - ×™×¦×™×¨×ª ×ª××•× ×” ×¢× OpenAI\n\nğŸ¬ ×™×¦×™×¨×ª ×•×™×“××•:\nğŸ¥ #### [×ª×™××•×¨] - ×™×¦×™×¨×ª ×•×™×“××• ×¢× Veo 3 (9:16, ××™×›×•×ª ××§×¡×™××œ×™×ª)\nğŸ¥ ### [×ª×™××•×¨] - ×™×¦×™×¨×ª ×•×™×“××• ×¢× Kling 2.1 Master (9:16)\nğŸ¬ ×©×œ×— ×ª××•× ×” ×¢× ×›×•×ª×¨×ª: ### [×ª×™××•×¨] - ×•×™×“××• ××ª××•× ×” ×¢× Veo 3\nğŸ¬ ×©×œ×— ×ª××•× ×” ×¢× ×›×•×ª×¨×ª: ## [×ª×™××•×¨] - ×•×™×“××• ××ª××•× ×” ×¢× Kling 2.1\nğŸ¬ ×©×œ×— ×•×™×“××• ×¢× ×›×•×ª×¨×ª: ## [×ª×™××•×¨] - ×¢×™×‘×•×“ ×•×™×“××• ×¢× RunwayML Gen4\n\nğŸµ ×™×¦×™×¨×ª ××•×–×™×§×”:\nğŸ¶ **** [×ª×™××•×¨] - ×™×¦×™×¨×ª ×©×™×¨ ×¢× Suno (×¢×“ 20 ×“×§×•×ª)\nğŸ“ ×“×•×’××”: **** ×©×™×¨ ×¢×¦×•×‘ ×¢×œ ×’×©× ×‘×—×•×¨×£\nğŸµ ×”×©×™×¨ × ×©×œ×— ×›-voice note + ××™×œ×•×ª ×”×©×™×¨ ×‘×”×•×“×¢×ª ×˜×§×¡×˜\n\nğŸ—£ï¸ ×™×¦×™×¨×ª ×“×™×‘×•×¨:\nğŸ™ï¸ *** [×˜×§×¡×˜] - Text-to-Speech ×¢× ElevenLabs (×§×•×œ ××§×¨××™)\nğŸ“ ×“×•×’××”: *** ×©×œ×•×, ××™×š ×©×œ×•××š ×”×™×•×?\nğŸ¤ ×”×“×™×‘×•×¨ × ×©×œ×— ×›-voice note\n\nğŸ¤ ×¢×™×‘×•×“ ×§×•×œ×™:\nğŸ—£ï¸ ×©×œ×— ×”×§×œ×˜×” ×§×•×œ×™×ª - ×ª××œ×•×œ + ×ª×’×•×‘×ª AI + ×©×™×‘×•×˜ ×§×•×œ\nğŸ“ Flow: ×§×•×œ â†’ ×ª××œ×•×œ â†’ Gemini â†’ ×§×•×œ ×—×“×© ×‘×§×•×œ×š\nğŸ¤ ×”×ª×’×•×‘×” ×”×§×•×œ×™×ª × ×©×œ×—×ª ×›-voice note\nâš ï¸ ×”×•×“×¢×•×ª ×§×•×œ×™×•×ª ×©×œ×š ×œ× ××ª×¢×‘×“×•×ª (×¨×§ × ×›× ×¡×•×ª)\n\nâœ¨ ×¢×¨×™×›×ª ×ª××•× ×•×ª:\nğŸ¨ ×©×œ×— ×ª××•× ×” ×¢× ×›×•×ª×¨×ª: * [×”×•×¨××•×ª ×¢×¨×™×›×”] - Gemini\nğŸ–¼ï¸ ×©×œ×— ×ª××•× ×” ×¢× ×›×•×ª×¨×ª: # [×”×•×¨××•×ª ×¢×¨×™×›×”] - OpenAI\n\nâš™ï¸ × ×™×”×•×œ ×©×™×—×”:\nğŸ“ ×¡×›× ×©×™×—×” - ×¡×™×›×•× 10 ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª\nğŸ—‘ï¸ /clear - ××—×™×§×ª ×”×™×¡×˜×•×¨×™×”\nğŸ“ /history - ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×”\nâ“ /help - ×”×¦×’×ª ×¢×–×¨×” ×–×•\n\nğŸ”Š ×‘×§×¨×ª ×ª××œ×•×œ:\nâ„¹ï¸ ×¡×˜×˜×•×¡ ×ª××œ×•×œ - ×‘×“×™×§×ª ××¦×‘ ×”×ª××œ×•×œ + ×¨×©×™××ª ××•×¨×©×™×\nâœ… ×”×•×¡×£ ×œ×ª××œ×•×œ <×©×> - ×”×•×¡×¤×ª ××™×© ×§×©×¨ ×œ×¨×©×™××ª ×”××•×¨×©×™×\nğŸš« ×”×¡×¨ ××ª××œ×•×œ <×©×> - ×”×¡×¨×ª ××™×© ×§×©×¨ ××¨×©×™××ª ×”××•×¨×©×™×\n\nğŸ’¡ ×“×•×’×××•×ª:\n* ××” ×”×”×‘×“×œ ×‘×™×Ÿ AI ×œ×‘×™×Ÿ ML?\n# ×›×ª×•×‘ ×œ×™ ×©×™×¨ ×¢×œ ×—×ª×•×œ\n+ ××” ××ª×” ×—×•×©×‘ ×¢×œ ×”×¢×ª×™×“ ×©×œ AI?\n** ×—×ª×•×œ ×›×ª×•× ×©×™×•×©×‘ ×¢×œ ×¢×¥\n#### ×©×¤×Ÿ ××•××¨ Hi\n### ×—×ª×•×œ ×¨×•×§×“ ×‘×’×©×\n**** ×©×™×¨ ×¨×•×§ ×¢×œ ××”×‘×”\n*** ×©×œ×•×, ××™×š ×©×œ×•××š ×”×™×•×?\nğŸ¨ ×ª××•× ×” + ×›×•×ª×¨×ª: * ×”×•×¡×£ ×›×•×‘×¢ ××“×•×\nğŸ–¼ï¸ ×ª××•× ×” + ×›×•×ª×¨×ª: # ×”×¤×•×š ×¨×§×¢ ×œ×›×—×•×œ\nğŸ¬ ×ª××•× ×” + ×›×•×ª×¨×ª: ### ×”× ×¤×© ××ª ×”×ª××•× ×” ×¢× Veo 3\nğŸ¬ ×ª××•× ×” + ×›×•×ª×¨×ª: ## ×”× ×¤×© ××ª ×”×ª××•× ×” ×¢× Kling\nğŸ¬ ×•×™×“××• + ×›×•×ª×¨×ª: ## ×©×¤×¨ ××ª ×”×•×•×™×“××• ×•×ª×•×¡×™×£ ××¤×§×˜×™×\nğŸ¤ ×©×œ×— ×”×§×œ×˜×” ×§×•×œ×™×ª ×œ×¢×™×‘×•×“ ××œ×\nğŸ“ ×¡×›× ×©×™×—×”\nğŸš« ×”×¡×¨ ××ª××œ×•×œ ×§×¨×œ×•×¡\nâœ… ×”×•×¡×£ ×œ×ª××œ×•×œ ×“× ×”';

        await sendTextMessage(chatId, helpMessage);
        break;

      case 'media_creation_status':
        try {
          const status = await authStore.getStatus();
          const allowList = status.authorizedUsers;
          
          const statusIcon = status.closedByDefault ? 'ğŸ”' : 'ğŸ”';
          const statusText = status.closedByDefault ? '×¡×’×•×¨ ×œ×›×•×œ× (×‘×¨×™×¨×ª ××—×“×œ)' : '××•×’×‘×œ ×œ××•×¨×©×™×';
          let statusMessage = `${statusIcon} ×¡×˜×˜×•×¡ ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××•×œ×˜×™××“×™×”: ${statusText}`;
          
          if (allowList.length > 0) {
            const allowedList = allowList.join('\nâ€¢ ');
            statusMessage += `\n\nâœ… ×× ×©×™ ×§×©×¨ ××•×¨×©×™× (${allowList.length}):\nâ€¢ ${allowedList}`;
          } else {
            statusMessage += '\n\nâ„¹ï¸ ××™×Ÿ ×× ×©×™ ×§×©×¨ ××•×¨×©×™× (×™×¦×™×¨×” ×¡×’×•×¨×” ×œ×›×•×œ×)';
          }
          
          statusMessage += '\n\nğŸ“‹ ×¤×§×•×“×•×ª × ×™×”×•×œ:\n' +
            'â€¢ ×”×•×¡×£ ×œ×™×¦×™×¨×” [×©×] - ×”×•×¡×¤×ª ×”×¨×©××”\n' +
            'â€¢ ×”×¡×¨ ××™×¦×™×¨×” [×©×] - ×”×¡×¨×ª ×”×¨×©××”\n' +
            'â€¢ ×¡×˜×˜×•×¡ ×™×¦×™×¨×” - ×”×¦×’×ª ××¦×‘ × ×•×›×—×™';
          
          await sendTextMessage(chatId, statusMessage);
        } catch (error) {
          console.error('âŒ Error getting media creation status:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×‘×“×™×§×ª ×¡×˜×˜×•×¡ ×™×¦×™×¨×ª ×ª×•×›×Ÿ');
        }
        break;

      case 'voice_transcription_status':
        try {
          const allowList = await conversationManager.getVoiceAllowList();
          
          const statusIcon = 'ğŸ”';
          const statusText = allowList.length > 0 ? '××•×’×‘×œ ×œ××•×¨×©×™×' : '×¡×’×•×¨ ×œ×›×•×œ× (×‘×¨×™×¨×ª ××—×“×œ)';
          let statusMessage = `${statusIcon} ×¡×˜×˜×•×¡ ×ª××œ×•×œ ×”×•×“×¢×•×ª ×§×•×œ×™×•×ª: ${statusText}`;
          
          if (allowList.length > 0) {
            const allowedList = allowList.join('\nâ€¢ ');
            statusMessage += `\n\nâœ… ×× ×©×™ ×§×©×¨ ××•×¨×©×™× (${allowList.length}):\nâ€¢ ${allowedList}`;
          } else {
            statusMessage += '\n\nâ„¹ï¸ ××™×Ÿ ×× ×©×™ ×§×©×¨ ××•×¨×©×™× (×ª××œ×•×œ ×¡×’×•×¨ ×œ×›×•×œ×)';
          }
          
          statusMessage += '\n\nğŸ“‹ ×¤×§×•×“×•×ª × ×™×”×•×œ:\n' +
            'â€¢ ×”×•×¡×£ ×œ×ª××œ×•×œ [×©×] - ×”×•×¡×¤×ª ×”×¨×©××”\n' +
            'â€¢ ×”×¡×¨ ××ª××œ×•×œ [×©×] - ×”×¡×¨×ª ×”×¨×©××”\n' +
            'â€¢ ×¡×˜×˜×•×¡ ×ª××œ×•×œ - ×”×¦×’×ª ××¦×‘ × ×•×›×—×™';
          
          await sendTextMessage(chatId, statusMessage);
          console.log(`â„¹ï¸ Voice transcription status checked by ${senderName}: ${statusText}, allowed: ${allowList.length}`);
        } catch (error) {
          console.error('âŒ Error getting voice transcription status:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×§×‘×œ×ª ×¡×˜×˜×•×¡ ×”×ª××œ×•×œ');
        }
        break;

      case 'exclude_from_transcription':
        // Note: "×”×¡×¨ ××ª××œ×•×œ" now means "remove from allow list" (opposite logic)
        try {
          const wasRemoved = await conversationManager.removeFromVoiceAllowList(command.contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${command.contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× - ×”×•×“×¢×•×ª ×§×•×œ×™×•×ª ×©×œ×• ×œ× ×™×ª×•××œ×œ×•`);
            console.log(`ğŸš« Contact ${command.contactName} removed from voice allow list by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${command.contactName} ×›×‘×¨ ×œ× ×”×™×” ×‘×¨×©×™××ª ×”××•×¨×©×™×`);
            console.log(`â„¹ï¸ Contact ${command.contactName} was not in allow list (requested by ${senderName})`);
          }
        } catch (error) {
          console.error('âŒ Error removing from voice allow list:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×”×¡×¨×” ××¨×©×™××ª ×”××•×¨×©×™×');
        }
        break;

      case 'include_in_transcription':
        // Note: "×”×•×¡×£ ×œ×ª××œ×•×œ" now means "add to allow list"
        try {
          const wasAdded = await conversationManager.addToVoiceAllowList(command.contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${command.contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× - ×”×•×“×¢×•×ª ×§×•×œ×™×•×ª ×©×œ×• ×™×ª×•××œ×œ×•`);
            console.log(`âœ… Contact ${command.contactName} added to voice allow list by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${command.contactName} ×›×‘×¨ ×”×™×” ×‘×¨×©×™××ª ×”××•×¨×©×™×`);
            console.log(`â„¹ï¸ Contact ${command.contactName} was already in allow list (requested by ${senderName})`);
          }
        } catch (error) {
          console.error('âŒ Error adding to voice allow list:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×”×•×¡×¤×” ×œ×¨×©×™××ª ×”××•×¨×©×™×');
        }
        break;

      case 'add_media_authorization':
        try {
          const wasAdded = await authStore.addAuthorizedUser(command.contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${command.contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××•×œ×˜×™××“×™×”`);
            console.log(`âœ… Added ${command.contactName} to media creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${command.contactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××•×œ×˜×™××“×™×”`);
          }
        } catch (error) {
          console.error('âŒ Error adding media authorization:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×”×•×¡×¤×” ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ');
        }
        break;

      case 'remove_media_authorization':
        try {
          const wasRemoved = await authStore.removeAuthorizedUser(command.contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `âœ… ${command.contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××•×œ×˜×™××“×™×”`);
            console.log(`âœ… Removed ${command.contactName} from media creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${command.contactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××•×œ×˜×™××“×™×”`);
          }
        } catch (error) {
          console.error('âŒ Error removing media authorization:', error);
          await sendTextMessage(chatId, 'âŒ ×©×’×™××” ×‘×”×¡×¨×” ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×ª×•×›×Ÿ');
        }
        break;

      default:
        console.log(`â“ Unknown command type: ${command.type}`);
    }
  } catch (error) {
    console.error('âŒ Error executing command:', error.message || error);
    await sendTextMessage(chatId, `âŒ ${error.message || error}`);
  }
}

/**
 * Parse text message to extract command
 */
function parseTextCommand(text) {
  if (!text || typeof text !== 'string') {
    return null;
  }

  text = text.trim();

  // Music Generation command: **** + space + text
  if (text.startsWith('**** ')) {
    const prompt = text.substring(5).trim(); // Remove "**** "
    return {
      type: 'music_generation',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Text-to-Speech command: *** + space + text
  if (text.startsWith('*** ')) {
    const prompt = text.substring(4).trim(); // Remove "*** "
    return {
      type: 'text_to_speech',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Veo 3 Video Generation command: #### + space + text
  if (text.startsWith('#### ')) {
    const prompt = text.substring(5).trim(); // Remove "#### "
    return {
      type: 'veo3_video',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Kling Text-to-Video Generation command: ### + space + text
  if (text.startsWith('### ')) {
    const prompt = text.substring(4).trim(); // Remove "### "
    return {
      type: 'kling_text_to_video',
      prompt: prompt,
      originalMessage: text
    };
  }

  // OpenAI Image Generation command: ## + space + text
  if (text.startsWith('## ')) {
    const prompt = text.substring(3).trim(); // Remove "## "
    return {
      type: 'openai_image',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Gemini Image Generation command: ** + space + text
  if (text.startsWith('** ')) {
    const prompt = text.substring(3).trim(); // Remove "** "
    return {
      type: 'gemini_image',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Gemini Chat command: * + space + text
  if (text.startsWith('* ')) {
    const prompt = text.substring(2).trim(); // Remove "* "
    return {
      type: 'gemini_chat',
      prompt: prompt,
      originalMessage: text
    };
  }

  // OpenAI Chat command: # + space + text
  if (text.startsWith('# ')) {
    const prompt = text.substring(2).trim(); // Remove "# "
    return {
      type: 'openai_chat',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Grok Image Generation command: ++ + space + text
  if (text.startsWith('++ ')) {
    const prompt = text.substring(3).trim(); // Remove "++ "
    return {
      type: 'grok_image',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Grok Chat command: + + space + text
  if (text.startsWith('+ ')) {
    const prompt = text.substring(2).trim(); // Remove "+ "
    return {
      type: 'grok_chat',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Chat summary
  if (text === '×¡×›× ×©×™×—×”') {
    return { type: 'chat_summary' };
  }

  // Command list
  if (text === '×¨×©×™××ª ×¤×§×•×“×•×ª') {
    return { type: 'command_list' };
  }

  // Clear conversation history (admin command)
  if (text === '× ×§×” ×”×™×¡×˜×•×¨×™×”') {
    return { type: 'clear_all_conversations' };
  }

  // Show history
  if (text.toLowerCase() === '/history') {
    return { type: 'show_history' };
  }

  // Help
  if (text.toLowerCase() === '/help') {
    return { type: 'help' };
  }

  // Media creation status
  if (text === '×¡×˜×˜×•×¡ ×™×¦×™×¨×”') {
    return { type: 'media_creation_status' };
  }

  // Voice transcription controls
  if (text === '×¡×˜×˜×•×¡ ×ª××œ×•×œ') {
    return { type: 'voice_transcription_status' };
  }

  // Media creation authorization commands
  if (text.startsWith('×”×•×¡×£ ×œ×™×¦×™×¨×” ')) {
    const contactName = text.substring('×”×•×¡×£ ×œ×™×¦×™×¨×” '.length).trim();
    if (contactName) {
      return { 
        type: 'add_media_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  if (text.startsWith('×”×¡×¨ ××™×¦×™×¨×” ')) {
    const contactName = text.substring('×”×¡×¨ ××™×¦×™×¨×” '.length).trim();
    if (contactName) {
      return { 
        type: 'remove_media_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  // Voice transcription exclude list management
  if (text.startsWith('×”×¡×¨ ××ª××œ×•×œ ')) {
    const contactName = text.substring('×”×¡×¨ ××ª××œ×•×œ '.length).trim();
    if (contactName) {
      return { 
        type: 'exclude_from_transcription', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  if (text.startsWith('×”×•×¡×£ ×œ×ª××œ×•×œ ')) {
    const contactName = text.substring('×”×•×¡×£ ×œ×ª××œ×•×œ '.length).trim();
    if (contactName) {
      return { 
        type: 'include_in_transcription', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  return null;
}

module.exports = router;
