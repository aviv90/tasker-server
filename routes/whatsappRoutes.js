const express = require('express');
const router = express.Router();
const { sendTextMessage, sendFileByUrl, downloadFile, getChatHistory, getMessage, sendPoll, sendLocation } = require('../services/greenApiService');
const { getStaticFileUrl } = require('../utils/urlUtils');
const { cleanPromptFromProviders } = require('../utils/promptCleaner');
const { generateTextResponse: generateOpenAIResponse, generateImageForWhatsApp: generateOpenAIImage, editImageForWhatsApp: editOpenAIImage, generateVideoWithSoraForWhatsApp, generateVideoWithSoraFromImageForWhatsApp } = require('../services/openaiService');
const { generateTextResponse: generateGeminiResponse, generateImageForWhatsApp, editImageForWhatsApp, analyzeVideoWithText, generateVideoForWhatsApp, generateVideoFromImageForWhatsApp, generateChatSummary, parseMusicRequest, parseTextToSpeechRequest, translateText, generateCreativePoll, getLocationInfo } = require('../services/geminiService');
const { generateTextResponse: generateGrokResponse, generateImageForWhatsApp: generateGrokImage } = require('../services/grokService');
const { generateVideoFromImageForWhatsApp: generateKlingVideoFromImage, generateVideoFromVideoForWhatsApp: generateRunwayVideoFromVideo, generateVideoWithTextForWhatsApp: generateKlingVideoFromText } = require('../services/replicateService');
const { generateMusicWithLyrics } = require('../services/musicService');
const speechService = require('../services/speechService');
const { voiceService } = require('../services/voiceService');
const { audioConverterService } = require('../services/audioConverterService');
const { creativeAudioService } = require('../services/creativeAudioService');
const conversationManager = require('../services/conversationManager');
const { routeIntent } = require('../services/intentRouter');
const { executeAgentQuery } = require('../services/agentService');
const authStore = require('../store/authStore');
const groupAuthStore = require('../store/groupAuthStore');
const fs = require('fs');
const path = require('path');
const os = require('os');
const { exec } = require('child_process');
const { promisify } = require('util');
const execAsync = promisify(exec);

// Message deduplication cache - prevent processing duplicate messages
const processedMessages = new Set();

// Chat history limit for context retrieval
const CHAT_HISTORY_LIMIT = 30;

// Voice transcription and media authorization are managed through PostgreSQL database

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• SHARED REGEX PATTERNS (Avoid Duplication) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Image edit detection patterns (Hebrew + English with ALL conjugations)
const IMAGE_EDIT_PATTERN = /×©× ×”|×ª×©× ×”|×ª×©× ×™|×©× ×™|×¢×¨×•×š|×ª×¢×¨×•×š|×¢×¨×›×™|×¢×“×›×Ÿ|×ª×¢×“×›×Ÿ|×ª×§×Ÿ|×ª×ª×§×Ÿ|×¡×“×¨|×ª×¡×“×¨|×¡×“×¨×™|×ª×¡×“×¨×™|×”×•×¡×£|×ª×•×¡×™×£|×ª×•×¡×™×¤×™|×”×•×¡×™×¤×™|××—×§|×ª××—×§|××—×§×™|×ª××—×§×™|×”×•×¨×“|×ª×•×¨×™×“|×”×•×¨×™×“×™|×ª×•×¨×™×“×™|×¡×™×¨|×ª×¡×™×¨|×¡×™×¨×™|×ª×¡×™×¨×™|×¦×™×™×¨|×ª×¦×™×™×¨|×¦×™×™×¨×™|×ª×¦×¨×™|×”×¤×•×š|×ª×”×¤×•×š|×”××¨|×ª×”××¨|×©×¤×¨|×ª×©×¤×¨|×©×¤×¨×™|×ª×©×¤×¨×™|×ª×—×œ×™×£|×”×—×œ×£|×”×—×œ×™×¤×™|×ª×—×œ×™×¤×™|×¦×•×¨|×ª×¦×•×¨|×¦×•×¨×™|×ª×¦×¨×™|edit|change|modify|update|fix|correct|add|remove|delete|draw|paint|replace|swap|improve|enhance|create|make|transform/i;

// Implicit edit pattern (wearing/dressed patterns)
const IMAGE_IMPLICIT_EDIT_PATTERN = /^(×œ×‘×•×©|×œ×‘×•×©×”|×œ×•×‘×©|×œ×•×‘×©×ª|×¢×|×›(?!××”)|×‘×ª×•×¨)|^\b(wearing|dressed|with\s+a|as\s+a|in\s+a)\b/i;

// TTS keywords pattern (for detecting voice output requests)
const TTS_KEYWORDS_PATTERN = /×××•×¨|×××¨×™|×××¨×•|×ª×××¨|×ª×××¨×™|×ª×××¨×•|×”×§×¨×|×”×§×¨××™|×”×§×¨××•|×ª×§×¨×|×ª×§×¨××™|×ª×§×¨××•|×”×§×¨×™×|×”×§×¨×™××™|×”×§×¨×™××•|×ª×§×¨×™×|×ª×§×¨×™××™|×ª×§×¨×™××•|×“×‘×¨|×“×‘×¨×™|×“×‘×¨×•|×ª×“×‘×¨|×ª×“×‘×¨×™|×ª×“×‘×¨×•|×‘×§×•×œ|×§×•×œ×™×ª|\b(say|speak|tell|voice|read\s+aloud)\b/i;

// Translation keywords pattern (for detecting text-only translation)
const TRANSLATE_KEYWORDS_PATTERN = /×ª×¨×’×|×ª×¨×’××™|×ª×¨×’××•|×ª×ª×¨×’×|×ª×ª×¨×’××™|×ª×ª×¨×’××•|×ª×¨×’×•×|\b(translate|translation)\b/i;

// Just transcription pattern (no other processing requested)
const JUST_TRANSCRIPTION_PATTERN = /^(×ª××œ×œ|×ª××œ×™×œ|transcribe|transcript)$/i;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CONSTANTS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Minimum audio duration required for voice cloning (ElevenLabs requirement)
const MIN_DURATION_FOR_CLONING = 4.6; // seconds

// ElevenLabs TTS default settings
const ELEVENLABS_TTS_DEFAULTS = {
  model_id: 'eleven_v3',
  optimize_streaming_latency: 0,
  output_format: 'mp3_44100_128'
};

// Speech-to-text transcription default settings
const TRANSCRIPTION_DEFAULTS = {
  model: 'scribe_v1_experimental', // Excellent multilingual support
  language: null, // Auto-detect (Hebrew, English, Spanish, etc.)
  removeNoise: true,
  removeFiller: true,
  optimizeLatency: 0,
  format: 'ogg' // WhatsApp audio format
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Clean sensitive/large data from objects for logging
 * Removes base64 thumbnails and truncates long strings
 */
function cleanForLogging(obj) {
  if (!obj || typeof obj !== 'object') return obj;
  
  // Create a deep copy to avoid modifying the original
  const cleaned = JSON.parse(JSON.stringify(obj));
  
  function cleanObject(o) {
    for (const key in o) {
      if (o[key] && typeof o[key] === 'object') {
        cleanObject(o[key]);
      } else if (key === 'jpegThumbnail' || key === 'thumbnail') {
        // Replace base64 thumbnails with a short indicator
        if (typeof o[key] === 'string' && o[key].length > 100) {
          o[key] = `[base64 thumbnail: ${o[key].length} chars]`;
        }
      } else if (key === 'vcard' && typeof o[key] === 'string' && o[key].length > 200) {
        // Truncate long vCard fields (contact cards with base64 photos)
        o[key] = `[vCard: ${o[key].length} chars, starts with: ${o[key].substring(0, 100)}...]`;
      } else if ((key === 'downloadUrl' || key === 'url') && typeof o[key] === 'string' && o[key].length > 200) {
        // Truncate long URLs
        o[key] = `[URL: ${o[key].length} chars, starts with: ${o[key].substring(0, 80)}...]`;
      } else if (key === 'data' && typeof o[key] === 'string' && o[key].length > 200) {
        // Truncate long base64 data fields
        o[key] = `[base64 data: ${o[key].length} chars, starts with: ${o[key].substring(0, 50)}...]`;
      }
    }
  }
  
  cleanObject(cleaned);
  return cleaned;
}

/**
 * Check if a location description indicates land (not open water)
 * @param {string} description - Location description from Gemini
 * @returns {boolean} - true if land, false if open water
 */
function isLandLocation(description) {
  const descLower = description.toLowerCase();
  
  // POSITIVE INDICATORS: If any found, immediately accept as land
  // (e.g., "city by the sea" should be accepted)
  const landIndicators = [
    '×¢×™×¨', '×›×¤×¨', '×™×©×•×‘', '××“×™× ×”', '×¨×—×•×‘', '×©×›×•× ×”', '××–×•×¨', '××—×•×–', '××“×‘×¨', '×”×¨', '×¢××§', '×™×¢×¨',
    'city', 'town', 'village', 'country', 'street', 'district', 'region', 'province', 
    'desert', 'mountain', 'valley', 'forest', 'park', 'road', 'highway', 'building',
    'neighborhood', 'settlement', 'capital', 'state', 'county', 'rural', 'urban', 'population'
  ];
  
  const hasLandIndicator = landIndicators.some(indicator => descLower.includes(indicator));
  
  if (hasLandIndicator) {
    return true; // Strong land indicator - accept!
  }
  
  // NEGATIVE INDICATORS: Only reject if OPEN WATER (not coastal areas)
  const openWaterKeywords = [
    '××•×§×™×™× ×•×¡', '×‘××•×§×™×™× ×•×¡', '×‘×××¦×¢ ×”××•×§×™×™× ×•×¡', '×‘×××¦×¢ ×”×™×', '×‘×œ×‘ ×”×™×',
    'in the ocean', 'in the middle of the ocean', 'in the middle of the sea',
    'open water', 'open ocean', 'deep water', 'deep ocean', 'open sea',
    'atlantic ocean', 'pacific ocean', 'indian ocean', 'arctic ocean',
    '××™× ×¤×ª×•×—×™×', '××™× ×¢××•×§×™×', '××™×Ÿ ×™×‘×©×”', 'no land'
  ];
  
  const isOpenWater = openWaterKeywords.some(keyword => descLower.includes(keyword));
  
  return !isOpenWater; // Accept unless it's open water
}

/**
 * Extract requested region/country/city from location prompt
 * Supports flexible Hebrew and English variations
 * IMPROVED: Better city detection, expanded country list, priority handling
 * @param {string} prompt - User prompt (e.g., "# ×©×œ×— ××™×§×•× ×‘××–×•×¨ ×¡×œ×•×‘× ×™×”" or "×©×œ×— ××™×§×•× ×‘×ª×œ ××‘×™×‘")
 * @returns {Promise<Object|null>} - {continentName: string, displayName: string, bounds: Object|null, isCity: boolean} or null if no match
 */
async function extractRequestedRegion(prompt) {
  if (!prompt || typeof prompt !== 'string') return null;
  
  const promptLower = prompt.toLowerCase();
  console.log(`ğŸ” extractRequestedRegion called with: "${prompt}"`);
  
  // Load country and city bounds from JSON files (loaded once, cached)
  let countryBounds = null;
  let cityBounds = null;
  try {
    countryBounds = require('../utils/countryBounds.json');
  } catch (err) {
    console.warn('âš ï¸ Could not load countryBounds.json:', err.message);
  }
  try {
    cityBounds = require('../utils/cityBounds.json');
  } catch (err) {
    console.warn('âš ï¸ Could not load cityBounds.json:', err.message);
  }
  
  // IMPORTANT: Check for specific city names FIRST (before checking countries)
  // This prevents "×ª×œ ××‘×™×‘" from being incorrectly matched as "××‘×™×‘" (spring)
  const cityKeywords = {
    // Israel
    '×ª×œ ××‘×™×‘': true, 'tel aviv': true, '×ª×œ-××‘×™×‘': true,
    '×™×¨×•×©×œ×™×': true, 'jerusalem': true,
    '×—×™×¤×”': true, 'haifa': true,
    '×‘××¨ ×©×‘×¢': true, 'beer sheva': true, '×‘××¨-×©×‘×¢': true,
    '××™×œ×ª': true, 'eilat': true,
    '× ×ª× ×™×”': true, 'netanya': true,
    '×¤×ª×— ×ª×§×•×•×”': true, 'petah tikva': true, '×¤×ª×—-×ª×§×•×•×”': true,
    '×¨××©×•×Ÿ ×œ×¦×™×•×Ÿ': true, 'rishon lezion': true, '×¨××©×•×Ÿ-×œ×¦×™×•×Ÿ': true,
    // International major cities
    '× ×™×• ×™×•×¨×§': true, 'new york': true, 'ny': true, 'nyc': true,
    '×œ×•×¡ ×× ×’\'×œ×¡': true, 'los angeles': true, 'la': true,
    '×œ×•× ×“×•×Ÿ': true, 'london': true,
    '×¤×¨×™×–': true, 'paris': true,
    '×‘×¨×œ×™×Ÿ': true, 'berlin': true,
    '××“×¨×™×“': true, 'madrid': true,
    '×¨×•××': true, 'rome': true,
    '××™×œ×× ×•': true, 'milan': true,
    '×‘×¨×¦×œ×•× ×”': true, 'barcelona': true,
    '×××¡×˜×¨×“×': true, 'amsterdam': true,
    '×˜×•×§×™×•': true, 'tokyo': true,
    '×¡×™××•×œ': true, 'seoul': true,
    '×‘×™×™×’\'×™× ×’': true, 'beijing': true, '×¤×§×™×Ÿ': true,
    '×©× ×’×—××™': true, 'shanghai': true,
    '×“×•×‘××™': true, 'dubai': true,
    '×¡×™× ×’×¤×•×¨': true, 'singapore': true,
    '×”×•× ×’ ×§×•× ×’': true, 'hong kong': true,
    '×‘× ×’×§×•×§': true, 'bangkok': true,
    '××™×¡×˜× ×‘×•×œ': true, 'istanbul': true,
    '×§×”×™×¨': true, 'cairo': true,
    '××•××‘××™': true, 'mumbai': true,
    '×“×œ×”×™': true, 'delhi': true,
    '×¡×™×“× ×™': true, 'sydney': true,
    '××œ×‘×•×¨×Ÿ': true, 'melbourne': true,
    '×˜×•×¨×•× ×˜×•': true, 'toronto': true,
    '×•× ×§×•×‘×¨': true, 'vancouver': true,
    '××›×¡×™×§×• ×¡×™×˜×™': true, 'mexico city': true,
    '×¨×™×• ×“×” ×–\'× ×¨×•': true, 'rio de janeiro': true, 'rio': true,
    '×¡××• ×¤××•×œ×•': true, 'sao paulo': true,
    '×‘×•×× ×•×¡ ××™×™×¨×¡': true, 'buenos aires': true,
    '×§×™×™×¤×˜××•×Ÿ': true, 'cape town': true,
    '×™×•×”× ×¡×‘×•×¨×’': true, 'johannesburg': true,
    '××•×¡×§×‘×”': true, 'moscow': true,
    '×¡× ×˜ ×¤×˜×¨×‘×•×¨×’': true, 'saint petersburg': true, 'st petersburg': true,
    '×•×¨×©×”': true, 'warsaw': true,
    '×¤×¨××’': true, 'prague': true,
    '×‘×•×“×¤×©×˜': true, 'budapest': true,
    '×•×™× ×”': true, 'vienna': true,
    '×¦×™×¨×™×š': true, 'zurich': true,
    '×’\'× ×‘×”': true, 'geneva': true,
    '×‘×¨×™×¡×œ': true, 'brussels': true,
    '××ª×•× ×”': true, 'athens': true,
    '×œ×™×¡×‘×•×Ÿ': true, 'lisbon': true,
    '×§×•×¤× ×”×’×Ÿ': true, 'copenhagen': true,
    '×©×˜×•×§×”×•×œ×': true, 'stockholm': true,
    '××•×¡×œ×•': true, 'oslo': true,
    '×”×œ×¡×™× ×§×™': true, 'helsinki': true,
    '×“×‘×œ×™×Ÿ': true, 'dublin': true
  };
  
  // Check if prompt explicitly mentions a known city (PRIORITY OVER COUNTRIES!)
  let detectedCity = null;
  for (const cityName in cityKeywords) {
    const escapedCityName = cityName.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    // Check for city with various patterns (more lenient for cities)
    const cityPatterns = [
      new RegExp(`\\b${escapedCityName}\\b`, 'i'),  // Standalone word
      new RegExp(`×‘-?${escapedCityName}(?:[^×-×ªa-z]|$)`, 'i'),  // "×‘×ª×œ ××‘×™×‘"
      new RegExp(`×‘××–×•×¨\\s*${escapedCityName}`, 'i'), // "×‘××–×•×¨ ×ª×œ ××‘×™×‘"
      new RegExp(`in\\s+${escapedCityName}`, 'i')  // "in Tel Aviv"
    ];
    
    for (const pattern of cityPatterns) {
      if (pattern.test(promptLower)) {
        console.log(`ğŸ™ï¸ Detected explicit city mention: "${cityName}" - prioritizing over countries`);
        detectedCity = cityName;
        break;
      }
    }
    if (detectedCity) break;
  }
  
  // If a known city was detected, try to get its bounds (prefer hardcoded, then geocoding)
  if (detectedCity) {
    console.log(`ğŸŒ Priority city detected: "${detectedCity}"`);
    
    // STEP 1: Try hardcoded city bounds first (most reliable)
    const detectedCityLower = detectedCity.toLowerCase();
    if (cityBounds && cityBounds[detectedCityLower]) {
      console.log(`âœ… Found hardcoded bounds for city: "${detectedCity}"`);
      return {
        continentName: null, // Cities don't have continents
        displayName: detectedCity,
        bounds: cityBounds[detectedCityLower],
        isCity: true
      };
    }
    
    // STEP 2: Try geocoding as fallback
    try {
      const { getLocationBounds } = require('../services/geminiService');
      const geocodedBounds = await getLocationBounds(detectedCity);
      
      if (geocodedBounds) {
        console.log(`âœ… Found geocoded bounds for priority city: "${detectedCity}"`);
        return {
          continentName: null, // Cities don't have continents
          displayName: geocodedBounds.foundName || detectedCity,
          bounds: geocodedBounds,
          isCity: true
        };
      } else {
        console.warn(`âš ï¸ Could not get bounds for known city "${detectedCity}", will try country search as fallback`);
      }
    } catch (err) {
      console.warn(`âš ï¸ Error geocoding known city "${detectedCity}":`, err.message);
      // Continue to country search as fallback
    }
  }
  
  // Map of countries/regions to continent names (supporting Hebrew and English)
  // Format: 'country_name': {continent: 'Continent Name', display: 'Display Name'}
  // Bounds are loaded from countryBounds.json and added automatically if available
  const regionMap = {
    // Europe
    '×¡×œ×•×‘× ×™×”': {continent: 'Southern Europe', display: '×¡×œ×•×‘× ×™×”'},
    'slovenia': {continent: 'Southern Europe', display: 'Slovenia'},
    '×¡×œ×•×‘×§×™×”': 'Eastern Europe',
    'slovakia': 'Eastern Europe',
    '×¤×•×œ×™×Ÿ': 'Eastern Europe',
    'poland': 'Eastern Europe',
    '×’×¨×× ×™×”': 'Western Europe',
    'germany': 'Western Europe',
    '×¦×¨×¤×ª': 'Western Europe',
    'france': 'Western Europe',
    '×¡×¤×¨×“': 'Southern Europe',
    'spain': 'Southern Europe',
    '××™×˜×œ×™×”': 'Southern Europe',
    'italy': 'Southern Europe',
    '×‘×¨×™×˜× ×™×”': 'UK & Ireland',
    'britain': 'UK & Ireland',
    'uk': 'UK & Ireland',
    '×× ×’×œ×™×”': 'UK & Ireland',
    'england': 'UK & Ireland',
    '×©×•×•×“×™×”': 'Scandinavia',
    'sweden': 'Scandinavia',
    '× ×•×¨×•×•×’×™×”': 'Scandinavia',
    'norway': 'Scandinavia',
    '×“× ××¨×§': 'Scandinavia',
    'denmark': 'Scandinavia',
    '×¤×™× ×œ× ×“': 'Scandinavia',
    'finland': 'Scandinavia',
    '×¨×•×¡×™×”': 'Eastern Europe',
    'russia': 'Eastern Europe',
    '×˜×•×¨×§×™×”': 'Levant & Turkey',
    'turkey': 'Levant & Turkey',
    '×™×•×•×Ÿ': 'Southern Europe',
    'greece': 'Southern Europe',
    '×¤×•×¨×˜×•×’×œ': 'Southern Europe',
    'portugal': 'Southern Europe',
    '×”×•×œ× ×“': 'Western Europe',
    'netherlands': 'Western Europe',
    '×‘×œ×’×™×”': 'Western Europe',
    'belgium': 'Western Europe',
    '×©×•×•×™×¥': 'Western Europe',
    'switzerland': 'Western Europe',
    '××•×¡×˜×¨×™×”': 'Western Europe',
    'austria': 'Western Europe',
    '×¦\'×›×™×”': 'Eastern Europe',
    'czech': 'Eastern Europe',
    '×”×•× ×’×¨×™×”': 'Eastern Europe',
    'hungary': 'Eastern Europe',
    '×¨×•×× ×™×”': 'Eastern Europe',
    'romania': 'Eastern Europe',
    '×‘×•×œ×’×¨×™×”': 'Eastern Europe',
    'bulgaria': 'Eastern Europe',
    '×§×¨×•××˜×™×”': 'Southern Europe',
    'croatia': 'Southern Europe',
    '×¡×¨×‘×™×”': 'Eastern Europe',
    'serbia': 'Eastern Europe',
    '××™×¨×œ× ×“': 'UK & Ireland',
    'ireland': 'UK & Ireland',
    
    // Asia
    '×¡×™×Ÿ': 'China Mainland',
    'china': 'China Mainland',
    '×™×¤×Ÿ': 'Japan',
    'japan': 'Japan',
    '×§×•×¨×™××”': 'Korea',
    'korea': 'Korea',
    '×“×¨×•× ×§×•×¨×™××”': 'Korea',
    'south korea': 'Korea',
    '×”×•×“×•': 'India',
    'india': 'India',
    '×ª××™×œ× ×“': 'Mainland Southeast Asia',
    'thailand': 'Mainland Southeast Asia',
    '×•×™×™×˜× ××': 'Mainland Southeast Asia',
    'vietnam': 'Mainland Southeast Asia',
    '××™× ×“×•× ×–×™×”': 'Indonesia West',
    'indonesia': 'Indonesia West',
    '×¤×™×œ×™×¤×™× ×™×': 'Philippines',
    'philippines': 'Philippines',
    '×¡×™× ×’×¤×•×¨': 'Mainland Southeast Asia',
    'singapore': 'Mainland Southeast Asia',
    '××œ×–×™×”': 'Mainland Southeast Asia',
    'malaysia': 'Mainland Southeast Asia',
    '×¤×§×™×¡×˜×Ÿ': 'Pakistan & Afghanistan',
    'pakistan': 'Pakistan & Afghanistan',
    '××¤×’× ×™×¡×˜×Ÿ': 'Pakistan & Afghanistan',
    'afghanistan': 'Pakistan & Afghanistan',
    
    // Middle East
    '×™×©×¨××œ': 'Levant & Turkey',
    'israel': 'Levant & Turkey',
    '×¤×œ×¡×˜×™×Ÿ': 'Levant & Turkey',
    'palestine': 'Levant & Turkey',
    '×œ×‘× ×•×Ÿ': 'Levant & Turkey',
    'lebanon': 'Levant & Turkey',
    '×¡×•×¨×™×”': 'Levant & Turkey',
    'syria': 'Levant & Turkey',
    '×™×¨×“×Ÿ': 'Levant & Turkey',
    'jordan': 'Levant & Turkey',
    '×¢×¨×‘ ×”×¡×¢×•×“×™×ª': 'Arabian Peninsula',
    'saudi arabia': 'Arabian Peninsula',
    '××™×—×•×“ ×”×××™×¨×•×™×•×ª': 'Arabian Peninsula',
    'uae': 'Arabian Peninsula',
    '××™×¨××Ÿ': 'Iran',
    'iran': 'Iran',
    '×¢×™×¨××§': 'Levant & Turkey',
    'iraq': 'Levant & Turkey',
    
    // North America
    '××¨×¦×•×ª ×”×‘×¨×™×ª': 'Eastern USA',
    'usa': 'Eastern USA',
    'united states': 'Eastern USA',
    '××¨×”"×‘': 'Eastern USA',
    '×§× ×“×”': 'Eastern Canada',
    'canada': 'Eastern Canada',
    '××§×¡×™×§×•': 'Mexico',
    'mexico': 'Mexico',
    
    // South America
    '×‘×¨×–×™×œ': 'Brazil North',
    'brazil': 'Brazil North',
    '××¨×’× ×˜×™× ×”': 'Chile & Argentina',
    'argentina': 'Chile & Argentina',
    '×¦\'×™×œ×”': 'Chile & Argentina',
    'chile': 'Chile & Argentina',
    '×¤×¨×•': 'Andean Countries',
    'peru': 'Andean Countries',
    '×§×•×œ×•××‘×™×”': 'Andean Countries',
    'colombia': 'Andean Countries',
    
    // Africa
    '××¦×¨×™×': 'North Africa',
    'egypt': 'North Africa',
    '××¨×•×§×•': 'North Africa',
    'morocco': 'North Africa',
    '×“×¨×•× ××¤×¨×™×§×”': 'Southern Africa',
    'south africa': 'Southern Africa',
    '× ×™×’×¨×™×”': 'West Africa',
    'nigeria': 'West Africa',
    '×§× ×™×”': 'East Africa',
    'kenya': 'East Africa',
    
    // Oceania
    '××•×¡×˜×¨×œ×™×”': 'Australia',
    'australia': 'Australia',
    '× ×™×• ×–×™×œ× ×“': 'New Zealand',
    'new zealand': 'New Zealand',
    
    // Regional/Continental names - returns MULTIPLE continents when applicable
    // For broader geographic requests, we'll handle these specially to include multiple regions
    '××™×¨×•×¤×”': {continent: 'MULTI_EUROPE', display: '××™×¨×•×¤×”', multiRegions: ['Western Europe', 'Eastern Europe', 'Southern Europe', 'Scandinavia', 'UK & Ireland']},
    'europe': {continent: 'MULTI_EUROPE', display: 'Europe', multiRegions: ['Western Europe', 'Eastern Europe', 'Southern Europe', 'Scandinavia', 'UK & Ireland']},
    '××¡×™×”': {continent: 'MULTI_ASIA', display: '××¡×™×”', multiRegions: ['China Mainland', 'Japan', 'Korea', 'Mainland Southeast Asia', 'India', 'Pakistan & Afghanistan']},
    'asia': {continent: 'MULTI_ASIA', display: 'Asia', multiRegions: ['China Mainland', 'Japan', 'Korea', 'Mainland Southeast Asia', 'India', 'Pakistan & Afghanistan']},
    '××–×¨×— ××¡×™×”': {continent: 'MULTI_EAST_ASIA', display: '××–×¨×— ××¡×™×”', multiRegions: ['China Mainland', 'Japan', 'Korea']},
    'east asia': {continent: 'MULTI_EAST_ASIA', display: 'East Asia', multiRegions: ['China Mainland', 'Japan', 'Korea']},
    '×“×¨×•× ××¡×™×”': {continent: 'India', display: '×“×¨×•× ××¡×™×”'},
    'south asia': {continent: 'India', display: 'South Asia'},
    '×“×¨×•× ××–×¨×— ××¡×™×”': {continent: 'MULTI_SOUTHEAST_ASIA', display: '×“×¨×•× ××–×¨×— ××¡×™×”', multiRegions: ['Mainland Southeast Asia', 'Indonesia West', 'Philippines']},
    'southeast asia': {continent: 'MULTI_SOUTHEAST_ASIA', display: 'Southeast Asia', multiRegions: ['Mainland Southeast Asia', 'Indonesia West', 'Philippines']},
    '××–×¨×— ×”×ª×™×›×•×Ÿ': {continent: 'MULTI_MIDDLE_EAST', display: '××–×¨×— ×”×ª×™×›×•×Ÿ', multiRegions: ['Levant & Turkey', 'Arabian Peninsula', 'Iran']},
    'middle east': {continent: 'MULTI_MIDDLE_EAST', display: 'Middle East', multiRegions: ['Levant & Turkey', 'Arabian Peninsula', 'Iran']},
    '×××¨×™×§×”': {continent: 'MULTI_AMERICAS', display: '×××¨×™×§×”', multiRegions: ['Eastern USA', 'Western USA', 'Eastern Canada', 'Western Canada', 'Mexico', 'Brazil North', 'Brazil South', 'Chile & Argentina']},
    'america': {continent: 'MULTI_AMERICAS', display: 'America', multiRegions: ['Eastern USA', 'Western USA', 'Eastern Canada', 'Western Canada', 'Mexico', 'Brazil North', 'Brazil South', 'Chile & Argentina']},
    '×¦×¤×•×Ÿ ×××¨×™×§×”': {continent: 'MULTI_NORTH_AMERICA', display: '×¦×¤×•×Ÿ ×××¨×™×§×”', multiRegions: ['Eastern USA', 'Western USA', 'Eastern Canada', 'Western Canada', 'Mexico']},
    'north america': {continent: 'MULTI_NORTH_AMERICA', display: 'North America', multiRegions: ['Eastern USA', 'Western USA', 'Eastern Canada', 'Western Canada', 'Mexico']},
    '×“×¨×•× ×××¨×™×§×”': {continent: 'MULTI_SOUTH_AMERICA', display: '×“×¨×•× ×××¨×™×§×”', multiRegions: ['Brazil North', 'Brazil South', 'Andean Countries', 'Chile & Argentina']},
    'south america': {continent: 'MULTI_SOUTH_AMERICA', display: 'South America', multiRegions: ['Brazil North', 'Brazil South', 'Andean Countries', 'Chile & Argentina']},
    '××¤×¨×™×§×”': {continent: 'MULTI_AFRICA', display: '××¤×¨×™×§×”', multiRegions: ['North Africa', 'West Africa', 'East Africa', 'Southern Africa']},
    'africa': {continent: 'MULTI_AFRICA', display: 'Africa', multiRegions: ['North Africa', 'West Africa', 'East Africa', 'Southern Africa']},
    '××•×§×™×× ×™×”': {continent: 'MULTI_OCEANIA', display: '××•×§×™×× ×™×”', multiRegions: ['Australia', 'New Zealand']},
    'oceania': {continent: 'MULTI_OCEANIA', display: 'Oceania', multiRegions: ['Australia', 'New Zealand']}
  };
  
  // Search for region keywords in prompt
  // Support patterns like: "×‘××–×•×¨ X", "×‘-X", "X", "in X", "in region X", etc.
  for (const [regionName, regionData] of Object.entries(regionMap)) {
    // Escape special regex characters in region name
    const escapedRegionName = regionName.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    
    // Check for various patterns
    // Note: \b (word boundary) doesn't work well with Hebrew, so we use more flexible patterns
    const patterns = [
      // Pattern 1: "×‘××–×•×¨ X" or "×‘××–×•×¨X" (with or without space)
      new RegExp(`×‘××–×•×¨\\s*${escapedRegionName}(?:\\s|$|,|\\.|!|\\?|:|\\))`, 'i'),
      // Pattern 2: "×‘-X" or "×‘X" (with or without dash)
      new RegExp(`×‘-?${escapedRegionName}(?:\\s|$|,|\\.|!|\\?|:|\\))`, 'i'),
      // Pattern 3: "X" as standalone word (Hebrew - not part of another word)
      new RegExp(`(?:^|[^×-×ªa-z])${escapedRegionName}(?:[^×-×ªa-z]|$)`, 'i'),
      // Pattern 4: "in X" or "in region X" (English)
      new RegExp(`in\\s+(the\\s+)?(region\\s+of\\s+)?${escapedRegionName}(?:\\s|$|,|\\.|!|\\?|:|\\))`, 'i'),
      // Pattern 5: "in X" (English, simple)
      new RegExp(`in\\s+${escapedRegionName}(?:\\s|$|,|\\.|!|\\?|:|\\))`, 'i')
    ];
    
    // Test each pattern
    for (let i = 0; i < patterns.length; i++) {
      const pattern = patterns[i];
      try {
        if (pattern.test(promptLower)) {
          console.log(`âœ… Pattern ${i + 1} matched: "${pattern.source}" for "${regionName}"`);
          console.log(`âœ… Found region match: "${regionName}" â†’ "${typeof regionData === 'string' ? regionData : regionData.continent}"`);
          // Support both old format (string) and new format (object)
          if (typeof regionData === 'string') {
            // Old format: use continent name as display name
            return {
              continentName: regionData,
              displayName: regionName.charAt(0).toUpperCase() + regionName.slice(1) // Capitalize first letter
            };
          } else {
            // New format: object with continent and display
            // Try to get bounds from countryBounds.json file
            const bounds = countryBounds && countryBounds[regionName] ? countryBounds[regionName] : null;
            
            // If this is a multi-region request (continent/large area), return the list
            if (regionData.multiRegions && Array.isArray(regionData.multiRegions)) {
              return {
                continentName: regionData.continent,
                displayName: regionData.display,
                bounds: bounds, // Usually null for broad regions
                multiRegions: regionData.multiRegions // List of specific regions to include
              };
            }
            
            return {
              continentName: regionData.continent,
              displayName: regionData.display,
              bounds: bounds // Include bounds if available for specific country
            };
          }
        }
      } catch (err) {
        // Skip invalid patterns
        console.warn(`âš ï¸ Pattern ${i + 1} failed for "${regionName}":`, err.message);
      }
    }
  }
  
  // If no country/region found, try to search for a city/location
  console.log(`ğŸ” No country/region found, trying to find city/location in prompt: "${prompt}"`);
  
  // Extract potential location name from prompt
  // Remove common command words first, but preserve location context
  let cleanPrompt = prompt
    .replace(/^(×©×œ×—|×©×œ×—×™|×©×œ×—×•|×ª×©×œ×—|×ª×©×œ×—×™|×ª×©×œ×—×•)\s+(××™×§×•×|location)/i, '')
    .replace(/××™×§×•×\s+(××§×¨××™|random)/gi, '')
    .replace(/location\s+(random|××§×¨××™)/gi, '')
    .replace(/×©×œ×—\s+(××™×§×•×|location)/gi, '')
    .replace(/send\s+(location|××™×§×•×)/gi, '')
    .trim();
  
  // Enhanced patterns for city/location extraction
  // Support: "×‘××–×•×¨ X", "×‘-X", "X", "in X", "near X", etc.
  const locationPatterns = [
    /×‘××–×•×¨\s+(.+?)(?:\s|$|,|\.|!|\?|:|\))/i,           // "×‘××–×•×¨ ×ª×œ ××‘×™×‘"
    /×‘××–×•×¨\s*(.+?)$/i,                                  // "×‘××–×•×¨ ×ª×œ ××‘×™×‘" (end of string)
    /×‘-?(.+?)(?:\s|$|,|\.|!|\?|:|\))/i,                 // "×‘×ª×œ ××‘×™×‘" or "×‘-×ª×œ ××‘×™×‘"
    /×‘-?(.+?)$/i,                                       // "×‘×ª×œ ××‘×™×‘" (end of string)
    /in\s+(?:the\s+)?(?:area\s+of\s+)?(.+?)(?:\s|$|,|\.|!|\?|:|\))/i,  // "in Barcelona" or "in the area of Paris"
    /in\s+(?:the\s+)?(.+?)$/i,                          // "in Barcelona" (end of string)
    /near\s+(.+?)(?:\s|$|,|\.|!|\?|:|\))/i,            // "near Tokyo"
    /near\s+(.+?)$/i,                                    // "near Tokyo" (end of string)
    /^([×-×ªa-z]+(?:\s+[×-×ªa-z]+)*)$/i                   // Just location name (Hebrew/English words only)
  ];
  
  // Words to skip (too common or not locations)
  const skipWords = new Set([
    '×©×œ×—', '××™×§×•×', '××§×¨××™', 'location', 'random', 'send', 'in', 'the', 'region', 'of', 
    '××–×•×¨', '×‘', '×‘××–×•×¨', 'near', 'area', '××ª', '××ª×”', '××ª×™', '××ª×', '××ª×Ÿ',
    'the', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were'
  ]);
  
  let locationName = null;
  for (const pattern of locationPatterns) {
    const match = cleanPrompt.match(pattern);
    if (match && match[1]) {
      const candidate = match[1].trim();
      // Skip if too short, is a skip word, or contains only numbers/special chars
      if (candidate.length >= 2 && 
          !skipWords.has(candidate.toLowerCase()) &&
          /[×-×ªa-z]/.test(candidate)) { // Must contain at least one letter
        locationName = candidate;
        console.log(`ğŸŒ Extracted location name: "${locationName}" from pattern: ${pattern.source}`);
        break;
      }
    }
  }
  
  // If we found a potential location name, try to geocode it
  if (locationName) {
    console.log(`ğŸŒ Attempting to geocode city/location: "${locationName}"`);
    try {
      const { getLocationBounds } = require('../services/geminiService');
      const cityBounds = await getLocationBounds(locationName);
      
      if (cityBounds) {
        console.log(`âœ… Found city/location bounds for "${locationName}"`);
        return {
          continentName: null, // City doesn't have a continent
          displayName: locationName,
          bounds: cityBounds,
          isCity: true // Flag to indicate this is a city, not a country
        };
      }
    } catch (err) {
      console.warn(`âš ï¸ Error geocoding "${locationName}":`, err.message);
    }
  }
  
  console.log(`âŒ No region/city found in prompt: "${prompt}"`);
  return null; // No region found
}

/**
 * Save last executed command for retry functionality (persisted to DB)
 * @param {string} chatId - Chat ID
 * @param {Object} decision - Router decision object
 * @param {Object} options - Additional options (imageUrl, videoUrl, normalized)
 */
async function saveLastCommand(chatId, decision, options = {}) {
  // Don't save retry, clarification, or denial commands
  if (['retry_last_command', 'ask_clarification', 'deny_unauthorized'].includes(decision.tool)) {
    return;
  }
  
  // Save to database for persistence across restarts
  await conversationManager.saveLastCommand(chatId, decision.tool, decision.args, {
    normalized: options.normalized,
    imageUrl: options.imageUrl,
    videoUrl: options.videoUrl,
    audioUrl: options.audioUrl
  });
}

// Provider override helper for retry (supports Hebrew/English variants)
function applyProviderOverride(additionalInstructions, currentDecision, context = {}) {
  if (!additionalInstructions || !additionalInstructions.trim()) return null;

  const text = additionalInstructions.toLowerCase();
  const wantsOpenAI = /openai|××•×•×¤× ××™|××•×¤×Ÿ ××™×™/i.test(additionalInstructions);
  const wantsGemini = /gemini|×’×³××™× ×™|×’××™× ×™|×’×™××™× ×™/i.test(additionalInstructions);
  const wantsGrok   = /grok|×’×¨×•×§/i.test(additionalInstructions);
  const wantsSora   = /sora|×¡×•×¨×”/i.test(additionalInstructions);
  const wantsVeo    = /veo\s*3?(?:\.\d+)?|veo|×•×™×•|×•Ö¶××•/i.test(additionalInstructions);
  const wantsKling  = /kling|×§×œ×™× ×’/i.test(additionalInstructions);

  // Sora model variants
  const wantsSoraPro = /sora\s*2\s*pro|sora-2-pro|×¡×•×¨×”\s*2\s*×¤×¨×•|×¡×•×¨×”-?2-?×¤×¨×•/i.test(additionalInstructions);
  const wantsSora2   = /sora\s*2\b|sora-2\b|×¡×•×¨×”\s*2|×¡×•×¨×”-?2/i.test(additionalInstructions);

  // Decide new tool by media context and provider intent
  const { hasImage, hasVideo } = context;
  const originalTool = currentDecision?.tool || '';

  const cloneArgs = (args) => ({ ...(args || {}) });

  // Image-to-video intents with image present
  if (hasImage && (wantsSora || wantsVeo || wantsKling)) {
    if (wantsSora) {
      return {
        tool: 'sora_image_to_video',
        args: { ...cloneArgs(currentDecision.args), model: wantsSoraPro ? 'sora-2-pro' : (wantsSora2 ? 'sora-2' : (currentDecision.args?.model || 'sora-2')), service: 'openai' },
        reason: 'Retry override â†’ Sora image-to-video'
      };
    }
    if (wantsVeo) {
      return {
        tool: 'veo3_image_to_video',
        args: { ...cloneArgs(currentDecision.args), model: currentDecision.args?.model || 'veo-3', service: 'gemini' },
        reason: 'Retry override â†’ Veo image-to-video'
      };
    }
    if (wantsKling) {
      return {
        tool: 'kling_image_to_video',
        args: { ...cloneArgs(currentDecision.args), model: currentDecision.args?.model || 'kling-1', service: 'kling' },
        reason: 'Retry override â†’ Kling image-to-video'
      };
    }
  }

  // Text-to-image
  if (!hasImage && /image|×ª××•× ×”|×¦×™×™×¨|×¦×™×•×¨|×¦×•×¨.*×ª××•× ×”|×ª×™×™×¦×¨.*×ª××•× ×”|×ª×™×™×¦×¨×™.*×ª××•× ×”/i.test(additionalInstructions)) {
    if (wantsOpenAI) return { tool: 'openai_image', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ OpenAI image' };
    if (wantsGemini) return { tool: 'gemini_image', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Gemini image' };
    if (wantsGrok)   return { tool: 'grok_image',   args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Grok image' };
  }

  // Generic provider swap preserving tool family
  
  // Image editing
  if (originalTool.endsWith('_image_edit') || originalTool === 'image_edit') {
    if (wantsOpenAI) return { tool: 'image_edit', args: { ...cloneArgs(currentDecision.args), service: 'openai' }, reason: 'Retry override â†’ OpenAI image edit' };
    if (wantsGemini) return { tool: 'image_edit', args: { ...cloneArgs(currentDecision.args), service: 'gemini' }, reason: 'Retry override â†’ Gemini image edit' };
  }
  
  // Video editing
  if (originalTool.endsWith('_video_edit') || originalTool === 'video_to_video') {
    if (wantsSora) return { tool: 'video_to_video', args: { ...cloneArgs(currentDecision.args), service: 'openai' }, reason: 'Retry override â†’ Sora video' };
    if (wantsVeo) return { tool: 'video_to_video', args: { ...cloneArgs(currentDecision.args), service: 'gemini' }, reason: 'Retry override â†’ Veo video' };
    if (wantsKling) return { tool: 'video_to_video', args: { ...cloneArgs(currentDecision.args), service: 'kling' }, reason: 'Retry override â†’ Kling video' };
  }
  
  // Image generation (not editing)
  if (originalTool.endsWith('_image') && !originalTool.endsWith('_image_edit')) {
    if (wantsOpenAI) return { tool: 'openai_image', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ OpenAI image' };
    if (wantsGemini) return { tool: 'gemini_image', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Gemini image' };
    if (wantsGrok)   return { tool: 'grok_image',   args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Grok image' };
  }

  // Image-to-video
  if (originalTool.endsWith('_image_to_video')) {
    if (wantsSora)   return { tool: 'sora_image_to_video',  args: { ...cloneArgs(currentDecision.args), model: wantsSoraPro ? 'sora-2-pro' : (wantsSora2 ? 'sora-2' : (currentDecision.args?.model || 'sora-2')) }, reason: 'Retry override â†’ Sora image-to-video' };
    if (wantsVeo)    return { tool: 'veo3_image_to_video',  args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Veo image-to-video' };
    if (wantsKling)  return { tool: 'kling_image_to_video', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Kling image-to-video' };
  }
  
  // Text-to-video
  if (originalTool.endsWith('_video') || originalTool === 'kling_text_to_video') {
    if (wantsSora)   return { tool: 'sora_video',  args: { ...cloneArgs(currentDecision.args), model: wantsSoraPro ? 'sora-2-pro' : (wantsSora2 ? 'sora-2' : (currentDecision.args?.model || 'sora-2')) }, reason: 'Retry override â†’ Sora text-to-video' };
    if (wantsVeo)    return { tool: 'veo3_video',  args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Veo text-to-video' };
    if (wantsKling)  return { tool: 'kling_text_to_video', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Kling text-to-video' };
  }

  // Chat provider swap
  if (originalTool.endsWith('_chat')) {
    if (wantsOpenAI) return { tool: 'openai_chat', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ OpenAI chat' };
    if (wantsGemini) return { tool: 'gemini_chat', args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Gemini chat' };
    if (wantsGrok)   return { tool: 'grok_chat',   args: cloneArgs(currentDecision.args), reason: 'Retry override â†’ Grok chat' };
  }

  return null;
}

/**
 * Format chat history messages for including as context in prompts
 * @param {Array} messages - Array of messages from getChatHistory
 * @returns {string} - Formatted messages string
 */
function formatChatHistoryForContext(messages) {
  if (!messages || messages.length === 0) {
    return '';
  }
  
  let formattedMessages = '';
  messages.forEach((msg, index) => {
    const timestamp = new Date(msg.timestamp * 1000).toLocaleString('he-IL');
    
    // Use WhatsApp display name only (chatName), fallback to phone number
    let sender = '××©×ª××©';
    if (msg.chatName) {
      sender = msg.chatName;
    } else if (msg.sender) {
      // Extract phone number from sender ID (e.g., "972543995202@c.us" -> "972543995202")
      const phoneMatch = msg.sender.match(/^(\d+)@/);
      sender = phoneMatch ? phoneMatch[1] : msg.sender;
    }
    
    const messageText = msg.textMessage || msg.caption || '[××“×™×”]';
    
    formattedMessages += `${index + 1}. ${timestamp} - ${sender}: ${messageText}\n`;
  });
  
  return formattedMessages;
}

/**
 * Check if user is authorized for media creation (images, videos, music)
 * @param {Object} senderData - WhatsApp sender data from Green API
 * @returns {Promise<boolean>} - True if user is authorized
 */
async function isAuthorizedForMediaCreation(senderData) {
  return await authStore.isAuthorizedForMediaCreation(senderData);
}

/**
 * Check if user is authorized for group creation
 * @param {Object} senderData - WhatsApp sender data from Green API
 * @returns {Promise<boolean>} - True if user is authorized
 */
async function isAuthorizedForGroupCreation(senderData) {
  return await groupAuthStore.isAuthorizedForGroupCreation(senderData);
}

/**
 * Check if command requires media creation authorization
 * @param {string} commandType - Command type
 * @returns {boolean} - True if command requires authorization
 */
function requiresMediaAuthorization(commandType) {
  const mediaCommands = [
    'gemini_image',
    'openai_image',
    'grok_image', 
    'veo3_video',
    'kling_text_to_video',
    'kling_image_to_video',
    'veo3_image_to_video',
    'runway_video_to_video',
    'music_generation',
    'text_to_speech',
    'gemini_image_edit',
    'openai_image_edit'
  ];
  return mediaCommands.includes(commandType);
}

/**
 * Check if a command is an admin/management command (should only work from outgoing messages)
 * @param {string} commandType - Command type
 * @returns {boolean} - True if command is admin-only
 */
function isAdminCommand(commandType) {
  const adminCommands = [
    'include_in_transcription',
    'exclude_from_transcription',
    'add_media_authorization',
    'remove_media_authorization',
    'voice_transcription_status',
    'media_creation_status',
    'add_group_authorization',
    'remove_group_authorization',
    'group_creation_status',
    'clear_all_conversations',
    'sync_contacts',
    // New admin shortcuts without explicit name
    'add_media_authorization_current',
    'add_group_authorization_current',
    'include_in_transcription_current'
  ];
  return adminCommands.includes(commandType);
}

/**
 * Send unauthorized access message
 * @param {string} chatId - WhatsApp chat ID
 * @param {string} feature - Feature name (for logging)
 */
async function sendUnauthorizedMessage(chatId, feature) {
  const message = 'ğŸ”’ ×¡×œ×™×—×”, ××™×Ÿ ×œ×š ×”×¨×©××” ×œ×”×©×ª××© ×‘×ª×›×•× ×” ×–×•. ×¤× ×” ×œ×× ×”×œ ×”××¢×¨×›×ª.';
  await sendTextMessage(chatId, message);
  console.log(`ğŸš« Unauthorized access attempt to ${feature}`);
}

// Clean up old processed messages cache every 30 minutes
setInterval(() => {
  if (processedMessages.size > 1000) {
    processedMessages.clear();
    console.log('ğŸ§¹ Cleared processed messages cache');
  }
  // Last commands are now persisted in DB, no need to clean up in-memory cache
}, 30 * 60 * 1000);

/**
 * Send immediate acknowledgment for long-running commands
 */
async function sendAck(chatId, command) {
  let ackMessage = '';
  
  switch (command.type) {
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• AGENT MODE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'agent_query':
      ackMessage = 'ğŸ¤– ×§×™×‘×œ×ª×™! ××¢×‘×“ ×¢× AI Agent ××ª×§×“×...';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CHAT â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'gemini_chat':
      ackMessage = 'ğŸ’¬ ×§×™×‘×œ×ª×™. ××¢×‘×“ ×¢× Gemini...';
      break;
    case 'openai_chat':
      ackMessage = 'ğŸ’¬ ×§×™×‘×œ×ª×™. ××¢×‘×“ ×¢× OpenAI...';
      break;
    case 'grok_chat':
      ackMessage = 'ğŸ’¬ ×§×™×‘×œ×ª×™. ××¢×‘×“ ×¢× Grok...';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'gemini_image':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™! ××™×™×¦×¨ ×ª××•× ×” ×¢× Gemini...';
      break;
    case 'openai_image':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™! ××™×™×¦×¨ ×ª××•× ×” ×¢× OpenAI...';
      break;
    case 'grok_image':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™! ××™×™×¦×¨ ×ª××•× ×” ×¢× Grok...';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VIDEO GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'veo3_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...';
      break;
    case 'sora_video':
      // Check if using Pro model from command.model
      ackMessage = command.model === 'sora-2-pro' 
        ? 'ğŸ¬ ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2 Pro...' 
        : 'ğŸ¬ ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2...';
      break;
    case 'kling_text_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×•×™×“××• ×¢× Kling AI...';
      break;
    case 'veo3_image_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”! ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...';
      break;
    case 'sora_image_to_video':
      // Check if using Pro model from command.model
      ackMessage = command.model === 'sora-2-pro' 
        ? 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”! ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2 Pro...' 
        : 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”! ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2...';
      break;
    case 'kling_image_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”! ×™×•×¦×¨ ×•×™×“××• ×¢× Kling AI...';
      break;
    case 'runway_video_to_video':
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×•×•×™×“××•! ×¢×•×‘×“ ×¢×œ×™×• ×¢× RunwayML Gen4...';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• AUDIO & VOICE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'translate_text':
      ackMessage = 'ğŸŒ ×§×™×‘×œ×ª×™! ××ª×¨×’× ×¢× Gemini...';
      break;
    case 'text_to_speech':
      ackMessage = 'ğŸ—£ï¸ ×§×™×‘×œ×ª×™! ××ª×¨×’× ×•××™×™×¦×¨ ×“×™×‘×•×¨ ×¢× ElevenLabs...';
      break;
    case 'voice_processing':
      ackMessage = 'ğŸ¤ ×§×™×‘×œ×ª×™ ××ª ×”×”×§×œ×˜×”! ××¢×‘×“ ×•××›×™×Ÿ ×ª×©×•×‘×”...';
      break;
    case 'voice_generation':
      ackMessage = 'ğŸ¤ ×§×™×‘×œ×ª×™! ××™×™×¦×¨ ×§×•×œ ×¢× ElevenLabs...';
      break;
    case 'creative_voice_processing':
      ackMessage = 'ğŸ¨ ×§×™×‘×œ×ª×™ ××ª ×”×”×§×œ×˜×”! ××ª×—×™×œ ×¢×™×‘×•×“ ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™× ×•××•×–×™×§×”...';
      break;
    case 'voice_cloning_response':
      ackMessage = 'ğŸ¤ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×©×™×‘×•×˜ ×§×•×œ ×•×™×¦×™×¨×ª ×ª×’×•×‘×”...';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MUSIC â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'music_generation':
      ackMessage = 'ğŸµ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× Suno AI... ğŸ¶';
      break;
      
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• UTILITIES â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    case 'chat_summary':
      ackMessage = 'ğŸ“ ×§×™×‘×œ×ª×™! ××›×™×Ÿ ×¡×™×›×•× ×”×©×™×—×” ×¢× Gemini...';
      break;
    
    case 'retry_last_command':
      ackMessage = 'ğŸ”„ ×§×™×‘×œ×ª×™! ××¨×™×¥ ×©×•×‘ ××ª ×”×¤×§×•×“×” ×”××—×¨×•× ×”...';
      break;
    
    case 'create_poll':
      ackMessage = command.withRhyme === false 
        ? 'ğŸ“Š ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×¡×§×¨ ×™×¦×™×¨×ª×™...' 
        : 'ğŸ“Š ×§×™×‘×œ×ª×™! ×™×•×¦×¨ ×¡×§×¨ ×™×¦×™×¨×ª×™ ×¢× ×—×¨×•×–×™×...';
      break;
    
    case 'send_random_location':
      ackMessage = 'ğŸŒ ×§×™×‘×œ×ª×™! ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×¢×œ ×›×“×•×¨ ×”××¨×¥...';
      break;
      
    default:
      return; // No ACK needed for this command
  }
  
  try {
    await sendTextMessage(chatId, ackMessage);
    console.log(`âœ… ACK sent for ${command.type}`);
  } catch (error) {
    console.error('âŒ Error sending ACK:', error.message || error);
  }
}

/**
 * WhatsApp Green API Integration Routes
 */

/**
 * Webhook endpoint for receiving WhatsApp messages from Green API
 */
router.post('/webhook', async (req, res) => {
  try {
    // Security check: Verify webhook token
    const token = req.headers['authorization']?.replace('Bearer ', '') ||
                  req.query.token || 
                  req.body.token;
    
    const expectedToken = process.env.GREEN_API_WEBHOOK_TOKEN;
    
    if (!expectedToken) {
      console.error('âŒ GREEN_API_WEBHOOK_TOKEN not configured in environment');
      return res.status(500).json({ error: 'Webhook token not configured' });
    }
    
    if (token !== expectedToken) {
      console.error('âŒ Unauthorized webhook request - invalid token');
      return res.status(401).json({ error: 'Unauthorized' });
    }

    const webhookData = req.body;
    
    // Log full webhook payload for debugging
    console.log(`ğŸ“± Green API webhook: ${webhookData.typeWebhook || 'unknown'} | Type: ${webhookData.messageData?.typeMessage || 'N/A'}`);
    
    // TEMPORARY DEBUG: Log full payload to see what we're missing
    if (webhookData.messageData?.typeMessage) {
      console.log('ğŸ” FULL WEBHOOK PAYLOAD:', JSON.stringify(webhookData, null, 2));
    }

    // Handle different webhook types asynchronously
    if (webhookData.typeWebhook === 'incomingMessageReceived') {
      // Process in background - don't await
      handleIncomingMessage(webhookData).catch(error => {
        console.error('âŒ Error in async webhook processing:', error.message || error);
      });
    } else if (webhookData.typeWebhook === 'outgoingMessageReceived') {
      // Process outgoing messages (commands sent by you)
      handleOutgoingMessage(webhookData).catch(error => {
        console.error('âŒ Error in async outgoing message processing:', error.message || error);
      });
    }

    // Return 200 OK immediately
    res.status(200).json({ status: 'ok' });
  } catch (error) {
    console.error('âŒ Error processing webhook:', error.message || error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

/**
 * Handle quoted (replied) messages
 * Merges quoted message content with current message prompt
 */
async function handleQuotedMessage(quotedMessage, currentPrompt, chatId) {
  try {
    console.log(`ğŸ”— Processing quoted message: ${quotedMessage.stanzaId}`);
    
    // Extract quoted message type and content
    const quotedType = quotedMessage.typeMessage;
    
    // For text messages, combine both texts
    if (quotedType === 'textMessage' || quotedType === 'extendedTextMessage') {
      const quotedText = quotedMessage.textMessage || '';
      const combinedPrompt = `${quotedText}\n\n${currentPrompt}`;
      console.log(`ğŸ“ Combined text prompt: ${combinedPrompt.substring(0, 100)}...`);
      return {
        hasImage: false,
        hasVideo: false,
        prompt: combinedPrompt,
        imageUrl: null,
        videoUrl: null
      };
    }
    
    // For media messages (image/video/audio/sticker), fetch the original message to get downloadUrl
    if (quotedType === 'imageMessage' || quotedType === 'videoMessage' || quotedType === 'audioMessage' || quotedType === 'stickerMessage') {
      console.log(`ğŸ“¸ Quoted ${quotedType}, fetching original message...`);
      
      // getMessage returns the full message with proper downloadUrl
      const originalMessage = await getMessage(chatId, quotedMessage.stanzaId);
      
      if (!originalMessage) {
        throw new Error('Failed to fetch quoted message');
      }
      
      // Extract download URL from the original message
      // Try multiple possible locations in the response structure
      let downloadUrl = null;
      
      if (quotedType === 'imageMessage' || quotedType === 'stickerMessage') {
        downloadUrl = originalMessage.downloadUrl || 
                     originalMessage.fileMessageData?.downloadUrl || 
                     originalMessage.imageMessageData?.downloadUrl ||
                     originalMessage.stickerMessageData?.downloadUrl ||
                     originalMessage.messageData?.fileMessageData?.downloadUrl ||
                     originalMessage.messageData?.imageMessageData?.downloadUrl ||
                     originalMessage.messageData?.stickerMessageData?.downloadUrl;
      } else if (quotedType === 'videoMessage') {
        downloadUrl = originalMessage.downloadUrl || 
                     originalMessage.fileMessageData?.downloadUrl || 
                     originalMessage.videoMessageData?.downloadUrl ||
                     originalMessage.messageData?.fileMessageData?.downloadUrl ||
                     originalMessage.messageData?.videoMessageData?.downloadUrl;
      } else if (quotedType === 'audioMessage') {
        downloadUrl = originalMessage.downloadUrl || 
                     originalMessage.fileMessageData?.downloadUrl || 
                     originalMessage.audioMessageData?.downloadUrl ||
                     originalMessage.messageData?.fileMessageData?.downloadUrl ||
                     originalMessage.messageData?.audioMessageData?.downloadUrl;
      }
      
      if (!downloadUrl) {
        console.log('âš ï¸ No downloadUrl found in originalMessage structure, trying quotedMessage directly...');
        // Fallback: try to get downloadUrl from quotedMessage itself (for outgoing messages)
        if (quotedType === 'imageMessage' || quotedType === 'stickerMessage') {
          downloadUrl = quotedMessage.downloadUrl || 
                       quotedMessage.fileMessageData?.downloadUrl || 
                       quotedMessage.imageMessageData?.downloadUrl ||
                       quotedMessage.stickerMessageData?.downloadUrl;
        } else if (quotedType === 'videoMessage') {
          downloadUrl = quotedMessage.downloadUrl || 
                       quotedMessage.fileMessageData?.downloadUrl || 
                       quotedMessage.videoMessageData?.downloadUrl;
        } else if (quotedType === 'audioMessage') {
          downloadUrl = quotedMessage.downloadUrl || 
                       quotedMessage.fileMessageData?.downloadUrl || 
                       quotedMessage.audioMessageData?.downloadUrl;
        }
        
        if (!downloadUrl) {
          console.log(`âš ï¸ No downloadUrl found for quoted ${quotedType} in getMessage or quotedMessage`);
          throw new Error(`No downloadUrl found for quoted ${quotedType}. Cannot process this quoted media.`);
        }
        console.log(`âœ… Found downloadUrl in quotedMessage (fallback)`);
      }
      
      console.log(`âœ… Found downloadUrl for quoted ${quotedType}`);
      
      // Extract caption from media message (if exists)
      // Caption can be directly on quotedMessage or nested in fileMessageData/imageMessageData
      let originalCaption = null;
      if (quotedType === 'imageMessage' || quotedType === 'stickerMessage') {
        originalCaption = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.imageMessageData?.caption;
      } else if (quotedType === 'videoMessage') {
        originalCaption = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.videoMessageData?.caption;
      }
      
      console.log(`ğŸ“ [handleQuotedMessage] Original caption found: "${originalCaption}"`);
      console.log(`ğŸ“ [handleQuotedMessage] Current prompt (additional): "${currentPrompt}"`);
      
      // If there's a caption with a command (starts with #), merge it with additional instructions
      let finalPrompt = currentPrompt;
      if (originalCaption && /^#\s+/.test(originalCaption.trim())) {
        // Remove # prefix from original caption
        const cleanCaption = originalCaption.trim().replace(/^#\s+/, '');
        // If there are additional instructions, append them
        if (currentPrompt && currentPrompt.trim()) {
          finalPrompt = `${cleanCaption}, ${currentPrompt}`;
          console.log(`ğŸ”— Merged caption with additional instructions: "${finalPrompt.substring(0, 100)}..."`);
        } else {
          finalPrompt = cleanCaption;
        }
      }
      
      // Return the URL directly - let the handler functions download when needed
      return {
        hasImage: quotedType === 'imageMessage' || quotedType === 'stickerMessage',
        hasVideo: quotedType === 'videoMessage',
        hasAudio: quotedType === 'audioMessage',
        prompt: finalPrompt, // Use merged prompt (original caption + additional instructions)
        imageUrl: (quotedType === 'imageMessage' || quotedType === 'stickerMessage') ? downloadUrl : null,
        videoUrl: quotedType === 'videoMessage' ? downloadUrl : null,
        audioUrl: quotedType === 'audioMessage' ? downloadUrl : null
      };
    }
    
    // For other types, just use current prompt
    console.log(`âš ï¸ Unsupported quoted message type: ${quotedType}, using current prompt only`);
    return {
      hasImage: false,
      hasVideo: false,
      hasAudio: false,
      prompt: currentPrompt,
      imageUrl: null,
      videoUrl: null,
      audioUrl: null
    };
    
  } catch (error) {
    console.error('âŒ Error handling quoted message:', error.message);
    
    // If it's a downloadUrl error for bot's own messages, return a clear error
    if (error.message.includes('Cannot process media from bot')) {
      return {
        hasImage: false,
        hasVideo: false,
        hasAudio: false,
        prompt: currentPrompt,
        imageUrl: null,
        videoUrl: null,
        audioUrl: null,
        error: 'âš ï¸ ×œ× ×™×›×•×œ ×œ×¢×‘×“ ×ª××•× ×•×ª/×•×™×“××•/××•×“×™×• ×©×”×‘×•×˜ ×©×œ×—. ×©×œ×— ××ª ×”××“×™×” ××—×“×© ××• ×¦×˜×˜ ×”×•×“×¢×” ×××©×ª××© ××—×¨.'
      };
    }
    
    // For other errors, fallback to current prompt only
    return {
      hasImage: false,
      hasVideo: false,
      hasAudio: false,
      prompt: currentPrompt,
      imageUrl: null,
      videoUrl: null,
      audioUrl: null
    };
  }
}

/**
 * Handle incoming WhatsApp message
 */
async function handleIncomingMessage(webhookData) {
  try {
    const messageData = webhookData.messageData;
    const senderData = webhookData.senderData;
    
    // Extract message ID for deduplication
    let messageId = webhookData.idMessage;
    
    // For edited messages, append suffix to ensure they're processed even if original was processed
    if (messageData.typeMessage === 'editedMessage') {
      messageId = `${messageId}_edited_${Date.now()}`;
      console.log(`âœï¸ Edited message - using unique ID for reprocessing: ${messageId}`);
    }
    
    // Check if we already processed this message
    if (processedMessages.has(messageId)) {
      console.log(`ğŸ”„ Duplicate message detected, skipping: ${messageId}`);
      return;
    }
    
    // Mark message as processed
    processedMessages.add(messageId);
    
    const chatId = senderData.chatId;
    const senderId = senderData.sender;
    const senderName = senderData.senderName || senderId;
    const senderContactName = senderData.senderContactName || "";
    const chatName = senderData.chatName || "";
    
    // Handle text messages (regular, extended, quoted, and edited)
    let messageText = null;
    
    if (messageData.typeMessage === 'textMessage') {
      messageText = messageData.textMessageData?.textMessage;
    } else if (messageData.typeMessage === 'extendedTextMessage') {
      messageText = messageData.extendedTextMessageData?.text;
    } else if (messageData.typeMessage === 'quotedMessage') {
      // When replying to a message, the text is in extendedTextMessageData
      messageText = messageData.extendedTextMessageData?.text;
      // BUT: If this is actually an image/video/sticker with caption (not a reply), extract the caption
      if (!messageText) {
        messageText = messageData.fileMessageData?.caption || 
                     messageData.imageMessageData?.caption || 
                     messageData.videoMessageData?.caption ||
                     messageData.stickerMessageData?.caption;
      }
    } else if (messageData.typeMessage === 'editedMessage') {
      // Handle edited messages - treat them as regular messages
      messageText = messageData.editedMessageData?.textMessage;
      console.log(`âœï¸ Edited message detected: "${messageText}"`);
    }
    
    // Enhanced logging for incoming messages
    console.log(`ğŸ“± Incoming from ${senderName} | Type: ${messageData.typeMessage}${messageData.typeMessage === 'editedMessage' ? ' âœï¸' : ''}`);
    if (messageText) {
      console.log(`   Text: ${messageText.substring(0, 100)}${messageText.length > 100 ? '...' : ''}`);
    }
    if (messageData.typeMessage === 'imageMessage') {
      const caption = messageData.fileMessageData?.caption || messageData.imageMessageData?.caption;
      console.log(`   Image Caption: ${caption || 'N/A'}`);
    }
    if (messageData.typeMessage === 'stickerMessage') {
      const caption = messageData.fileMessageData?.caption;
      console.log(`   Sticker Caption: ${caption || 'N/A'} (treating as image)`);
    }
    if (messageData.typeMessage === 'videoMessage') {
      const caption = messageData.fileMessageData?.caption || messageData.videoMessageData?.caption;
      console.log(`   Video Caption: ${caption || 'N/A'}`);
    }
    if (messageData.typeMessage === 'quotedMessage' && messageData.quotedMessage) {
      console.log(`   Quoted Message Type: ${messageData.quotedMessage.typeMessage}`);
      if (messageData.quotedMessage.textMessage) {
        console.log(`   Quoted Text: ${messageData.quotedMessage.textMessage.substring(0, 50)}...`);
      }
      if (messageData.quotedMessage.caption) {
        console.log(`   Quoted Caption: ${messageData.quotedMessage.caption.substring(0, 50)}...`);
      }
    }
    
    // Unified intent router for commands that start with "# "
    if (messageText && /^#\s+/.test(messageText.trim())) {
      try {
        // Extract the prompt (remove "# " prefix if exists)
        // For edited messages, # might be removed by WhatsApp/Green API
        const basePrompt = messageText.trim().replace(/^#\s+/, '').trim();
        
        // Check if this is a quoted/replied message
        // Only process quotedMessage if typeMessage is 'quotedMessage' (actual reply)
        // Don't process if it's just extendedTextMessage with leftover quotedMessage metadata
        const quotedMessage = messageData.quotedMessage;
        
        // IMPORTANT: Green API sends images/videos with captions as quotedMessage, but they're NOT actual quotes!
        // Check if this is a REAL quote (reply) or just a media message with caption
        // Logic:
        // - If caption exists AND matches/starts with the text â†’ It's a NEW media message (not a quote)
        // - If caption doesn't exist OR doesn't match â†’ It's a REAL quote
        const quotedCaption = quotedMessage?.caption;
        const extractedText = messageData.extendedTextMessageData?.text; // Don't shadow messageText!
        // Check if caption matches text (exact match OR caption starts with text, covering "# ××” ×–×”..." case)
        const captionMatchesText = quotedCaption && extractedText && 
                                  (quotedCaption === extractedText || 
                                   quotedCaption.startsWith(extractedText) ||
                                   extractedText.startsWith(quotedCaption));
        
        const isActualQuote = messageData.typeMessage === 'quotedMessage' && 
                             quotedMessage && 
                             quotedMessage.stanzaId &&
                             extractedText &&
                             !captionMatchesText; // It's a quote if text doesn't match caption
        
        let finalPrompt = basePrompt;
        let hasImage = messageData.typeMessage === 'imageMessage' || messageData.typeMessage === 'stickerMessage';
        let hasVideo = messageData.typeMessage === 'videoMessage';
        let hasAudio = messageData.typeMessage === 'audioMessage';
        let imageUrl = null;
        let videoUrl = null;
        let audioUrl = null;
        
        if (isActualQuote) {
          console.log(`ğŸ”— Detected quoted message with stanzaId: ${quotedMessage.stanzaId}`);
          
          // Handle quoted message - merge content
          const quotedResult = await handleQuotedMessage(quotedMessage, basePrompt, chatId);
          
          // Check if there was an error processing the quoted message
          if (quotedResult.error) {
            await sendTextMessage(chatId, quotedResult.error);
            return;
          }
          
          finalPrompt = quotedResult.prompt;
          hasImage = quotedResult.hasImage;
          hasVideo = quotedResult.hasVideo;
          hasAudio = quotedResult.hasAudio;
          imageUrl = quotedResult.imageUrl;
          videoUrl = quotedResult.videoUrl;
          audioUrl = quotedResult.audioUrl;
        } else if (messageData.typeMessage === 'quotedMessage' && quotedMessage) {
          // This is a media message (image/video) with caption, NOT an actual quote
          // Extract downloadUrl from the message itself
          console.log(`ğŸ“¸ Media message with caption (not a quote) - Type: ${quotedMessage.typeMessage || 'unknown'}`);
          
          if (quotedMessage.typeMessage === 'imageMessage' || quotedMessage.typeMessage === 'stickerMessage') {
            hasImage = true;
            // Try all possible locations for downloadUrl
            imageUrl = messageData.downloadUrl || 
                      messageData.fileMessageData?.downloadUrl || 
                      messageData.imageMessageData?.downloadUrl ||
                      messageData.stickerMessageData?.downloadUrl ||
                      quotedMessage.downloadUrl ||
                      quotedMessage.fileMessageData?.downloadUrl ||
                      quotedMessage.imageMessageData?.downloadUrl ||
                      quotedMessage.stickerMessageData?.downloadUrl;
            
            // If still not found, try getMessage to fetch the current message's downloadUrl
            if (!imageUrl) {
              console.log('âš ï¸ downloadUrl not found in webhook, fetching from Green API...');
              try {
                const currentMessageId = webhookData.idMessage;
                const originalMessage = await greenApiService.getMessage(chatId, currentMessageId);
                imageUrl = originalMessage?.downloadUrl || 
                          originalMessage?.fileMessageData?.downloadUrl || 
                          originalMessage?.imageMessageData?.downloadUrl;
                console.log(`âœ… downloadUrl fetched from getMessage: ${imageUrl ? 'found' : 'still NOT FOUND'}`);
              } catch (err) {
                console.log(`âŒ Failed to fetch downloadUrl via getMessage: ${err.message}`);
              }
            }
            console.log(`ğŸ“¸ Image with caption detected, final downloadUrl: ${imageUrl ? 'found' : 'NOT FOUND'}`);
          } else if (quotedMessage.typeMessage === 'videoMessage') {
            hasVideo = true;
            videoUrl = messageData.downloadUrl || 
                      messageData.fileMessageData?.downloadUrl || 
                      messageData.videoMessageData?.downloadUrl ||
                      quotedMessage.downloadUrl ||
                      quotedMessage.fileMessageData?.downloadUrl ||
                      quotedMessage.videoMessageData?.downloadUrl;
            
            // If still not found, try getMessage to fetch the current message's downloadUrl
            if (!videoUrl) {
              console.log('âš ï¸ Video downloadUrl not found in webhook, fetching from Green API...');
              try {
                const currentMessageId = webhookData.idMessage;
                const originalMessage = await greenApiService.getMessage(chatId, currentMessageId);
                videoUrl = originalMessage?.downloadUrl || 
                          originalMessage?.fileMessageData?.downloadUrl || 
                          originalMessage?.videoMessageData?.downloadUrl;
                console.log(`âœ… Video downloadUrl fetched from getMessage: ${videoUrl ? 'found' : 'still NOT FOUND'}`);
              } catch (err) {
                console.log(`âŒ Failed to fetch video downloadUrl via getMessage: ${err.message}`);
              }
            }
            console.log(`ğŸ¥ Video with caption detected, final downloadUrl: ${videoUrl ? 'found' : 'NOT FOUND'}`);
          }
        }
        
        const normalized = {
          userText: `# ${finalPrompt}`, // Add back the # prefix for router
          hasImage: hasImage,
          hasVideo: hasVideo,
          hasAudio: hasAudio,
          chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
          language: 'he',
          authorizations: {
            media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
            // group_creation and voice_allowed will be checked only when needed (lazy evaluation)
            group_creation: null,
            voice_allowed: null
          },
          // Pass sender data for lazy authorization checks
          senderData: { senderContactName, chatName, senderName, chatId }
        };

        const decision = await routeIntent(normalized);

        // Router-based direct execution - call services directly
        const rawPrompt = decision.args?.prompt || finalPrompt;
        // Clean prompt from provider mentions before sending to services
        let prompt = cleanPromptFromProviders(rawPrompt);
        
        try {
          // Execute command - loop allows retry to re-execute with updated decision
          let executionAttempts = 0;
          const maxExecutionAttempts = 2; // Allow retry to run command once more
          
          while (executionAttempts < maxExecutionAttempts) {
            executionAttempts++;
            const isRetryExecution = executionAttempts > 1;
            
            if (isRetryExecution) {
              console.log(`ğŸ”„ Retry execution attempt ${executionAttempts} with tool: ${decision.tool}`);
            }
          
          switch (decision.tool) {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• AGENT MODE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'agent_query': {
              // Autonomous agent that can use multiple tools
              console.log(`ğŸ¤– [INCOMING] Agent query detected`);
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'agent_query' });
              
              try {
                const agentResult = await executeAgentQuery(prompt, chatId, {
                  maxIterations: 5
                });
                
                if (agentResult.success) {
                  await sendTextMessage(chatId, agentResult.text);
                  
                  // Log tool usage
                  if (agentResult.toolsUsed && agentResult.toolsUsed.length > 0) {
                    console.log(`ğŸ”§ [Agent] Tools used: ${agentResult.toolsUsed.join(', ')}`);
                  }
                  console.log(`âœ… [Agent] Completed in ${agentResult.iterations} iterations`);
                } else {
                  await sendTextMessage(chatId, `âŒ ${agentResult.error}`);
                }
              } catch (error) {
                console.error('âŒ Error in agent execution:', error);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”: ${error.message}`);
              }
              
              return;
            }
            
            case 'retry_last_command': {
              // Extract any additional instructions after "× ×¡×” ×©×•×‘"
              // Examples: "# × ×¡×” ×©×•×‘, ×¨×§ ×¢× ×©×™×¢×¨ ××¨×•×š", "# ×©×•×‘ ××‘×œ ×‘×œ×™ ××©×§×¤×™×™×"
              const additionalInstructions = basePrompt
                .replace(/^(× ×¡×”\s*×©×•×‘|×©×•×‘|retry|try\s*again)\s*,?\s*/i, '')
                .trim();

              // Check if there's a quoted message with a command
              // Use isActualQuote to avoid false positives from extendedTextMessage metadata
              if (isActualQuote && quotedMessage && quotedMessage.stanzaId) {
                console.log('ğŸ”„ Retry with quoted message - extracting command from quoted message');
                if (additionalInstructions) {
                  console.log(`ğŸ“ Additional instructions to merge: "${additionalInstructions}"`);
                }
                
                // Extract the command from the quoted message
                let quotedText = null;
                if (quotedMessage.typeMessage === 'textMessage' || quotedMessage.typeMessage === 'extendedTextMessage') {
                  quotedText = quotedMessage.textMessage || quotedMessage.extendedTextMessage?.text;
                } else if (quotedMessage.typeMessage === 'imageMessage' || quotedMessage.typeMessage === 'stickerMessage') {
                  quotedText = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.imageMessageData?.caption;
                } else if (quotedMessage.typeMessage === 'videoMessage') {
                  quotedText = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.videoMessageData?.caption;
                }
                
                // Check if quoted message has a command (starts with #)
                if (quotedText && /^#\s+/.test(quotedText.trim())) {
                  console.log(`ğŸ”„ Found command in quoted message: "${quotedText.substring(0, 50)}..."`);
                  // Re-process the quoted message, merging with additional instructions
                  // This allows users to say "# × ×¡×” ×©×•×‘, ×¨×§ ×¢× ×©×™×¢×¨ ××¨×•×š ×™×•×ª×¨"
                  const quotedResult = await handleQuotedMessage(quotedMessage, additionalInstructions, chatId);
                  
                  if (quotedResult.error) {
                    await sendTextMessage(chatId, quotedResult.error);
                    return;
                  }
                  
                  // Re-route with the quoted message content
                  // Use quotedResult.prompt (merged text) instead of quotedText (original only)
                  const retryNormalized = {
                    userText: `# ${quotedResult.prompt}`,
                    hasImage: quotedResult.hasImage,
                    hasVideo: quotedResult.hasVideo,
                    hasAudio: quotedResult.hasAudio,
                    chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
                    language: 'he',
                    authorizations: {
                      media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
                      group_creation: null,
                      voice_allowed: null
                    },
                    senderData: { senderContactName, chatName, senderName, chatId }
                  };
                  
                  console.log(`ğŸ”„ [Retry] Routing with merged prompt | Image:${retryNormalized.hasImage} Video:${retryNormalized.hasVideo}`);
                  
                  const retryDecision = await routeIntent(retryNormalized);
                  console.log(`ğŸ”„ Retry routing decision: ${retryDecision.tool}, reason: ${retryDecision.reason}`);
                  
                  // No need to save here - will be saved automatically when the command executes
                  
                  // Continue with normal execution (don't return here, fall through to execute the command)
                  // Re-assign decision to retryDecision so it executes
                  Object.assign(decision, retryDecision);
                  // Also update imageUrl/videoUrl/audioUrl for media commands
                  imageUrl = quotedResult.imageUrl;
                  videoUrl = quotedResult.videoUrl;
                  audioUrl = quotedResult.audioUrl;
                  hasImage = quotedResult.hasImage;
                  hasVideo = quotedResult.hasVideo;
                  hasAudio = quotedResult.hasAudio;
                } else {
                  await sendTextMessage(chatId, 'â„¹ï¸ ×”×”×•×“×¢×” ×”××¦×•×˜×˜×ª ×œ× ××›×™×œ×” ×¤×§×•×“×”. ×¦×˜×˜ ×”×•×“×¢×” ×©××ª×—×™×œ×” ×‘-"#"');
                  return;
                }
              } else {
                // No quoted message - retry last command from database
                console.log(`ğŸ”„ No quoted message, checking database for last command: ${chatId}`);
                const lastCommand = await conversationManager.getLastCommand(chatId);
                
                if (!lastCommand) {
                  console.log(`âŒ No last command found in database for ${chatId}`);
                  await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ×¤×§×•×“×” ×§×•×“××ª ×œ×‘×™×¦×•×¢ ××—×“×©. × ×¡×” ×œ×©×œ×•×— ×¤×§×•×“×” ×—×“×©×”.');
                  return;
                }
                
                console.log(`ğŸ”„ Found last command: ${lastCommand.tool}`);
                if (additionalInstructions) {
                  console.log(`ğŸ“ Additional instructions: "${additionalInstructions}"`);
                }
                
                // âœ¨ CRITICAL: Check for provider override BEFORE merging prompts
                // This allows "# × ×¡×” ×©×•×‘ ×¢× OpenAI" to change gemini_image â†’ openai_image
                // Restore media URLs first so applyProviderOverride can see the context
                if (lastCommand.imageUrl) {
                  imageUrl = lastCommand.imageUrl;
                  hasImage = true;
                }
                if (lastCommand.videoUrl) {
                  videoUrl = lastCommand.videoUrl;
                  hasVideo = true;
                }
                if (lastCommand.audioUrl) {
                  audioUrl = lastCommand.audioUrl;
                  hasAudio = true;
                }
                
                // Build a decision object from the last command to pass to applyProviderOverride
                const lastCommandDecision = {
                  tool: lastCommand.tool,
                  args: lastCommand.args
                };
                
                // Apply provider override if specified (e.g., "×¢× OpenAI", "with Grok")
                const override = applyProviderOverride(additionalInstructions, lastCommandDecision, { hasImage, hasVideo });
                if (override) {
                  console.log(`ğŸ” Retry with provider override â†’ tool: ${override.tool}, reason: ${override.reason}`);
                  // Use the overridden tool and merge args
                  Object.assign(decision, {
                    tool: override.tool,
                    args: override.args || lastCommand.args,
                    reason: override.reason
                  });
                  
                  // Merge additional instructions with the original prompt if needed
                  // BUT: Remove provider names from the prompt to avoid "OpenAI" appearing in the image
                  if (lastCommand.args?.prompt) {
                    const cleanedInstructions = cleanPromptFromProviders(additionalInstructions);
                    
                    if (cleanedInstructions.trim()) {
                      decision.args.prompt = `${lastCommand.args.prompt}, ${cleanedInstructions}`;
                      console.log(`âœ¨ Merged prompt (cleaned): "${decision.args.prompt}"`);
                    } else {
                      // No additional instructions after cleaning provider names
                      decision.args.prompt = lastCommand.args.prompt;
                      console.log(`âœ¨ Using original prompt (no additional instructions after cleaning)`);
                    }
                  }
                } else {
                  // No provider override - just merge instructions normally
                  let mergedArgs = { ...lastCommand.args };
                  if (additionalInstructions && lastCommand.args?.prompt) {
                    // Append additional instructions to the original prompt
                    mergedArgs.prompt = `${lastCommand.args.prompt}, ${additionalInstructions}`;
                    console.log(`âœ¨ New merged prompt: "${mergedArgs.prompt}"`);
                  }
                  
                  // Re-assign decision to last command with merged args
                  Object.assign(decision, {
                    tool: lastCommand.tool,
                    args: mergedArgs,
                    reason: 'Retry last command with modifications'
                  });
                }
                
                // No need to update timestamp - it's persisted in DB
                
                // Update prompt from decision.args for the re-execution
                prompt = decision.args?.prompt || prompt;
              }
              // Continue to next iteration of while loop to execute the updated command
              continue;
            }
            
            case 'ask_clarification':
              await sendTextMessage(chatId, 'â„¹ï¸ ×œ× ×‘×¨×•×¨ ××” ×œ×‘×¦×¢. ×ª×•×›×œ ×œ×—×“×“ ×‘×‘×§×©×”?');
              return;
              
            case 'deny_unauthorized':
              if (decision.args?.feature && decision.args.feature !== 'voice') {
                await sendUnauthorizedMessage(chatId, decision.args.feature);
              }
              return;
              
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CHAT (Text Generation) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'gemini_chat': {
              // Save command for retry (before execution)
              saveLastCommand(chatId, decision, { imageUrl, videoUrl, normalized });
              
              await sendAck(chatId, { type: 'gemini_chat' });
              
              // Check if this is image analysis (hasImage = true)
              if (normalized.hasImage) {
                try {
                  // Get image URL (either from quoted message or current message)
                  const finalImageUrl = imageUrl || messageData.fileMessageData?.downloadUrl || messageData.imageMessageData?.downloadUrl || messageData.stickerMessageData?.downloadUrl;
                  if (!finalImageUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×ª××•× ×”');
                    return;
                  }
                  
                  // Download and convert to base64
                  const downloadedBuffer = await downloadFile(finalImageUrl);
                  const base64Image = downloadedBuffer.toString('base64');
                  
                  // Check if this is an edit request vs analysis request
                  // Edit requests: ×©× ×”/×ª×©× ×”/×¢×¨×•×š/×ª×¢×¨×•×š/×ª×¡×“×¨/×¡×“×¨/×”×•×¡×£/×ª×•×¡×™×£/××—×§/×ª××—×§/×¦×™×™×¨/×ª×¦×™×™×¨...
                  // Implicit edit: ×œ×‘×•×©/dressed/wearing/×›.../×‘×ª×•×¨...
                  const isEditRequest = IMAGE_EDIT_PATTERN.test(prompt);
                  const isImplicitEdit = IMAGE_IMPLICIT_EDIT_PATTERN.test(prompt);
                  
                  if (isEditRequest || isImplicitEdit) {
                    // This is image EDITING - use editImageForWhatsApp
                    console.log(`ğŸ–¼ï¸ Detected image edit request in gemini_chat, switching to editImageForWhatsApp`);
                    
                    // Check if user wants to reference previous messages
                    let finalPrompt = prompt;
                    if (decision.args?.needsChatHistory) {
                      try {
                        console.log(`ğŸ“œ User requested chat history context for image editing, fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                        const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                        
                        if (chatHistory && chatHistory.length > 0) {
                          const formattedHistory = formatChatHistoryForContext(chatHistory);
                          finalPrompt = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                          console.log(`âœ… Added ${chatHistory.length} messages as context to image editing`);
                        }
                      } catch (historyError) {
                        console.error('âŒ Error fetching chat history:', historyError);
                      }
                    }
                    
                    const editResult = await editImageForWhatsApp(finalPrompt, base64Image);
                    if (editResult.success && editResult.imageUrl) {
                      const fileName = `gemini_edited_${Date.now()}.png`;
                      await sendFileByUrl(chatId, editResult.imageUrl, fileName, editResult.description || '');
                      console.log('ğŸ¨ Edited image sent successfully');
                    } else if (editResult.textResponse) {
                      // Gemini returned text instead of image
                      await sendTextMessage(chatId, `âš ï¸ ${editResult.textResponse}\n\nğŸ’¡ ×”×¦×¢×”: × ×¡×” ×¢× OpenAI - ×©×œ×— "# × ×¡×” ×©×•×‘, ×¢× OpenAI"`);
                      console.log('ğŸ¨ Gemini returned text instead of image, sent suggestion to user');
                    } else {
                      await sendTextMessage(chatId, `âŒ ${editResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×¨×•×š ××ª ×”×ª××•× ×”'}`);
                      console.log('ğŸ¨ Error message sent:', editResult.error);
                    }
                  } else {
                    // This is image ANALYSIS - use analyzeImageWithText
                    const { analyzeImageWithText } = require('../services/geminiService');
                    console.log(`ğŸ” Detected image analysis request in gemini_chat`);
                    
                    // Check if user wants to reference previous messages
                    let finalPrompt = prompt;
                    if (decision.args?.needsChatHistory) {
                      try {
                        console.log(`ğŸ“œ User requested chat history context for image analysis, fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                        const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                        
                        if (chatHistory && chatHistory.length > 0) {
                          const formattedHistory = formatChatHistoryForContext(chatHistory);
                          finalPrompt = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                          console.log(`âœ… Added ${chatHistory.length} messages as context to image analysis`);
                        }
                      } catch (historyError) {
                        console.error('âŒ Error fetching chat history:', historyError);
                      }
                    }
                    
                    const result = await analyzeImageWithText(finalPrompt, base64Image);
                    if (result.success) {
                      await sendTextMessage(chatId, result.text);
                    } else {
                      await sendTextMessage(chatId, `âŒ ${result.error}`);
                    }
                  }
                } catch (error) {
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×ª××•× ×”: ${error.message}`);
                }
              } else if (normalized.hasVideo) {
                // This is video analysis - use analyzeVideoWithText
                const { analyzeVideoWithText } = require('../services/geminiService');
                
                try {
                  // Get video URL (either from quoted message or current message)
                  const finalVideoUrl = videoUrl || messageData.fileMessageData?.downloadUrl || messageData.videoMessageData?.downloadUrl;
                  if (!finalVideoUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×•×™×“××• ×œ× ×™×ª×•×—');
                    return;
                  }
                  
                  // Download video buffer
                  const videoBuffer = await downloadFile(finalVideoUrl);
                  
                  // Check if user wants to reference previous messages
                  let finalPromptVideo = prompt;
                  if (decision.args?.needsChatHistory) {
                    try {
                      console.log(`ğŸ“œ User requested chat history context for video analysis, fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                      const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                      
                      if (chatHistory && chatHistory.length > 0) {
                        const formattedHistory = formatChatHistoryForContext(chatHistory);
                        finalPromptVideo = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                        console.log(`âœ… Added ${chatHistory.length} messages as context to video analysis`);
                      }
                    } catch (historyError) {
                      console.error('âŒ Error fetching chat history:', historyError);
                    }
                  }
                  
                  const result = await analyzeVideoWithText(finalPromptVideo, videoBuffer);
                  if (result.success) {
                    await sendTextMessage(chatId, result.text);
                  } else {
                    await sendTextMessage(chatId, `âŒ ${result.error}`);
                  }
                } catch (error) {
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×•×™×“××•: ${error.message}`);
                }
              } else if (normalized.hasAudio && decision.args?.needsTranscription) {
                // Audio processing with transcription
                console.log('ğŸ¤ Audio message with transcription request');
                
                try {
                  // Get audio URL (either from quoted message or current message)
                  const finalAudioUrl = audioUrl || messageData.fileMessageData?.downloadUrl || messageData.audioMessageData?.downloadUrl;
                  if (!finalAudioUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×”×§×œ×˜×”');
                    return;
                  }
                  
                  // Step 1: Download and transcribe audio
                  console.log('ğŸ”„ Transcribing audio...');
                  const audioBuffer = await downloadFile(finalAudioUrl);
                  
                  const transcriptionOptions = TRANSCRIPTION_DEFAULTS;
                  
                  const transcriptionResult = await speechService.speechToText(audioBuffer, transcriptionOptions);
                  
                  if (transcriptionResult.error) {
                    await sendTextMessage(chatId, `âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×”: ${transcriptionResult.error}`);
                    return;
                  }
                  
                  const transcribedText = transcriptionResult.text;
                  const detectedLanguage = transcriptionResult.detectedLanguage || 'he';
                  console.log(`âœ… Transcription complete: ${transcribedText.length} chars, language: ${detectedLanguage}`);
                  
                  // Step 2: Detect what user wants to do with the transcription
                  const promptLower = prompt.toLowerCase();
                  
                  // Case 1: Just transcription - send transcribed text
                  const isJustTranscription = JUST_TRANSCRIPTION_PATTERN.test(prompt.trim());
                  if (isJustTranscription) {
                    console.log('ğŸ“ Just transcription requested');
                    await sendTextMessage(chatId, `ğŸ“ ×ª××œ×•×œ:\n\n${transcribedText}`);
                    return;
                  }
                  
                  // Case 2: Translation request with TTS - detect target language and voice keywords
                  // Support ALL Hebrew conjugations (male/female/plural) per rule 7
                  const hasTTSKeywords = TTS_KEYWORDS_PATTERN.test(prompt);
                  const hasTextKeywords = TRANSLATE_KEYWORDS_PATTERN.test(prompt) && !hasTTSKeywords;
                  
                  console.log(`ğŸ” Audio processing intent detection - TTS keywords: ${hasTTSKeywords}, Text keywords: ${hasTextKeywords}`);
                  
                  // Detect target language from prompt
                  // Hebrew uses "×‘" prefix (e.g., "×‘×™×¤× ×™×ª" = "in Japanese")
                  // NOTE: Don't use \b before Hebrew words - it doesn't work in JavaScript
                  const languagePatterns = {
                    'en': /(×‘?×× ×’×œ×™×ª|\benglish\b|\bin\s+english\b)/i,
                    'es': /(×‘?×¡×¤×¨×“×™×ª|\bspanish\b|\bin\s+spanish\b)/i,
                    'fr': /(×‘?×¦×¨×¤×ª×™×ª|\bfrench\b|\bin\s+french\b)/i,
                    'de': /(×‘?×’×¨×× ×™×ª|\bgerman\b|\bin\s+german\b)/i,
                    'it': /(×‘?××™×˜×œ×§×™×ª|\bitalian\b|\bin\s+italian\b)/i,
                    'pt': /(×‘?×¤×•×¨×˜×•×’×–×™×ª|\bportuguese\b|\bin\s+portuguese\b)/i,
                    'ru': /(×‘?×¨×•×¡×™×ª|\brussian\b|\bin\s+russian\b)/i,
                    'zh': /(×‘?×¡×™× ×™×ª|×‘?×× ×“×¨×™× ×™×ª|\bchinese\b|\bmandarin\b|\bin\s+chinese\b)/i,
                    'ja': /(×‘?×™×¤× ×™×ª|\bjapanese\b|\bin\s+japanese\b)/i,
                    'ko': /(×‘?×§×•×¨×™×× ×™×ª|\bkorean\b|\bin\s+korean\b)/i,
                    'ar': /(×‘?×¢×¨×‘×™×ª|\barabic\b|\bin\s+arabic\b)/i,
                    'hi': /(×‘?×”×™× ×“×™×ª|\bhindi\b|\bin\s+hindi\b)/i,
                    'tr': /(×‘?×˜×•×¨×§×™×ª|\bturkish\b|\bin\s+turkish\b)/i,
                    'pl': /(×‘?×¤×•×œ× ×™×ª|\bpolish\b|\bin\s+polish\b)/i,
                    'nl': /(×‘?×”×•×œ× ×“×™×ª|\bdutch\b|\bin\s+dutch\b)/i,
                    'sv': /(×‘?×©×•×•×“×™×ª|\bswedish\b|\bin\s+swedish\b)/i,
                    'fi': /(×‘?×¤×™× ×™×ª|\bfinnish\b|\bin\s+finnish\b)/i,
                    'no': /(×‘?× ×•×¨×•×•×’×™×ª|\bnorwegian\b|\bin\s+norwegian\b)/i,
                    'da': /(×‘?×“× ×™×ª|\bdanish\b|\bin\s+danish\b)/i,
                    'cs': /(×‘?×¦'×›×™×ª|\bczech\b|\bin\s+czech\b)/i,
                    'he': /(×‘?×¢×‘×¨×™×ª|\bhebrew\b|\bin\s+hebrew\b)/i
                  };
                  
                  let targetLanguage = null;
                  let targetLanguageCode = null;
                  for (const [code, pattern] of Object.entries(languagePatterns)) {
                    if (pattern.test(prompt)) {
                      targetLanguageCode = code;
                      targetLanguage = prompt.match(pattern)[0];
                      break;
                    }
                  }
                  
                  console.log(`ğŸŒ Language detection - Target: ${targetLanguageCode || 'none'} (${targetLanguage || 'N/A'})`);
                  
                  // Case 3: Translation with TTS (e.g., "# ×××•×¨ ×‘×™×¤× ×™×ª", "# say in Japanese")
                  if (hasTTSKeywords && targetLanguageCode) {
                    console.log(`ğŸ”Š Translation + TTS requested to ${targetLanguageCode}`);
                    
                    // Translate the transcribed text
                    const translationPrompt = `Translate the following text to ${targetLanguage}. Return ONLY the translated text, nothing else:\n\n${transcribedText}`;
                    const translationResult = await generateGeminiResponse(translationPrompt, []);
                    
                    if (translationResult.error) {
                      await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
                      return;
                    }
                    
                    const translatedText = translationResult.text;
                    console.log(`âœ… Translated to ${targetLanguageCode}: ${translatedText.substring(0, 100)}...`);
                    
                    // âœ¨ VOICE CLONING: Try to clone the voice from the quoted audio
                    // Check audio duration and decide whether to clone voice
                    const audioDuration = await getAudioDuration(audioBuffer);
                    let quotedVoiceId = null;
                    let shouldCloneQuotedVoice = audioDuration >= MIN_DURATION_FOR_CLONING;
                    
                    if (shouldCloneQuotedVoice) {
                      console.log(`ğŸ¤ Attempting voice clone (duration: ${audioDuration.toFixed(2)}s >= ${MIN_DURATION_FOR_CLONING}s)...`);
                      
                      const voiceCloneOptions = {
                        name: `WhatsApp Quoted Voice Clone ${Date.now()}`,
                        description: `Voice clone from quoted audio`,
                        removeBackgroundNoise: true,
                        labels: JSON.stringify({
                          accent: 'natural',
                          use_case: 'conversational',
                          quality: 'high',
                          style: 'natural',
                          language: targetLanguageCode
                        })
                      };
                      
                      const voiceCloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
                      
                      if (voiceCloneResult.error) {
                        console.warn(`âš ï¸ Voice cloning failed: ${voiceCloneResult.error}. Falling back to random voice.`);
                        shouldCloneQuotedVoice = false;
                      } else {
                        quotedVoiceId = voiceCloneResult.voiceId;
                        console.log(`âœ… Voice cloned: ${quotedVoiceId} for ${targetLanguageCode}`);
                      }
                    } else {
                      console.log(`â­ï¸ Skipping voice clone (duration: ${audioDuration.toFixed(2)}s < ${MIN_DURATION_FOR_CLONING}s) - will use random voice`);
                    }
                    
                    // If voice wasn't cloned, get random voice for target language
                    if (!shouldCloneQuotedVoice || !quotedVoiceId) {
                      console.log(`ğŸ”„ Getting random voice for ${targetLanguageCode}...`);
                      const voiceResult = await voiceService.getVoiceForLanguage(targetLanguageCode);
                      if (voiceResult.error) {
                        // Fallback: send text if TTS fails
                        await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translatedText}\n\nâš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×§×•×œ: ${voiceResult.error}`);
                        return;
                      }
                      quotedVoiceId = voiceResult.voiceId;
                    }
                    
                    // Generate speech with cloned or random voice
                    const ttsResult = await voiceService.textToSpeech(quotedVoiceId, translatedText, ELEVENLABS_TTS_DEFAULTS);
                    
                    if (!ttsResult.error && ttsResult.audioBuffer) {
                      const conversionResult = await audioConverterService.convertAndSaveAsOpus(ttsResult.audioBuffer, 'mp3');
                      if (conversionResult.success && conversionResult.fileName) {
                        const fullUrl = getStaticFileUrl(conversionResult.fileName);
                        await sendFileByUrl(chatId, fullUrl, conversionResult.fileName, `ğŸŒ ${targetLanguage}`);
                      } else {
                        await sendTextMessage(chatId, `âŒ ${conversionResult.error}`);
                      }
                    } else {
                      await sendTextMessage(chatId, `âŒ ${ttsResult.error || '×©×’×™××” ×‘×™×¦×™×¨×ª ×”×§×•×œ'}`);
                    }
                    return;
                  }
                  
                  // Case 4: Text translation only (e.g., "# ×ª×¨×’× ×œ×©×•×•×“×™×ª")
                  if (hasTextKeywords && targetLanguageCode) {
                    console.log(`ğŸ“ Text translation requested to ${targetLanguageCode}`);
                    
                    const translationPrompt = `Translate the following text to ${targetLanguage}. Return ONLY the translated text, nothing else:\n\n${transcribedText}`;
                    const translationResult = await generateGeminiResponse(translationPrompt, []);
                    
                    if (translationResult.error) {
                      await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
                    } else {
                      await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translationResult.text}`);
                    }
                    return;
                  }
                  
                  // Case 5: General request (summarize, analyze, etc.) - use transcription as context
                  console.log('ğŸ“ General request with transcription');
                  const fullPrompt = `×”×ª××œ×•×œ ×©×œ ×”×”×§×œ×˜×”:\n\n"${transcribedText}"\n\n${prompt}`;
                  
                  const contextMessages = await conversationManager.getConversationHistory(chatId);
                  await conversationManager.addMessage(chatId, 'user', fullPrompt);
                  // Check if Google Search should be used
                  const useGoogleSearchAudio = decision.args?.useGoogleSearch === true;
                  const result = await generateGeminiResponse(fullPrompt, contextMessages, { useGoogleSearch: useGoogleSearchAudio });
                  
                  if (!result.error) {
                    await conversationManager.addMessage(chatId, 'assistant', result.text);
                    await sendTextMessage(chatId, result.text);
                  } else {
                    await sendTextMessage(chatId, `âŒ ${result.error}`);
                  }
                  
                } catch (audioError) {
                  console.error('âŒ Error processing audio:', audioError);
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”××•×“×™×•: ${audioError.message}`);
                }
              } else {
                // Regular text chat
                let finalPrompt = prompt;
                
                // Check if user wants to reference previous messages in the chat/group
                if (decision.args?.needsChatHistory) {
                  try {
                    console.log(`ğŸ“œ User requested chat history context, fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                    const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                    
                    if (chatHistory && chatHistory.length > 0) {
                      const formattedHistory = formatChatHistoryForContext(chatHistory);
                      
                      // Prepend chat history to the prompt
                      finalPrompt = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                      console.log(`âœ… Added ${chatHistory.length} messages as context to prompt`);
                    } else {
                      console.log('âš ï¸ No chat history available, proceeding without context');
                    }
                  } catch (historyError) {
                    console.error('âŒ Error fetching chat history:', historyError);
                    // Continue without history if fetch fails
                  }
                }
                
                const contextMessages = await conversationManager.getConversationHistory(chatId);
                await conversationManager.addMessage(chatId, 'user', finalPrompt);
                // Check if Google Search should be used
                const useGoogleSearch = decision.args?.useGoogleSearch === true;
                const result = await generateGeminiResponse(finalPrompt, contextMessages, { useGoogleSearch });
                if (!result.error) {
                  await conversationManager.addMessage(chatId, 'assistant', result.text);
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              }
              return;
            }
            
            case 'openai_chat': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'openai_chat' });
              const contextMessages = await conversationManager.getConversationHistory(chatId);
              await conversationManager.addMessage(chatId, 'user', prompt);
              const result = await generateOpenAIResponse(prompt, contextMessages);
              if (!result.error) {
                await conversationManager.addMessage(chatId, 'assistant', result.text);
                await sendTextMessage(chatId, result.text);
              } else {
                await sendTextMessage(chatId, `âŒ ${result.error}`);
              }
              return;
            }
            
            case 'grok_chat': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'grok_chat' });
              // Note: Grok doesn't use conversation history (causes issues)
              await conversationManager.addMessage(chatId, 'user', prompt);
              const result = await generateGrokResponse(prompt, []);
              if (!result.error) {
                await conversationManager.addMessage(chatId, 'assistant', result.text);
                await sendTextMessage(chatId, result.text);
              } else {
                await sendTextMessage(chatId, `âŒ ${result.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'gemini_image': {
              saveLastCommand(chatId, decision, { normalized });
              try {
                await sendAck(chatId, { type: 'gemini_image' });
                console.log('ğŸ¨ ACK sent for gemini_image, starting generation...');
                
                const imageResult = await generateImageForWhatsApp(prompt);
                console.log('ğŸ¨ Gemini image generation result:', imageResult.success ? 'SUCCESS' : 'FAILED');
                
                if (imageResult.success && imageResult.imageUrl) {
                  const fileName = `gemini_image_${Date.now()}.png`;
                  const caption = imageResult.description || '';
                  await sendFileByUrl(chatId, imageResult.imageUrl, fileName, caption);
                  console.log('ğŸ¨ Image sent successfully to WhatsApp');
                } else if (imageResult.textResponse) {
                  await sendTextMessage(chatId, imageResult.textResponse);
                  console.log('ğŸ¨ Text response sent instead of image');
                } else {
                  await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
                  console.log('ğŸ¨ Error message sent:', imageResult.error);
                }
              } catch (imageError) {
                console.error('âŒ Error in gemini_image case:', imageError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”: ${imageError.message}`);
              }
              return;
            }
            
            case 'openai_image': {
              saveLastCommand(chatId, decision, { normalized });
              try {
                await sendAck(chatId, { type: 'openai_image' });
                console.log('ğŸ¨ ACK sent for openai_image, starting generation...');
                
                const imageResult = await generateOpenAIImage(prompt);
                console.log('ğŸ¨ OpenAI image generation result:', imageResult.success ? 'SUCCESS' : 'FAILED');
                
                if (imageResult.success && imageResult.imageUrl) {
                  const fileName = `openai_image_${Date.now()}.png`;
                  const caption = imageResult.description || '';
                  await sendFileByUrl(chatId, imageResult.imageUrl, fileName, caption);
                  console.log('ğŸ¨ OpenAI image sent successfully to WhatsApp');
                } else {
                  await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
                  console.log('ğŸ¨ OpenAI error message sent:', imageResult.error);
                }
              } catch (imageError) {
                console.error('âŒ Error in openai_image case:', imageError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”: ${imageError.message}`);
              }
              return;
            }
            
            case 'grok_image': {
              saveLastCommand(chatId, decision, { normalized });
              try {
                // Grok doesn't have image generation - fallback to Gemini
                await sendAck(chatId, { type: 'grok_image' });
                console.log('ğŸ¨ ACK sent for grok_image (fallback to Gemini), starting generation...');
                
                const imageResult = await generateImageForWhatsApp(prompt);
                console.log('ğŸ¨ Grok->Gemini image generation result:', imageResult.success ? 'SUCCESS' : 'FAILED');
                
                if (imageResult.success && imageResult.imageUrl) {
                  const fileName = `gemini_image_${Date.now()}.png`;
                  await sendFileByUrl(chatId, imageResult.imageUrl, fileName, imageResult.description || '');
                  console.log('ğŸ¨ Grok->Gemini image sent successfully to WhatsApp');
                } else {
                  await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
                  console.log('ğŸ¨ Grok->Gemini error message sent:', imageResult.error);
                }
              } catch (imageError) {
                console.error('âŒ Error in grok_image case:', imageError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”: ${imageError.message}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VIDEO GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'veo3_video': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'veo3_video' });
              const videoResult = await generateVideoForWhatsApp(prompt);
              if (videoResult.success && videoResult.videoUrl) {
                await sendFileByUrl(chatId, videoResult.videoUrl, `veo3_video_${Date.now()}.mp4`, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            
            case 'sora_video': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'sora_video', model: decision.args?.model });
              // Pass model from decision args (defaults to sora-2 in the function)
              const options = decision.args?.model ? { model: decision.args.model } : {};
              const videoResult = await generateVideoWithSoraForWhatsApp(prompt, null, options);
              if (videoResult.success && videoResult.videoUrl) {
                const fileName = videoResult.fileName || `sora_video_${Date.now()}.mp4`;
                await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            
            case 'kling_text_to_video': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'kling_text_to_video' });
              const videoResult = await generateKlingVideoFromText(prompt);
              if (videoResult.success && videoResult.videoUrl) {
                const fileName = videoResult.fileName || `kling_video_${Date.now()}.mp4`;
                await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE/VIDEO EDITING â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'veo3_image_to_video':
            case 'sora_image_to_video':
            case 'kling_image_to_video':
              saveLastCommand(chatId, decision, { imageUrl, normalized });
              // Use imageUrl (from quoted message or current message)
              if (hasImage) {
                let service;
                if (decision.tool === 'veo3_image_to_video') {
                  service = 'veo3';
                } else if (decision.tool === 'sora_image_to_video') {
                  service = 'sora';
                } else {
                  service = 'kling';
                }
                const finalImageUrl = imageUrl || (messageData.fileMessageData || messageData.imageMessageData || messageData.stickerMessageData)?.downloadUrl;
                const model = decision.args?.model; // Pass model for Sora Pro/regular
                processImageToVideoAsync({
                  chatId, senderId, senderName,
                  imageUrl: finalImageUrl,
                  prompt: prompt,
                  service: service,
                  model: model
                });
              }
              return;
              
            case 'image_edit':
              saveLastCommand(chatId, decision, { imageUrl, normalized });
              // Use imageUrl (from quoted message or current message)
              if (hasImage) {
                const service = decision.args?.service || 'gemini';
                const finalImageUrl = imageUrl || (messageData.fileMessageData || messageData.imageMessageData || messageData.stickerMessageData)?.downloadUrl;
                processImageEditAsync({
                  chatId, senderId, senderName,
                  imageUrl: finalImageUrl,
                  prompt: decision.args.prompt || prompt,
                  service: service
                });
              }
              return;
              
            case 'video_to_video':
              saveLastCommand(chatId, decision, { videoUrl, normalized });
              // Use videoUrl (from quoted message or current message)
              if (hasVideo) {
                const finalVideoUrl = videoUrl || (messageData.fileMessageData || messageData.videoMessageData)?.downloadUrl;
                processVideoToVideoAsync({
                  chatId, senderId, senderName,
                  videoUrl: finalVideoUrl,
                  prompt: decision.args?.prompt || prompt
                });
              }
              return;
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• TEXT TRANSLATION (NO TTS) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'translate_text': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'translate_text' });
              
              // Detect target language from prompt (e.g., "×ª×¨×’× ×œ×™×¤× ×™×ª: ×˜×§×¡×˜")
              const languagePatterns = {
                'English': /(×œ?×× ×’×œ×™×ª|\bto\s+english\b|\benglish\b)/i,
                'Spanish': /(×œ?×¡×¤×¨×“×™×ª|\bto\s+spanish\b|\bspanish\b)/i,
                'French': /(×œ?×¦×¨×¤×ª×™×ª|\bto\s+french\b|\bfrench\b)/i,
                'German': /(×œ?×’×¨×× ×™×ª|\bto\s+german\b|\bgerman\b)/i,
                'Italian': /(×œ?××™×˜×œ×§×™×ª|\bto\s+italian\b|\bitalian\b)/i,
                'Portuguese': /(×œ?×¤×•×¨×˜×•×’×–×™×ª|\bto\s+portuguese\b|\bportuguese\b)/i,
                'Russian': /(×œ?×¨×•×¡×™×ª|\bto\s+russian\b|\brussian\b)/i,
                'Chinese': /(×œ?×¡×™× ×™×ª|×œ?×× ×“×¨×™× ×™×ª|\bto\s+chinese\b|\bchinese\b|\bmandarin\b)/i,
                'Japanese': /(×œ?×™×¤× ×™×ª|\bto\s+japanese\b|\bjapanese\b)/i,
                'Korean': /(×œ?×§×•×¨×™×× ×™×ª|\bto\s+korean\b|\bkorean\b)/i,
                'Arabic': /(×œ?×¢×¨×‘×™×ª|\bto\s+arabic\b|\barabic\b)/i,
                'Hindi': /(×œ?×”×™× ×“×™×ª|\bto\s+hindi\b|\bhindi\b)/i,
                'Turkish': /(×œ?×˜×•×¨×§×™×ª|\bto\s+turkish\b|\bturkish\b)/i,
                'Polish': /(×œ?×¤×•×œ× ×™×ª|\bto\s+polish\b|\bpolish\b)/i,
                'Dutch': /(×œ?×”×•×œ× ×“×™×ª|\bto\s+dutch\b|\bdutch\b)/i,
                'Swedish': /(×œ?×©×•×•×“×™×ª|\bto\s+swedish\b|\bswedish\b)/i,
                'Finnish': /(×œ?×¤×™× ×™×ª|\bto\s+finnish\b|\bfinnish\b)/i,
                'Norwegian': /(×œ?× ×•×¨×•×•×’×™×ª|\bto\s+norwegian\b|\bnorwegian\b)/i,
                'Danish': /(×œ?×“× ×™×ª|\bto\s+danish\b|\bdanish\b)/i,
                'Czech': /(×œ?×¦'×›×™×ª|\bto\s+czech\b|\bczech\b)/i,
                'Hebrew': /(×œ?×¢×‘×¨×™×ª|\bto\s+hebrew\b|\bhebrew\b)/i
              };
              
              let targetLanguage = 'English'; // Default
              for (const [langName, pattern] of Object.entries(languagePatterns)) {
                if (pattern.test(prompt)) {
                  targetLanguage = langName;
                  break;
                }
              }
              
              // Extract text to translate (remove translation instructions)
              let textToTranslate = prompt
                .replace(/^(×ª×¨×’×|×ª×¨×’××™|×ª×¨×’××•|×ª×ª×¨×’×|translate)\s+/i, '')
                .replace(new RegExp(`(×œ|to)\\s*${targetLanguage}`, 'i'), '')
                .replace(/[:ï¼š]\s*/, '')
                .trim();
              
              // If text is too short, use the full prompt
              if (textToTranslate.length < 2) {
                textToTranslate = prompt;
              }
              
              console.log(`ğŸŒ Text translation: "${textToTranslate}" â†’ ${targetLanguage}`);
              
              // Translate using Gemini
              const translationResult = await translateText(textToTranslate, targetLanguage);
              
              if (translationResult.success) {
                await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translationResult.translatedText}`);
              } else {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• TEXT-TO-SPEECH â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'text_to_speech': {
              // Ensure decision.args.prompt contains the full prompt for retry functionality
              decision.args.prompt = prompt;
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'text_to_speech' });
              
              // Parse the TTS request to check if translation is needed
              // Use full prompt (not decision.args.text) to include quoted message text
              const originalText = prompt;
              const parseResult = await parseTextToSpeechRequest(originalText);
              
              let textToSpeak = parseResult.text;
              let targetLanguageCode = parseResult.languageCode;
              
              // If translation is needed, translate the text first
              if (parseResult.needsTranslation && parseResult.targetLanguage) {
                console.log(`ğŸŒ Translation requested to ${parseResult.targetLanguage}`);
                const translationResult = await translateText(parseResult.text, parseResult.targetLanguage);
                
                if (translationResult.success) {
                  textToSpeak = translationResult.translatedText;
                  console.log(`âœ… Using translated text: "${textToSpeak}"`);
                } else {
                  await sendTextMessage(chatId, `âŒ ${translationResult.error}`);
                  return;
                }
              } else {
                // No translation needed - detect language from original text
                targetLanguageCode = voiceService.detectLanguage(textToSpeak);
              }
              
              // Get appropriate voice for the target language
              const voiceResult = await voiceService.getVoiceForLanguage(targetLanguageCode);
              if (voiceResult.error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×‘×—×™×¨×ª ×§×•×œ: ${voiceResult.error}`);
                return;
              }
              
              const voiceId = voiceResult.voiceId;
              const ttsResult = await voiceService.textToSpeech(voiceId, textToSpeak, {
                modelId: 'eleven_v3',
                outputFormat: 'mp3_44100_128',
                languageCode: targetLanguageCode
              });
              
              if (!ttsResult.error) {
                const conversionResult = await audioConverterService.convertUrlToOpus(ttsResult.audioUrl, 'mp3');
                if (conversionResult.success) {
                  await sendFileByUrl(chatId, getStaticFileUrl(conversionResult.fileName), conversionResult.fileName, '');
                } else {
                  const fallbackUrl = ttsResult.audioUrl.startsWith('http') ? ttsResult.audioUrl : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
                  await sendFileByUrl(chatId, fallbackUrl, `tts_${Date.now()}.mp3`, '');
                }
              } else {
                await sendTextMessage(chatId, `âŒ ${ttsResult.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MUSIC GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'music_generation': {
              saveLastCommand(chatId, decision, { normalized });
              // Parse music request to check if video is requested
              const musicParsing = await parseMusicRequest(prompt);
              const cleanMusicPrompt = musicParsing.cleanPrompt || prompt;
              const wantsVideo = musicParsing.wantsVideo || false;
              
              // Send customized ACK based on whether video is requested
              const ackMsg = wantsVideo 
                ? 'ğŸµğŸ¬ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× ×§×œ×™×¤/×•×™×“××• ×‘×××¦×¢×•×ª Suno AI... ğŸ¶'
                : 'ğŸµ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× Suno AI... ğŸ¶';
              await sendTextMessage(chatId, ackMsg);
              
              const musicResult = await generateMusicWithLyrics(cleanMusicPrompt, {
                callbackUrl: null,
                whatsappContext: { chatId, senderId, senderName },
                makeVideo: wantsVideo
              });
              if (musicResult.error) {
                await sendTextMessage(chatId, `âŒ ${musicResult.error}`);
              } else if (musicResult.message) {
                await sendTextMessage(chatId, musicResult.message);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• POLL CREATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'create_poll': {
              saveLastCommand(chatId, decision, { normalized });
              
              // Check if user explicitly requested NO rhyming
              // Note: \b word boundaries don't work with Hebrew, so we use a more flexible pattern
              const noRhymePatterns = /(×‘×œ×™|×œ×œ×|×œ×|without|no)\s+(×—×¨×™×–×”|×—×¨×•×–×™×|rhyme|rhymes|rhyming)/i;
              const withRhyme = !noRhymePatterns.test(prompt);
              
              await sendAck(chatId, { type: 'create_poll', withRhyme });
              
              // Extract topic from prompt (remove "×¦×•×¨ ×¡×§×¨ ×¢×œ/×‘× ×•×©×" etc.)
              let topic = prompt
                .replace(/^#\s*/, '') // Remove # prefix first
                .replace(/^(×¦×•×¨|×™×¦×¨|×”×›×Ÿ|create|make)\s+(×¡×§×¨|poll)\s+(×¢×œ|×‘× ×•×©×|about)?\s*/i, '')
                .replace(noRhymePatterns, '') // Remove "×‘×œ×™ ×—×¨×™×–×”" etc. from topic
                .trim();
              
              if (!topic || topic.length < 2) {
                topic = prompt; // Use full prompt if extraction failed
              }
              
              const pollResult = await generateCreativePoll(topic, withRhyme);
              
              if (!pollResult.success) {
                await sendTextMessage(chatId, `âŒ ${pollResult.error}`);
                return;
              }
              
              // Send the poll using Green API
              try {
                // Convert options array to Green API format
                const pollOptions = pollResult.options.map(opt => ({ optionName: opt }));
                
                console.log(`ğŸ“Š Sending poll with ${pollOptions.length} ${withRhyme ? 'rhyming' : 'non-rhyming'} options`);
                await sendPoll(chatId, pollResult.question, pollOptions, false);
                console.log(`âœ… Poll sent successfully to ${chatId}`);
              } catch (pollError) {
                console.error('âŒ Error sending poll:', pollError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”×¡×§×¨: ${pollError.message}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• RANDOM LOCATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'send_random_location': {
              saveLastCommand(chatId, decision, { normalized });
              
              // Check if user requested a specific region
              // Use the prompt text (not normalized object) to extract region
              console.log(`ğŸ“ [INCOMING] Extracting region from prompt: "${prompt}"`);
              const requestedRegion = await extractRequestedRegion(prompt);
              const requestedRegionName = requestedRegion ? requestedRegion.continentName : null;
              const displayName = requestedRegion ? requestedRegion.displayName : null;
              const isCity = requestedRegion ? requestedRegion.isCity : false;
              console.log(`ğŸ“ [INCOMING] Extracted region: ${displayName ? `${displayName}${requestedRegionName ? ` (${requestedRegionName})` : isCity ? ' (×¢×™×¨)' : ''}` : 'none'}`);
              const ackMessage = displayName 
                ? `ğŸŒ ×§×™×‘×œ×ª×™! ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ${isCity ? '×‘×¢×™×¨' : '×‘××–×•×¨'} ${displayName}...`
                : 'ğŸŒ ×§×™×‘×œ×ª×™! ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×¢×œ ×›×“×•×¨ ×”××¨×¥...';
              await sendTextMessage(chatId, ackMessage);
              
              // Generate truly random coordinates within populated land areas
              // Using tighter bounding boxes to avoid oceans/seas - subdivided into smaller regions
              // Will retry up to 15 times if location falls in water
              let locationInfo = null;
              let attempts = 0;
              const maxAttempts = 15;
              
              const continents = [
                // EUROPE - subdivided to avoid Mediterranean/Atlantic/Black Sea
                { name: 'Western Europe', minLat: 42, maxLat: 60, minLng: -5, maxLng: 15, weight: 2 },
                { name: 'Eastern Europe', minLat: 44, maxLat: 60, minLng: 15, maxLng: 40, weight: 2 },
                { name: 'Southern Europe', minLat: 36, maxLat: 46, minLng: -9, maxLng: 28, weight: 2 },
                { name: 'Scandinavia', minLat: 55, maxLat: 71, minLng: 5, maxLng: 31, weight: 1 },
                { name: 'UK & Ireland', minLat: 50, maxLat: 60, minLng: -10, maxLng: 2, weight: 1 },
                
                // ASIA - East Asia (subdivided)
                { name: 'China Mainland', minLat: 18, maxLat: 53, minLng: 73, maxLng: 135, weight: 3 },
                { name: 'Japan', minLat: 30, maxLat: 46, minLng: 129, maxLng: 146, weight: 1 },
                { name: 'Korea', minLat: 33, maxLat: 43, minLng: 124, maxLng: 131, weight: 1 },
                
                // ASIA - Southeast Asia (subdivided to avoid Pacific Ocean)
                { name: 'Mainland Southeast Asia', minLat: 5, maxLat: 28, minLng: 92, maxLng: 109, weight: 2 },
                { name: 'Indonesia West', minLat: -11, maxLat: 6, minLng: 95, maxLng: 120, weight: 1 },
                { name: 'Philippines', minLat: 5, maxLat: 19, minLng: 117, maxLng: 127, weight: 1 },
                
                // ASIA - South Asia (tightened to avoid Indian Ocean)
                { name: 'India', minLat: 8, maxLat: 35, minLng: 68, maxLng: 97, weight: 2 },
                { name: 'Pakistan & Afghanistan', minLat: 24, maxLat: 38, minLng: 60, maxLng: 75, weight: 1 },
                
                // MIDDLE EAST (subdivided)
                { name: 'Levant & Turkey', minLat: 31, maxLat: 42, minLng: 26, maxLng: 45, weight: 1 },
                { name: 'Arabian Peninsula', minLat: 12, maxLat: 32, minLng: 34, maxLng: 60, weight: 1 },
                { name: 'Iran', minLat: 25, maxLat: 40, minLng: 44, maxLng: 63, weight: 1 },
                
                // NORTH AMERICA (subdivided to avoid Atlantic/Pacific)
                { name: 'Eastern USA', minLat: 25, maxLat: 50, minLng: -98, maxLng: -67, weight: 2 },
                { name: 'Western USA', minLat: 31, maxLat: 49, minLng: -125, maxLng: -102, weight: 2 },
                { name: 'Eastern Canada', minLat: 43, maxLat: 62, minLng: -95, maxLng: -52, weight: 1 },
                { name: 'Western Canada', minLat: 49, maxLat: 62, minLng: -140, maxLng: -95, weight: 1 },
                
                // CENTRAL AMERICA & MEXICO (tightened)
                { name: 'Mexico', minLat: 14, maxLat: 32, minLng: -118, maxLng: -86, weight: 1 },
                { name: 'Central America', minLat: 7, maxLat: 18, minLng: -93, maxLng: -77, weight: 1 },
                
                // SOUTH AMERICA (subdivided)
                { name: 'Brazil North', minLat: -10, maxLat: 5, minLng: -74, maxLng: -35, weight: 2 },
                { name: 'Brazil South', minLat: -34, maxLat: -10, minLng: -58, maxLng: -35, weight: 1 },
                { name: 'Andean Countries', minLat: -18, maxLat: 12, minLng: -81, maxLng: -66, weight: 1 },
                { name: 'Chile & Argentina', minLat: -55, maxLat: -22, minLng: -75, maxLng: -53, weight: 1 },
                
                // AFRICA (subdivided)
                { name: 'North Africa', minLat: 15, maxLat: 37, minLng: -17, maxLng: 52, weight: 2 },
                { name: 'West Africa', minLat: 4, maxLat: 20, minLng: -17, maxLng: 16, weight: 1 },
                { name: 'East Africa', minLat: -12, maxLat: 16, minLng: 22, maxLng: 51, weight: 1 },
                { name: 'Southern Africa', minLat: -35, maxLat: -15, minLng: 11, maxLng: 42, weight: 1 },
                
                // OCEANIA (tightened)
                { name: 'Australia', minLat: -44, maxLat: -10, minLng: 113, maxLng: 154, weight: 2 },
                { name: 'New Zealand', minLat: -47, maxLat: -34, minLng: 166, maxLng: 179, weight: 1 }
              ];
              
              // Check if specific country/city bounds are available (more precise than continent)
              const hasSpecificBounds = requestedRegion && requestedRegion.bounds;
              const isCityLocation = requestedRegion && requestedRegion.isCity === true;
              
              // Filter continents if specific region requested (but use country/city bounds if available)
              let availableContinents = continents;
              
              // Check if this is a multi-region request (e.g., "Europe", "Asia")
              const hasMultiRegions = requestedRegion && requestedRegion.multiRegions && Array.isArray(requestedRegion.multiRegions);
              
              if (requestedRegionName && !hasSpecificBounds) {
                if (hasMultiRegions) {
                  // Multi-region: filter to multiple specific continents
                  console.log(`ğŸ¯ [INCOMING] Multi-region request: "${displayName}" includes ${requestedRegion.multiRegions.length} regions`);
                  availableContinents = continents.filter(c => requestedRegion.multiRegions.includes(c.name));
                  console.log(`ğŸ¯ [INCOMING] Filtered to ${availableContinents.length} continents: ${availableContinents.map(c => c.name).join(', ')}`);
                  
                  if (availableContinents.length === 0) {
                    console.log(`âš ï¸ [INCOMING] No continents found for multi-region "${displayName}", falling back to all regions`);
                    await sendTextMessage(chatId, `âŒ ×œ× ××¦××ª×™ ××–×•×¨×™× ×¢×‘×•×¨ "${displayName}". ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×‘×›×œ ×”×¢×•×œ×...`);
                    availableContinents = continents; // Fallback to all regions
                  } else {
                    console.log(`âœ… [INCOMING] Multi-region filtered successfully: ${displayName} (${availableContinents.length} regions)`);
                  }
                } else {
                  // Single region/continent
                  console.log(`ğŸ¯ [INCOMING] Filtering continents to region: "${requestedRegionName}"`);
                  console.log(`ğŸ¯ [INCOMING] Available continent names: ${continents.map(c => c.name).join(', ')}`);
                  availableContinents = continents.filter(c => c.name === requestedRegionName);
                  console.log(`ğŸ¯ [INCOMING] Filtered continents count: ${availableContinents.length}`);
                  if (availableContinents.length === 0) {
                    console.log(`âš ï¸ [INCOMING] No continent found matching "${requestedRegionName}", falling back to all regions`);
                    await sendTextMessage(chatId, `âŒ ×œ× ××¦××ª×™ ××–×•×¨ ×‘×©× "${requestedRegionName}". ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×‘×›×œ ×”×¢×•×œ×...`);
                    availableContinents = continents; // Fallback to all regions
                  } else {
                    console.log(`âœ… [INCOMING] Filtered to region: ${requestedRegionName} (${availableContinents.length} continent(s))`);
                  }
                }
              } else if (hasSpecificBounds) {
                if (isCityLocation) {
                  console.log(`ğŸ¯ [INCOMING] Using specific city bounds for ${displayName}: lat ${requestedRegion.bounds.minLat}-${requestedRegion.bounds.maxLat}, lng ${requestedRegion.bounds.minLng}-${requestedRegion.bounds.maxLng}`);
                } else {
                  console.log(`ğŸ¯ [INCOMING] Using specific country bounds for ${displayName}: lat ${requestedRegion.bounds.minLat}-${requestedRegion.bounds.maxLat}, lng ${requestedRegion.bounds.minLng}-${requestedRegion.bounds.maxLng}`);
                }
              } else {
                console.log(`ğŸŒ [INCOMING] No region filter - using all continents`);
              }
              
              // Retry loop to avoid water locations
              // Track if we should use bounds or fallback to continent
              let useBoundsForGeneration = hasSpecificBounds;
              
              while (attempts < maxAttempts && !locationInfo) {
                attempts++;
                console.log(`ğŸ² [INCOMING] Attempt ${attempts}/${maxAttempts} to find land location...`);
                
                let latitude, longitude, regionName;
                
                if (useBoundsForGeneration && requestedRegion && requestedRegion.bounds) {
                  // Use specific country/city bounds with validation
                  const bounds = requestedRegion.bounds;
                  
                  // Validate bounds before using
                  if (bounds && 
                      typeof bounds.minLat === 'number' && typeof bounds.maxLat === 'number' &&
                      typeof bounds.minLng === 'number' && typeof bounds.maxLng === 'number' &&
                      bounds.minLat < bounds.maxLat && bounds.minLng < bounds.maxLng &&
                      bounds.minLat >= -90 && bounds.maxLat <= 90 &&
                      bounds.minLng >= -180 && bounds.maxLng <= 180) {
                    latitude = (Math.random() * (bounds.maxLat - bounds.minLat) + bounds.minLat).toFixed(6);
                    longitude = (Math.random() * (bounds.maxLng - bounds.minLng) + bounds.minLng).toFixed(6);
                    regionName = displayName;
                  } else {
                    console.warn(`âš ï¸ [INCOMING] Invalid bounds detected, falling back to continent-based generation`);
                    useBoundsForGeneration = false; // Fallback to continent-based
                    // Will continue to else block below
                  }
                }
                
                // If bounds were invalid or not available, use continent-based generation
                if (!useBoundsForGeneration || !latitude || !longitude) {
                  // Weighted random selection from continents (some regions more populous than others)
                  const totalWeight = availableContinents.reduce((sum, c) => sum + c.weight, 0);
                  if (totalWeight === 0) {
                    console.error(`âŒ [INCOMING] No available continents, using first continent as fallback`);
                    availableContinents = [continents[0]];
                  }
                  
                  let randomWeight = Math.random() * availableContinents.reduce((sum, c) => sum + c.weight, 0);
                  let selectedContinent = availableContinents[0];
                  
                  for (const continent of availableContinents) {
                    randomWeight -= continent.weight;
                    if (randomWeight <= 0) {
                      selectedContinent = continent;
                      break;
                    }
                  }
                  
                  // Generate random coordinates within the selected region
                  latitude = (Math.random() * (selectedContinent.maxLat - selectedContinent.minLat) + selectedContinent.minLat).toFixed(6);
                  longitude = (Math.random() * (selectedContinent.maxLng - selectedContinent.minLng) + selectedContinent.minLng).toFixed(6);
                  regionName = selectedContinent.name;
                }
                
                console.log(`ğŸŒ [INCOMING] Generated random location in ${regionName}: ${latitude}, ${longitude}`);
                
                // Get location information from Gemini with Google Maps grounding
                const tempLocationInfo = await getLocationInfo(parseFloat(latitude), parseFloat(longitude));
                
                // Check if location is valid (not in water/ocean)
                if (tempLocationInfo.success && tempLocationInfo.description) {
                  if (isLandLocation(tempLocationInfo.description)) {
                    // Valid land location found!
                    locationInfo = { ...tempLocationInfo, latitude, longitude };
                    console.log(`âœ… Found valid land location on attempt ${attempts}`);
                  } else {
                    console.log(`âš ï¸ Location is in open water, retrying... (${tempLocationInfo.description.substring(0, 80)})`);
                  }
                } else {
                  console.log(`âš ï¸ Location info failed, retrying...`);
                }
              }
              
              // If no valid location found after max attempts, use last one anyway
              if (!locationInfo) {
                await sendTextMessage(chatId, `âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ××¦×•× ××™×§×•× ×ª×§×™×Ÿ ××—×¨×™ ${maxAttempts} × ×™×¡×™×•× ×•×ª`);
                return;
              }
              
              // Send the location with description
              try {
                await sendLocation(chatId, parseFloat(locationInfo.latitude), parseFloat(locationInfo.longitude), '', '');
                await sendTextMessage(chatId, `ğŸ“ ${locationInfo.description}`);
                console.log(`âœ… Random location sent to ${chatId}`);
              } catch (locationError) {
                console.error('âŒ Error sending location:', locationError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”××™×§×•×: ${locationError.message}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CHAT SUMMARY â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'chat_summary': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'chat_summary' });
              const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
              if (!chatHistory || chatHistory.length === 0) {
                await sendTextMessage(chatId, 'ğŸ“ ××™×Ÿ ××¡×¤×™×§ ×”×•×“×¢×•×ª ×‘×©×™×—×”');
                return;
              }
              const summaryResult = await generateChatSummary(chatHistory);
              if (!summaryResult.error) {
                await sendTextMessage(chatId, `ğŸ“ **×¡×™×›×•× ×”×©×™×—×”:**\n\n${summaryResult.text}`);
              } else {
                await sendTextMessage(chatId, `âŒ ${summaryResult.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• HELP / COMMAND LIST â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'show_help': {
              const helpText = `
ğŸ¤– **××¢×¨×›×ª AI ××ª×§×“××ª**

**×¤×§×•×“×•×ª AI (××ª×—×™×œ×•×ª ×‘-"# "):**
â€¢ # ×”×™×™ - ×©×™×—×” ×¢× Gemini
â€¢ # ×¦×•×¨ ×ª××•× ×” ×©×œ... - ×™×¦×™×¨×ª ×ª××•× ×”
â€¢ # ×¦×•×¨ ×•×™×“××• ×©×œ... - ×™×¦×™×¨×ª ×•×™×“××•
â€¢ # ×¦×•×¨ ×©×™×¨ ×¢×œ... - ×™×¦×™×¨×ª ××•×–×™×§×”
â€¢ # ×”××¨ ×œ×“×™×‘×•×¨: ×˜×§×¡×˜ - Text-to-Speech
â€¢ # ×¡×›× ×©×™×—×” - ×¡×™×›×•× ×”×©×™×—×”
â€¢ # ×¦×•×¨ ×¡×§×¨ ×¢×œ/×‘× ×•×©×... - ×™×¦×™×¨×ª ×¡×§×¨ ×¢× ×—×¨×•×–×™× (×‘×¨×™×¨×ª ××—×“×œ)
â€¢ # ×¦×•×¨ ×¡×§×¨ ×¢×œ/×‘× ×•×©×... ×‘×œ×™ ×—×¨×™×–×” - ×™×¦×™×¨×ª ×¡×§×¨ ×œ×œ× ×—×¨×•×–×™×
â€¢ # ×©×œ×— ××™×§×•× / # ××™×§×•× ××§×¨××™ - ××™×§×•× ××§×¨××™ ×¢×œ ××¤×ª ×”×¢×•×œ×
â€¢ # × ×¡×” ×©×•×‘ / # ×©×•×‘ - ×‘×™×¦×•×¢ ××—×“×© ×¤×§×•×“×” ××—×¨×•× ×”
â€¢ # ×¦×•×¨/×¤×ª×—/×”×§× ×§×‘×•×¦×” ×‘×©× "×©×" ×¢× ×©×1, ×©×2 - ×™×¦×™×¨×ª ×§×‘×•×¦×”
â€¢ (××•×¤×¦×™×”) + ×¢× ×ª××•× ×” ×©×œ... - ×”×•×¡×¤×ª ×ª××•× ×ª ×¤×¨×•×¤×™×œ
â€¢ ×ª××•× ×” + # ×¢×¨×•×š... - ×¢×¨×™×›×ª ×ª××•× ×”
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×¢×¨×‘×‘/××™×§×¡ - ××™×§×¡ ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™×
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×¢× ×” ×œ×–×”/×ª×’×™×‘ - ×ª×’×•×‘×” ×§×•×œ×™×ª ×¢× ×©×™×‘×•×˜ ×§×•×œ
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×ª××œ×œ - ×ª××œ×•×œ ×‘×œ×‘×“
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×ª×¨×’× ×œ×©×•×•×“×™×ª - ×ª××œ×•×œ + ×ª×¨×’×•× (×˜×§×¡×˜)
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×××•×¨ ×‘×™×¤× ×™×ª - ×ª××œ×•×œ + ×ª×¨×’×•× + TTS
â€¢ ×•×™×“××• + # ×¢×¨×•×š... - ×¢×¨×™×›×ª ×•×™×“××•
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª - ×ª××œ×•×œ ×•×ª×©×•×‘×” ×§×•×œ×™×ª

**×¤×§×•×“×•×ª × ×™×”×•×œ:**
â€¢ ×”×¦×’ ×”×™×¡×˜×•×¨×™×” - ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”
â€¢ ×¡×˜×˜×•×¡ ×™×¦×™×¨×” - ×”×¨×©××•×ª ×™×¦×™×¨×ª ××“×™×”
â€¢ ×”×•×¡×£ ×œ×™×¦×™×¨×” [×©×] - ×”×•×¡×£ ×”×¨×©××ª ××“×™×”
â€¢ ×”×¡×¨ ××™×¦×™×¨×” [×©×] - ×”×¡×¨ ×”×¨×©××ª ××“×™×”
â€¢ ×¡×˜×˜×•×¡ ×§×‘×•×¦×•×ª - ×”×¨×©××•×ª ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª
â€¢ ×”×•×¡×£ ×œ×§×‘×•×¦×•×ª [×©×] - ×”×•×¡×£ ×”×¨×©××ª ×§×‘×•×¦×•×ª
â€¢ ×”×¡×¨ ××§×‘×•×¦×•×ª [×©×] - ×”×¡×¨ ×”×¨×©××ª ×§×‘×•×¦×•×ª
â€¢ ×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨ - ×¡× ×›×¨×•×Ÿ ×× ×©×™ ×§×©×¨
              `;
              await sendTextMessage(chatId, helpText.trim());
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE/VIDEO GENERATION FROM TEXT â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'veo3_image_to_video':
            case 'sora_image_to_video':
            case 'kling_image_to_video': {
              // These require an image - check if one was provided via quoted message
              if (hasImage && imageUrl) {
                let service;
                if (decision.tool === 'veo3_image_to_video') {
                  service = 'veo3';
                } else if (decision.tool === 'sora_image_to_video') {
                  service = 'sora';
                } else {
                  service = 'kling';
                }
                console.log(`ğŸ¬ ${service} image-to-video request from text command (incoming)`);
                const model = decision.args?.model; // Pass model for Sora Pro/regular
                await saveLastCommand(chatId, decision, { imageUrl, normalized });
                processImageToVideoAsync({
                  chatId, senderId, senderName,
                  imageUrl: imageUrl,
                  prompt: prompt,
                  service: service,
                  model: model
                });
              } else {
                await sendTextMessage(chatId, 'âŒ ×¤×§×•×“×” ×–×• ×“×•×¨×©×ª ×ª××•× ×”. ×× × ×¢× ×” ×¢×œ ×”×•×“×¢×” ×¢× ×ª××•× ×” ××• ×©×œ×— ×ª××•× ×” ×¢× caption.');
              }
              return;
            }
            
            case 'veo3_video':
            case 'sora_video':
            case 'kling_text_to_video': {
              saveLastCommand(chatId, decision, { normalized });
              let service;
              if (decision.tool === 'veo3_video') {
                service = 'veo3';
              } else if (decision.tool === 'sora_video') {
                service = 'sora';
              } else {
                service = 'kling';
              }
              console.log(`ğŸ¬ ${service} text-to-video request (incoming)`);
              await sendAck(chatId, { type: decision.tool });
              
              // Text-to-video
              let videoGenFunction;
              if (service === 'veo3') {
                videoGenFunction = generateVideoForWhatsApp;
              } else if (service === 'sora') {
                videoGenFunction = generateVideoWithSoraForWhatsApp;
              } else {
                videoGenFunction = generateKlingVideoFromText;
              }
              
              const result = await videoGenFunction(prompt);
              
              if (result.error) {
                await sendTextMessage(chatId, `âŒ ${result.error}`);
              } else if (result.success && result.videoUrl) {
                const fullUrl = result.videoUrl.startsWith('http') ? result.videoUrl : getStaticFileUrl(result.videoUrl.replace('/static/', ''));
                await sendFileByUrl(chatId, fullUrl, result.fileName, result.description || prompt);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CREATE GROUP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'create_group': {
              saveLastCommand(chatId, decision, { normalized });
              try {
                await sendTextMessage(chatId, 'ğŸ‘¥ ××ª×—×™×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”...');
                
                const { parseGroupCreationPrompt, resolveParticipants } = require('../services/groupService');
                const { createGroup, setGroupPicture } = require('../services/greenApiService');
                const { generateImageForWhatsApp } = require('../services/geminiService');
                
                // Step 1: Parse the prompt to extract group name, participants, and picture description
                await sendTextMessage(chatId, 'ğŸ” ×× ×ª×— ××ª ×”×‘×§×©×”...');
                const parsed = await parseGroupCreationPrompt(prompt);
                
                let statusMsg = `ğŸ“‹ ×©× ×”×§×‘×•×¦×”: "${parsed.groupName}"\nğŸ‘¥ ××—×¤×© ${parsed.participants.length} ××©×ª×ª×¤×™×...`;
                if (parsed.groupPicture) {
                  statusMsg += `\nğŸ¨ ×ª××•× ×”: ${parsed.groupPicture}`;
                }
                await sendTextMessage(chatId, statusMsg);
                
                // Step 2: Resolve participant names to WhatsApp IDs
                const resolution = await resolveParticipants(parsed.participants);
                
                // Check if we found all participants
                if (resolution.notFound.length > 0) {
                  let errorMsg = `âš ï¸ ×œ× ××¦××ª×™ ××ª ×”××©×ª×ª×¤×™× ×”×‘××™×:\n`;
                  resolution.notFound.forEach(name => {
                    errorMsg += `â€¢ ${name}\n`;
                  });
                  errorMsg += `\nğŸ’¡ ×˜×™×¤: ×•×•×“× ×©×”×©××•×ª × ×›×•× ×™× ××• ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ×× ×©×™ ×§×©×¨`;
                  
                  if (resolution.resolved.length === 0) {
                    await sendTextMessage(chatId, errorMsg + '\n\nâŒ ×œ× × ××¦××• ××©×ª×ª×¤×™× - ×‘×™×˜×•×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”');
                    return;
                  }
                  
                  await sendTextMessage(chatId, errorMsg);
                }
                
                // Step 3: Show found participants
                if (resolution.resolved.length > 0) {
                  let foundMsg = `âœ… × ××¦××• ${resolution.resolved.length} ××©×ª×ª×¤×™×:\n`;
                  resolution.resolved.forEach(p => {
                    foundMsg += `â€¢ ${p.searchName} â†’ ${p.contactName}\n`;
                  });
                  await sendTextMessage(chatId, foundMsg);
                }
                
                // Step 4: Create the group
                await sendTextMessage(chatId, 'ğŸ”¨ ×™×•×¦×¨ ××ª ×”×§×‘×•×¦×”...');
                
                // Filter out the current user (group creator) - WhatsApp adds them automatically
                const participantIds = resolution.resolved
                  .map(p => p.contactId)
                  .filter(id => id !== senderId); // Remove group creator from participants list
                
                if (participantIds.length === 0) {
                  await sendTextMessage(chatId, 'âš ï¸ ×œ× × ××¦××• ××©×ª×ª×¤×™× × ×•×¡×¤×™× (×—×•×¥ ×××š). ×¦×¨×™×š ×œ×¤×—×•×ª ××©×ª×ª×£ ××—×“ × ×•×¡×£ ×œ×™×¦×™×¨×ª ×§×‘×•×¦×”.');
                  return;
                }
                
                console.log(`ğŸ‘¥ Final participants (excluding creator ${senderId}): ${participantIds.join(', ')}`);
                const groupResult = await createGroup(parsed.groupName, participantIds);
                
                // Step 5: Generate and set group picture if requested
                if (parsed.groupPicture && groupResult.chatId) {
                  try {
                    await sendTextMessage(chatId, `ğŸ¨ ×™×•×¦×¨ ×ª××•× ×ª ×¤×¨×•×¤×™×œ ×œ×§×‘×•×¦×”...\n"${parsed.groupPicture}"`);
                    
                    // Generate image with Gemini
                    const imageResult = await generateImageForWhatsApp(parsed.groupPicture);
                    
                    if (imageResult.success && imageResult.fileName) {
                      // Read the generated image file
                      const fs = require('fs');
                      const path = require('path');
                      const imagePath = path.join(__dirname, '..', 'public', 'tmp', imageResult.fileName);
                      const imageBuffer = fs.readFileSync(imagePath);
                      
                      // Set as group picture
                      await sendTextMessage(chatId, 'ğŸ–¼ï¸ ××¢×œ×” ×ª××•× ×” ×œ×§×‘×•×¦×”...');
                      const pictureResult = await setGroupPicture(groupResult.chatId, imageBuffer);
                      
                      if (pictureResult.setGroupPicture) {
                        await sendTextMessage(chatId, 'âœ… ×ª××•× ×ª ×”×§×‘×•×¦×” ×”×•×¢×œ×ª×” ×‘×”×¦×œ×—×”!');
                      } else {
                        await sendTextMessage(chatId, `âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×¢×œ×•×ª ×ª××•× ×”: ${pictureResult.reason || '×¡×™×‘×” ×œ× ×™×“×•×¢×”'}`);
                      }
                      
                      // Clean up the image file
                      try {
                        fs.unlinkSync(imagePath);
                        console.log(`ğŸ§¹ Cleaned up group picture file: ${imageResult.fileName}`);
                      } catch (cleanupError) {
                        console.warn('âš ï¸ Could not clean up group picture file:', cleanupError.message);
                      }
                    } else {
                      await sendTextMessage(chatId, `âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”: ${imageResult.error || '×©×’×™××” ×œ× ×™×“×•×¢×”'}`);
                    }
                  } catch (pictureError) {
                    console.error('âŒ Error setting group picture:', pictureError);
                    await sendTextMessage(chatId, `âš ï¸ ×”×§×‘×•×¦×” × ×•×¦×¨×” ××‘×œ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×•×¡×™×£ ×ª××•× ×”: ${pictureError.message}`);
                  }
                }
                
                // Step 6: Success!
                const successMsg = `âœ… ×”×§×‘×•×¦×” "${parsed.groupName}" × ×•×¦×¨×” ×‘×”×¦×œ×—×”! ğŸ‰\n\nğŸ‘¥ ${participantIds.length + 1} ××©×ª×ª×¤×™× ×‘×§×‘×•×¦×” (×›×•×œ×œ ××ª×”)`;
                await sendTextMessage(chatId, successMsg);
                
                console.log(`âœ… Group created successfully by ${senderName}: "${parsed.groupName}" with ${participantIds.length} other participants${parsed.groupPicture ? ' (with picture)' : ''}`);
                
              } catch (error) {
                console.error('âŒ Error creating group:', error);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×§×‘×•×¦×”: ${error.message}\n\nğŸ’¡ ×•×•×“× ×©×”×¤×•×¨××˜ × ×›×•×Ÿ, ×œ×“×•×’××”:\n# ×¦×•×¨/×¤×ª×—/×”×§× ×§×‘×•×¦×” ×‘×©× "×©× ×”×§×‘×•×¦×”" ×¢× ×©×1, ×©×2, ×©×3\n# ×¦×•×¨ ×§×‘×•×¦×” ×‘×©× "×©×" ×¢× ×©×1, ×©×2 ×¢× ×ª××•× ×” ×©×œ ×—×ª×•×œ`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VOICE/AUDIO PROCESSING â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'creative_voice_processing': {
              // Creative audio processing with effects and background music
              if (!audioUrl) {
                await sendTextMessage(chatId, 'âŒ ×œ× × ××¦× ×§×•×‘×¥ ××•×“×™×• ××¦×•×˜×˜. ×¦×˜×˜ ×”×•×“×¢×” ×§×•×œ×™×ª ×•× ×¡×” ×©×•×‘.');
                return;
              }
              
              saveLastCommand(chatId, decision, { audioUrl, normalized });
              await sendAck(chatId, { type: 'creative_voice_processing' });
              
              await handleCreativeVoiceMessage({ chatId, senderId, senderName, audioUrl });
              return;
            }
            
            case 'voice_cloning_response': {
              // Voice cloning with Gemini response
              if (!audioUrl) {
                await sendTextMessage(chatId, 'âŒ ×œ× × ××¦× ×§×•×‘×¥ ××•×“×™×• ××¦×•×˜×˜. ×¦×˜×˜ ×”×•×“×¢×” ×§×•×œ×™×ª ×•× ×¡×” ×©×•×‘.');
                return;
              }
              
              saveLastCommand(chatId, decision, { audioUrl, normalized });
              await sendAck(chatId, { type: 'voice_cloning_response' });
              
              await handleVoiceMessage({ chatId, senderId, senderName, audioUrl });
              return;
            }
            
            case 'voice_processing':
              // Legacy - Voice messages are handled by separate block below
              break;
              
            default:
              console.log(`âš ï¸ Unknown tool from router: ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unknown tool from router: ${decision.tool}`);
              break;
          }
          
          // Break out of while loop after successful execution (unless retry continues)
          break;
          
          } // End of while loop
        } catch (toolError) {
          console.error(`âŒ Error executing tool ${decision.tool}:`, toolError);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”: ${toolError.message || toolError}`);
        }
      } catch (routerError) {
        console.error('âŒ Intent router error:', routerError.message || routerError);
        await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×‘ ×”×‘×§×©×”: ${routerError.message || routerError}`);
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle IMAGE/STICKER messages with caption starting with "# "
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if (messageData.typeMessage === 'imageMessage' || messageData.typeMessage === 'stickerMessage') {
      const imageData = messageData.fileMessageData || messageData.imageMessageData || messageData.stickerMessageData;
      const caption = imageData?.caption || '';
      
      if (/^#\s+/.test(caption.trim())) {
        try {
          const normalized = {
            userText: caption.trim(),
            hasImage: true,
            hasVideo: false,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: {
              media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
              // group_creation will be checked only if user requests group creation (lazy evaluation)
              group_creation: null,
              voice_allowed: false
            },
            // Pass sender data for lazy authorization checks
            senderData: { senderContactName, chatName, senderName, chatId }
          };

          const decision = await routeIntent(normalized);
          const prompt = normalized.userText.replace(/^#\s+/, '').trim();

          // Handle router decision for images
          switch (decision.tool) {
            case 'deny_unauthorized':
              await sendUnauthorizedMessage(chatId, decision.args?.feature || 'media');
              return;
              
            case 'image_edit': {
              const service = decision.args?.service || 'gemini';
              console.log(`ğŸ¨ ${service} image edit request (via router)`);
              await saveLastCommand(chatId, decision, { imageUrl: imageData.downloadUrl, normalized });
              processImageEditAsync({
                chatId, senderId, senderName,
                imageUrl: imageData.downloadUrl,
                prompt: decision.args?.prompt || prompt,
                service: service
              });
              return;
            }
            
            case 'veo3_video':
            case 'veo3_image_to_video':
            case 'sora_image_to_video':
            case 'kling_text_to_video':
            case 'kling_image_to_video': {
              let service;
              if (decision.tool === 'veo3_video' || decision.tool === 'veo3_image_to_video') {
                service = 'veo3';
              } else if (decision.tool === 'sora_image_to_video') {
                service = 'sora';
              } else {
                service = 'kling';
              }
              console.log(`ğŸ¬ ${service} image-to-video request (via router)`);
              await saveLastCommand(chatId, decision, { imageUrl: imageData.downloadUrl, normalized });
              const model = decision.args?.model; // Pass model for Sora Pro/regular
              processImageToVideoAsync({
                chatId, senderId, senderName,
                imageUrl: imageData.downloadUrl,
                prompt: decision.args?.prompt || prompt,
                service: service,
                model: model
              });
              return;
            }
            
            case 'gemini_chat': {
              await saveLastCommand(chatId, decision, { imageUrl: imageData.downloadUrl, normalized });
              await sendAck(chatId, { type: 'gemini_chat' });
              // Image analysis - use analyzeImageWithText
              const { analyzeImageWithText } = require('../services/geminiService');
              try {
                // Download and convert image to base64
                const imageBuffer = await downloadFile(imageData.downloadUrl);
                const base64Image = imageBuffer.toString('base64');
                
                const result = await analyzeImageWithText(prompt, base64Image);
                if (result.success) {
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              } catch (error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×ª××•× ×”: ${error.message}`);
              }
              return;
            }
            
            default:
              console.log(`âš ï¸ Unexpected tool for image: ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unexpected tool for image: ${decision.tool}`);
              return;
          }
        } catch (error) {
          console.error('âŒ Error routing image message:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×ª××•× ×”: ${error.message || error}`);
        }
      }
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle VIDEO messages with caption starting with "# "
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else if (messageData.typeMessage === 'videoMessage') {
      const videoData = messageData.fileMessageData || messageData.videoMessageData;
      const caption = videoData?.caption || '';
      
      if (/^#\s+/.test(caption.trim())) {
        try {
          const normalized = {
            userText: caption.trim(),
            hasImage: false,
            hasVideo: true,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: {
              media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
              // group_creation will be checked only if user requests group creation (lazy evaluation)
              group_creation: null,
              voice_allowed: false
            },
            // Pass sender data for lazy authorization checks
            senderData: { senderContactName, chatName, senderName, chatId }
          };

          const decision = await routeIntent(normalized);
          const prompt = normalized.userText.replace(/^#\s+/, '').trim();

          // Handle router decision for videos
          switch (decision.tool) {
            case 'deny_unauthorized':
              await sendUnauthorizedMessage(chatId, decision.args?.feature || 'media');
              return;
              
            case 'gemini_chat': {
              await saveLastCommand(chatId, decision, { videoUrl: videoData.downloadUrl, normalized });
              await sendAck(chatId, { type: 'gemini_chat' });
              // Video analysis - use analyzeVideoWithText
              const { analyzeVideoWithText } = require('../services/geminiService');
              try {
                // Download video buffer
                const videoBuffer = await downloadFile(videoData.downloadUrl);
                
                const result = await analyzeVideoWithText(prompt, videoBuffer);
                if (result.success) {
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              } catch (error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×•×™×“××•: ${error.message}`);
              }
              return;
            }
            
            case 'video_to_video': {
              console.log(`ğŸ¬ RunwayML Gen4 video-to-video request (via router)`);
              await saveLastCommand(chatId, decision, { videoUrl: videoData.downloadUrl, normalized });
              processVideoToVideoAsync({
                chatId, senderId, senderName,
                videoUrl: videoData.downloadUrl,
                prompt: decision.args?.prompt || prompt
              });
              return;
            }
            
            default:
              console.log(`âš ï¸ Unexpected tool for video: ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unexpected tool for video: ${decision.tool}`);
              return;
          }
        } catch (error) {
          console.error('âŒ Error routing video message:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×•×™×“××•: ${error.message || error}`);
        }
      }
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle voice messages with smart routing
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else if (messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage') {
      const audioData = messageData.fileMessageData || messageData.audioMessageData;
      
      console.log(`ğŸ¤ Voice message received`);
      
      try {
        // Check if sender is authorized for voice transcription
        const isAuthorized = await conversationManager.isAuthorizedForVoiceTranscription({ senderContactName, chatName, senderName, chatId });
        
        if (!isAuthorized) {
          console.log(`ğŸš« Voice processing not allowed - not authorized`);
          return;
        }
        
        console.log(`âœ… Voice processing authorized`);
        
        // Send immediate ACK for voice messages
        await sendAck(chatId, { type: 'voice_processing' });
        
        // â•â•â•â•â•â•â•â•â•â•â• NEW: Transcribe first to detect if it's a command â•â•â•â•â•â•â•â•â•â•â•
        console.log(`ğŸ”„ Step 1: Transcribing to detect intent...`);
        const audioBuffer = await downloadFile(audioData.downloadUrl);
        
        const transcriptionResult = await speechService.speechToText(audioBuffer, TRANSCRIPTION_DEFAULTS);
        
        if (transcriptionResult.error) {
          console.error('âŒ Transcription failed:', transcriptionResult.error);
          await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×”: ${transcriptionResult.error}`);
          return;
        }
        
        const transcribedText = transcriptionResult.text.trim();
        console.log(`âœ… Transcribed: "${transcribedText}"`);
        
        // Check if transcribed text contains a command
        // Strategy: Try to detect ANY valid command, not just ones with # or "×©×•×œ××™×ª" prefix
        let isCommand = /^(#|×©×•×œ××™×ª)\s+/i.test(transcribedText);
        let normalizedText = transcribedText;
        
        // If no explicit prefix, check if this could be a command using intentRouter
        if (!isCommand && transcribedText.length > 0) {
          console.log(`ğŸ” No explicit prefix - checking if this is a valid command using intentRouter...`);
          
          try {
            // Test with intentRouter to see if this would be recognized as a command
            const testInput = {
              userText: transcribedText,
              hasImage: false,
              hasVideo: false,
              hasAudio: false,
              chatType: 'private',
              language: null,
              senderData: { senderContactName, chatName, senderName, chatId },
              authorizations: {
                media_creation: await isAuthorizedForMediaCreation({ senderContactName, chatName, senderName, chatId }),
                voice_allowed: true
              }
            };
            
            const routingDecision = await routeIntent(testInput);
            
            // If intentRouter recognizes it as a command (not ask_clarification, gemini_chat, or creative_voice_processing),
            // then treat it as a command
            // Note: gemini_chat should go through voice-to-voice flow, not text re-processing
            if (routingDecision.tool && 
                routingDecision.tool !== 'ask_clarification' && 
                routingDecision.tool !== 'creative_voice_processing' &&
                routingDecision.tool !== 'gemini_chat') {
              isCommand = true;
              // Add # prefix for proper processing
              normalizedText = `# ${transcribedText}`;
              console.log(`âœ… Intent detected: ${routingDecision.tool} - treating as command`);
            } else {
              console.log(`â„¹ï¸ Intent router result: ${routingDecision.tool} - going to voice-to-voice flow`);
            }
          } catch (err) {
            console.error(`âš ï¸ Error checking intent:`, err.message);
            // On error, fall back to voice cloning flow
          }
        }
        
        if (isCommand) {
          console.log(`ğŸ¯ Detected command in voice message! Re-processing as text command...`);
          
          // Create a fake webhook data with the transcribed text as if user typed it
          // This allows ALL commands to work, including quoted messages, retry, etc.
          const fakeWebhookData = {
            typeWebhook: 'incomingMessageReceived',
            idMessage: `voice_${messageData.idMessage || Date.now()}`,
            senderData: {
              chatId,
              sender: senderId,
              senderName,
              senderContactName,
              chatName
            },
            messageData: {
              typeMessage: 'textMessage',
              textMessageData: {
                textMessage: normalizedText
              }
            }
          };
          
          console.log(`ğŸ”„ Re-processing voice as text: "${normalizedText.substring(0, 100)}"`);
          
          // Call handleIncomingMessage recursively with the fake data
          // This ensures ALL command logic works: retry, quoted messages, media creation, etc.
          await handleIncomingMessage(fakeWebhookData);
        } else {
          // No command detected - proceed with normal voice-to-voice flow
          console.log(`ğŸ’¬ No command in voice message - proceeding with voice cloning flow`);
          
          processVoiceMessageAsync({
            chatId,
            senderId,
            senderName,
            audioUrl: audioData.downloadUrl
          });
        }
      } catch (error) {
        console.error('âŒ Error processing voice message:', error);
        await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×”×§×œ×˜×”: ${error.message}`);
      }
    } else if (messageText && !messageText.startsWith('#')) {
      // Non-"#" text messages - handle management commands only
      const command = parseTextCommand(messageText);
      if (command) {
        await handleManagementCommand(command, chatId, senderId, senderName, senderContactName, chatName);
      } else {
        console.log(`â„¹ï¸ Text message without '# ' prefix - ignored (not a management command)`);
      }
    } else {
      console.log(`â„¹ï¸ Unsupported message type: ${messageData.typeMessage}`);
    }
  } catch (error) {
    console.error('âŒ Error handling incoming message:', error.message || error);
  }
}

/**
 * Handle outgoing WhatsApp message (commands sent by you)
 */
async function handleOutgoingMessage(webhookData) {
  try {
    const messageData = webhookData.messageData;
    const senderData = webhookData.senderData;
    
    // Extract message ID for deduplication
    let messageId = webhookData.idMessage;
    
    // For edited messages, append suffix to ensure they're processed even if original was processed
    if (messageData.typeMessage === 'editedMessage') {
      messageId = `${messageId}_edited_${Date.now()}`;
      console.log(`âœï¸ Edited message (outgoing) - using unique ID for reprocessing: ${messageId}`);
    }
    
    // Check if we already processed this message
    if (processedMessages.has(messageId)) {
      console.log(`ğŸ”„ Duplicate outgoing message detected, skipping: ${messageId}`);
      return;
    }
    
    // Mark message as processed
    processedMessages.add(messageId);
    
    const chatId = senderData.chatId;
    const senderId = senderData.sender;
    const senderName = senderData.senderName || senderId;
    const senderContactName = senderData.senderContactName || "";
    const chatName = senderData.chatName || "";
    
    // Handle text messages (regular, extended, quoted, and edited)
    let messageText = null;
    
    if (messageData.typeMessage === 'textMessage') {
      messageText = messageData.textMessageData?.textMessage;
    } else if (messageData.typeMessage === 'extendedTextMessage') {
      messageText = messageData.extendedTextMessageData?.text;
    } else if (messageData.typeMessage === 'quotedMessage') {
      // When replying to a message, the text is in extendedTextMessageData
      messageText = messageData.extendedTextMessageData?.text;
      // BUT: If this is actually an image/video/sticker with caption (not a reply), extract the caption
      if (!messageText) {
        messageText = messageData.fileMessageData?.caption || 
                     messageData.imageMessageData?.caption || 
                     messageData.videoMessageData?.caption ||
                     messageData.stickerMessageData?.caption;
      }
    } else if (messageData.typeMessage === 'editedMessage') {
      // Handle edited messages - treat them as regular messages
      messageText = messageData.editedMessageData?.textMessage;
      console.log(`âœï¸ Edited message detected (outgoing): "${messageText}"`);
    }
    
    // Enhanced logging for outgoing messages
    console.log(`ğŸ“¤ Outgoing from ${senderName}:`);
    console.log(`   Message Type: ${messageData.typeMessage}${messageData.typeMessage === 'editedMessage' ? ' âœï¸' : ''}`);
    console.log(`   messageText extracted: ${messageText ? `"${messageText.substring(0, 100)}"` : 'NULL/UNDEFINED'}`);
    if (messageText) {
      console.log(`   Text: ${messageText.substring(0, 100)}${messageText.length > 100 ? '...' : ''}`);
    }
    if (messageData.typeMessage === 'imageMessage') {
      const caption = messageData.fileMessageData?.caption || messageData.imageMessageData?.caption;
      console.log(`   Image Caption: ${caption || 'N/A'}`);
    }
    if (messageData.typeMessage === 'stickerMessage') {
      const caption = messageData.fileMessageData?.caption;
      console.log(`   Sticker Caption: ${caption || 'N/A'} (treating as image)`);
    }
    if (messageData.typeMessage === 'videoMessage') {
      const caption = messageData.fileMessageData?.caption || messageData.videoMessageData?.caption;
      console.log(`   Video Caption: ${caption || 'N/A'}`);
    }
    if (messageData.typeMessage === 'quotedMessage' && messageData.quotedMessage) {
      console.log(`   Quoted Message Type: ${messageData.quotedMessage.typeMessage}`);
      if (messageData.quotedMessage.textMessage) {
        console.log(`   Quoted Text: ${messageData.quotedMessage.textMessage.substring(0, 50)}...`);
      }
      if (messageData.quotedMessage.caption) {
        console.log(`   Quoted Caption: ${messageData.quotedMessage.caption.substring(0, 50)}...`);
      }
    }
    
    // Unified intent router for outgoing when text starts with "# "
    if (messageText && /^#\s+/.test(messageText.trim())) {
      try {
        const chatId = senderData.chatId;
        const senderId = senderData.sender;
        const senderName = senderData.senderName || senderId;
        const senderContactName = senderData.senderContactName || "";
        const chatName = senderData.chatName || "";

        // Extract the prompt (remove "# " prefix if exists)
        // For edited messages, # might be removed by WhatsApp/Green API
        const basePrompt = messageText.trim().replace(/^#\s+/, '').trim();
        
        // Check if this is a quoted/replied message
        // Only process quotedMessage if typeMessage is 'quotedMessage' (actual reply)
        // Don't process if it's just extendedTextMessage with leftover quotedMessage metadata
        const quotedMessage = messageData.quotedMessage;
        
        // IMPORTANT: Green API sends images/videos with captions as quotedMessage, but they're NOT actual quotes!
        // Check if this is a REAL quote (reply) or just a media message with caption
        // Logic:
        // - If caption exists AND matches/starts with the text â†’ It's a NEW media message (not a quote)
        // - If caption doesn't exist OR doesn't match â†’ It's a REAL quote
        const quotedCaption = quotedMessage?.caption;
        const extractedText = messageData.extendedTextMessageData?.text; // Don't shadow messageText!
        // Check if caption matches text (exact match OR caption starts with text, covering "# ××” ×–×”..." case)
        const captionMatchesText = quotedCaption && extractedText && 
                                  (quotedCaption === extractedText || 
                                   quotedCaption.startsWith(extractedText) ||
                                   extractedText.startsWith(quotedCaption));
        
        const isActualQuote = messageData.typeMessage === 'quotedMessage' && 
                             quotedMessage && 
                             quotedMessage.stanzaId &&
                             extractedText &&
                             !captionMatchesText; // It's a quote if text doesn't match caption
        
        let finalPrompt = basePrompt;
        let hasImage = messageData.typeMessage === 'imageMessage' || messageData.typeMessage === 'stickerMessage';
        let hasVideo = messageData.typeMessage === 'videoMessage';
        let hasAudio = messageData.typeMessage === 'audioMessage';
        let imageUrl = null;
        let videoUrl = null;
        let audioUrl = null;
        
        if (isActualQuote) {
          console.log(`ğŸ”— Outgoing: Detected quoted message with stanzaId: ${quotedMessage.stanzaId}`);
          
          // Handle quoted message - merge content
          const quotedResult = await handleQuotedMessage(quotedMessage, basePrompt, chatId);
          
          // Check if there was an error processing the quoted message
          if (quotedResult.error) {
            await sendTextMessage(chatId, quotedResult.error);
            return;
          }
          
          finalPrompt = quotedResult.prompt;
          hasImage = quotedResult.hasImage;
          hasVideo = quotedResult.hasVideo;
          hasAudio = quotedResult.hasAudio;
          imageUrl = quotedResult.imageUrl;
          videoUrl = quotedResult.videoUrl;
          audioUrl = quotedResult.audioUrl;
        } else if (messageData.typeMessage === 'quotedMessage' && quotedMessage) {
          // This is a media message (image/video) with caption, NOT an actual quote
          // Extract downloadUrl from the message itself
          console.log(`ğŸ“¸ Outgoing: Media message with caption (not a quote) - Type: ${quotedMessage.typeMessage || 'unknown'}`);
          
          if (quotedMessage.typeMessage === 'imageMessage' || quotedMessage.typeMessage === 'stickerMessage') {
            hasImage = true;
            // Try all possible locations for downloadUrl
            imageUrl = messageData.downloadUrl || 
                      messageData.fileMessageData?.downloadUrl || 
                      messageData.imageMessageData?.downloadUrl ||
                      messageData.stickerMessageData?.downloadUrl ||
                      quotedMessage.downloadUrl ||
                      quotedMessage.fileMessageData?.downloadUrl ||
                      quotedMessage.imageMessageData?.downloadUrl ||
                      quotedMessage.stickerMessageData?.downloadUrl;
            
            // If still not found, try getMessage to fetch the current message's downloadUrl
            if (!imageUrl) {
              console.log('âš ï¸ Outgoing: downloadUrl not found in webhook, fetching from Green API...');
              try {
                const currentMessageId = webhookData.idMessage;
                const originalMessage = await greenApiService.getMessage(chatId, currentMessageId);
                imageUrl = originalMessage?.downloadUrl || 
                          originalMessage?.fileMessageData?.downloadUrl || 
                          originalMessage?.imageMessageData?.downloadUrl;
                console.log(`âœ… Outgoing: downloadUrl fetched from getMessage: ${imageUrl ? 'found' : 'still NOT FOUND'}`);
              } catch (err) {
                console.log(`âŒ Outgoing: Failed to fetch downloadUrl via getMessage: ${err.message}`);
              }
            }
            console.log(`ğŸ“¸ Outgoing: Image with caption detected, final downloadUrl: ${imageUrl ? 'found' : 'NOT FOUND'}`);
          } else if (quotedMessage.typeMessage === 'videoMessage') {
            hasVideo = true;
            videoUrl = messageData.downloadUrl || 
                      messageData.fileMessageData?.downloadUrl || 
                      messageData.videoMessageData?.downloadUrl ||
                      quotedMessage.downloadUrl ||
                      quotedMessage.fileMessageData?.downloadUrl ||
                      quotedMessage.videoMessageData?.downloadUrl;
            
            // If still not found, try getMessage to fetch the current message's downloadUrl
            if (!videoUrl) {
              console.log('âš ï¸ Outgoing: Video downloadUrl not found in webhook, fetching from Green API...');
              try {
                const currentMessageId = webhookData.idMessage;
                const originalMessage = await greenApiService.getMessage(chatId, currentMessageId);
                videoUrl = originalMessage?.downloadUrl || 
                          originalMessage?.fileMessageData?.downloadUrl || 
                          originalMessage?.videoMessageData?.downloadUrl;
                console.log(`âœ… Outgoing: Video downloadUrl fetched from getMessage: ${videoUrl ? 'found' : 'still NOT FOUND'}`);
              } catch (err) {
                console.log(`âŒ Outgoing: Failed to fetch video downloadUrl via getMessage: ${err.message}`);
              }
            }
            console.log(`ğŸ¥ Outgoing: Video with caption detected, final downloadUrl: ${videoUrl ? 'found' : 'NOT FOUND'}`);
          }
        }

        const normalized = {
          userText: `# ${finalPrompt}`, // Add back the # prefix for router
          hasImage: hasImage,
          hasVideo: hasVideo,
          hasAudio: hasAudio,
          chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
          language: 'he',
          authorizations: {
            // Outgoing bypasses authorization in existing logic, but router still expects booleans
            media_creation: true,
            group_creation: true,
            voice_allowed: true
          }
        };

        const decision = await routeIntent(normalized);
        const rawPrompt = decision.args?.prompt || finalPrompt;
        // Clean prompt from provider mentions before sending to services
        let prompt = cleanPromptFromProviders(rawPrompt);

        // Router-based direct execution for outgoing messages (same as incoming)
        try {
          // Execute command - loop allows retry to re-execute with updated decision
          let executionAttempts = 0;
          const maxExecutionAttempts = 2; // Allow retry to run command once more
          
          while (executionAttempts < maxExecutionAttempts) {
            executionAttempts++;
            const isRetryExecution = executionAttempts > 1;
            
            if (isRetryExecution) {
              console.log(`ğŸ”„ [Outgoing] Retry execution attempt ${executionAttempts} with tool: ${decision.tool}`);
            }
          
          switch (decision.tool) {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• AGENT MODE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'agent_query': {
              // Autonomous agent that can use multiple tools
              console.log(`ğŸ¤– [OUTGOING] Agent query detected`);
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'agent_query' });
              
              try {
                const agentResult = await executeAgentQuery(prompt, chatId, {
                  maxIterations: 5
                });
                
                if (agentResult.success) {
                  await sendTextMessage(chatId, agentResult.text);
                  
                  // Log tool usage
                  if (agentResult.toolsUsed && agentResult.toolsUsed.length > 0) {
                    console.log(`ğŸ”§ [Agent] Tools used: ${agentResult.toolsUsed.join(', ')}`);
                  }
                  console.log(`âœ… [Agent] Completed in ${agentResult.iterations} iterations`);
                } else {
                  await sendTextMessage(chatId, `âŒ ${agentResult.error}`);
                }
              } catch (error) {
                console.error('âŒ Error in agent execution:', error);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”: ${error.message}`);
              }
              
              return;
            }
            
            case 'retry_last_command': {
              // Extract any additional instructions after "× ×¡×” ×©×•×‘" (same logic as incoming)
              const additionalInstructions = basePrompt
                .replace(/^(× ×¡×”\s*×©×•×‘|×©×•×‘|retry|try\s*again)\s*,?\s*/i, '')
                .trim();

              // Check if there's a quoted message with a command
              // Use isActualQuote to avoid false positives from extendedTextMessage metadata
              if (isActualQuote && quotedMessage && quotedMessage.stanzaId) {
                console.log('ğŸ”„ [Outgoing] Retry with quoted message');
                if (additionalInstructions) {
                  console.log(`ğŸ“ [Outgoing] Additional instructions to merge: "${additionalInstructions}"`);
                }
                
                // Extract the command from the quoted message
                let quotedText = null;
                if (quotedMessage.typeMessage === 'textMessage' || quotedMessage.typeMessage === 'extendedTextMessage') {
                  quotedText = quotedMessage.textMessage || quotedMessage.extendedTextMessage?.text;
                } else if (quotedMessage.typeMessage === 'imageMessage' || quotedMessage.typeMessage === 'stickerMessage') {
                  quotedText = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.imageMessageData?.caption;
                } else if (quotedMessage.typeMessage === 'videoMessage') {
                  quotedText = quotedMessage.caption || quotedMessage.fileMessageData?.caption || quotedMessage.videoMessageData?.caption;
                }
                
                // Check if quoted message has a command (starts with #)
                if (quotedText && /^#\s+/.test(quotedText.trim())) {
                  console.log(`ğŸ”„ [Outgoing] Found command in quoted message: "${quotedText.substring(0, 50)}..."`);
                  // Re-process the quoted message, merging with additional instructions
                  const quotedResult = await handleQuotedMessage(quotedMessage, additionalInstructions, chatId);
                  
                  if (quotedResult.error) {
                    await sendTextMessage(chatId, quotedResult.error);
                    return;
                  }
                  
                  // Re-route with the quoted message content
                  // Use quotedResult.prompt (merged text) instead of quotedText (original only)
                  const retryNormalized = {
                    userText: `# ${quotedResult.prompt}`,
                    hasImage: quotedResult.hasImage,
                    hasVideo: quotedResult.hasVideo,
                    hasAudio: quotedResult.hasAudio,
                    chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
                    language: 'he',
                    authorizations: {
                      media_creation: true,
                      group_creation: true,
                      voice_allowed: true
                    }
                  };
                  
                  console.log(`ğŸ”„ [Outgoing Retry] Routing with merged prompt | Image:${retryNormalized.hasImage} Video:${retryNormalized.hasVideo}`);
                  
                  const retryDecision = await routeIntent(retryNormalized);
                  console.log(`ğŸ”„ [Outgoing] Retry routing decision: ${retryDecision.tool}, reason: ${retryDecision.reason}`);
                  
                  // Continue with normal execution
                  Object.assign(decision, retryDecision);
                  imageUrl = quotedResult.imageUrl;
                  videoUrl = quotedResult.videoUrl;
                  audioUrl = quotedResult.audioUrl;
                  hasImage = quotedResult.hasImage;
                  hasVideo = quotedResult.hasVideo;
                  hasAudio = quotedResult.hasAudio;
                } else {
                  await sendTextMessage(chatId, 'â„¹ï¸ ×”×”×•×“×¢×” ×”××¦×•×˜×˜×ª ×œ× ××›×™×œ×” ×¤×§×•×“×”. ×¦×˜×˜ ×”×•×“×¢×” ×©××ª×—×™×œ×” ×‘-"#"');
                  return;
                }
              } else {
                // No quoted message - retry last command from database
                console.log(`ğŸ”„ [Outgoing] No quoted message, checking database for last command: ${chatId}`);
                const lastCommand = await conversationManager.getLastCommand(chatId);
                
                if (!lastCommand) {
                  console.log(`âŒ [Outgoing] No last command found in database for ${chatId}`);
                  await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ×¤×§×•×“×” ×§×•×“××ª ×œ×‘×™×¦×•×¢ ××—×“×©. × ×¡×” ×œ×©×œ×•×— ×¤×§×•×“×” ×—×“×©×”.');
                  return;
                }
                
                console.log(`ğŸ”„ [Outgoing] Found last command: ${lastCommand.tool}`);
                if (additionalInstructions) {
                  console.log(`ğŸ“ [Outgoing] Additional instructions: "${additionalInstructions}"`);
                }
                
                // âœ¨ CRITICAL: Check for provider override BEFORE merging prompts
                // This allows "# × ×¡×” ×©×•×‘ ×¢× OpenAI" to change gemini_image â†’ openai_image
                // Restore media URLs first so applyProviderOverride can see the context
                if (lastCommand.imageUrl) {
                  imageUrl = lastCommand.imageUrl;
                  hasImage = true;
                }
                if (lastCommand.videoUrl) {
                  videoUrl = lastCommand.videoUrl;
                  hasVideo = true;
                }
                if (lastCommand.audioUrl) {
                  audioUrl = lastCommand.audioUrl;
                  hasAudio = true;
                }
                
                // Build a decision object from the last command to pass to applyProviderOverride
                const lastCommandDecision = {
                  tool: lastCommand.tool,
                  args: lastCommand.args
                };
                
                // Apply provider override if specified (e.g., "×¢× OpenAI", "with Grok")
                const override = applyProviderOverride(additionalInstructions, lastCommandDecision, { hasImage, hasVideo });
                if (override) {
                  console.log(`ğŸ” [Outgoing] Retry with provider override â†’ tool: ${override.tool}, reason: ${override.reason}`);
                  // Use the overridden tool and merge args
                  Object.assign(decision, {
                    tool: override.tool,
                    args: override.args || lastCommand.args,
                    reason: override.reason
                  });
                  
                  // Merge additional instructions with the original prompt if needed
                  // BUT: Remove provider names from the prompt to avoid "OpenAI" appearing in the image
                  if (lastCommand.args?.prompt) {
                    const cleanedInstructions = cleanPromptFromProviders(additionalInstructions);
                    
                    if (cleanedInstructions.trim()) {
                      decision.args.prompt = `${lastCommand.args.prompt}, ${cleanedInstructions}`;
                      console.log(`âœ¨ [Outgoing] Merged prompt (cleaned): "${decision.args.prompt}"`);
                    } else {
                      // No additional instructions after cleaning provider names
                      decision.args.prompt = lastCommand.args.prompt;
                      console.log(`âœ¨ [Outgoing] Using original prompt (no additional instructions after cleaning)`);
                    }
                  }
                } else {
                  // No provider override - just merge instructions normally
                  let mergedArgs = { ...lastCommand.args };
                  if (additionalInstructions && lastCommand.args?.prompt) {
                    mergedArgs.prompt = `${lastCommand.args.prompt}, ${additionalInstructions}`;
                    console.log(`âœ¨ [Outgoing] New merged prompt: "${mergedArgs.prompt}"`);
                  }
                  
                  // Re-assign decision to last command with merged args
                  Object.assign(decision, {
                    tool: lastCommand.tool,
                    args: mergedArgs,
                    reason: 'Retry last command with modifications (outgoing)'
                  });
                }
                
                // No need to update timestamp - it's persisted in DB
                
                // Update prompt from decision.args for the re-execution
                prompt = decision.args?.prompt || prompt;
              }
              // Continue to next iteration of while loop to execute the updated command
              continue;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CHAT â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'gemini_chat': {
              saveLastCommand(chatId, decision, { imageUrl, videoUrl, normalized });
              await sendAck(chatId, { type: 'gemini_chat' });
              
              // Check if this is image analysis (hasImage = true)
              if (normalized.hasImage) {
                try {
                  // Get image URL (either from quoted message or current message)
                  const finalImageUrl = imageUrl || messageData.fileMessageData?.downloadUrl || messageData.imageMessageData?.downloadUrl || messageData.stickerMessageData?.downloadUrl;
                  if (!finalImageUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×ª××•× ×”');
                    return;
                  }
                  
                  // Download and convert to base64
                  const downloadedBuffer = await downloadFile(finalImageUrl);
                  const base64Image = downloadedBuffer.toString('base64');
                  
                  // Check if this is an edit request vs analysis request
                  const isEditRequest = IMAGE_EDIT_PATTERN.test(prompt);
                  const isImplicitEdit = IMAGE_IMPLICIT_EDIT_PATTERN.test(prompt);
                  
                  if (isEditRequest || isImplicitEdit) {
                    // This is image EDITING - use editImageForWhatsApp
                    console.log(`ğŸ–¼ï¸ [OUTGOING] Detected image edit request in gemini_chat, switching to editImageForWhatsApp`);
                    
                    // Check if user wants to reference previous messages
                    let finalPromptOutgoingImage = prompt;
                    if (decision.args?.needsChatHistory) {
                      try {
                        console.log(`ğŸ“œ User requested chat history context for image editing (outgoing), fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                        const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                        
                        if (chatHistory && chatHistory.length > 0) {
                          const formattedHistory = formatChatHistoryForContext(chatHistory);
                          finalPromptOutgoingImage = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                          console.log(`âœ… Added ${chatHistory.length} messages as context to image editing (outgoing)`);
                        }
                      } catch (historyError) {
                        console.error('âŒ Error fetching chat history:', historyError);
                      }
                    }
                    
                    const editResult = await editImageForWhatsApp(finalPromptOutgoingImage, base64Image);
                    if (editResult.success && editResult.imageUrl) {
                      const fileName = `gemini_edited_${Date.now()}.png`;
                      await sendFileByUrl(chatId, editResult.imageUrl, fileName, editResult.description || '');
                      console.log('ğŸ¨ [OUTGOING] Edited image sent successfully');
                    } else if (editResult.textResponse) {
                      // Gemini returned text instead of image
                      await sendTextMessage(chatId, `âš ï¸ ${editResult.textResponse}\n\nğŸ’¡ ×”×¦×¢×”: × ×¡×” ×¢× OpenAI - ×©×œ×— "# × ×¡×” ×©×•×‘, ×¢× OpenAI"`);
                      console.log('ğŸ¨ [OUTGOING] Gemini returned text instead of image, sent suggestion to user');
                    } else {
                      await sendTextMessage(chatId, `âŒ ${editResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×¨×•×š ××ª ×”×ª××•× ×”'}`);
                      console.log('ğŸ¨ [OUTGOING] Error message sent:', editResult.error);
                    }
                  } else {
                    // This is image ANALYSIS - use analyzeImageWithText
                    const { analyzeImageWithText } = require('../services/geminiService');
                    console.log(`ğŸ” [OUTGOING] Detected image analysis request in gemini_chat`);
                    
                    // Check if user wants to reference previous messages
                    let finalPromptOutgoingImage = prompt;
                    if (decision.args?.needsChatHistory) {
                      try {
                        console.log(`ğŸ“œ User requested chat history context for image analysis (outgoing), fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                        const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                        
                        if (chatHistory && chatHistory.length > 0) {
                          const formattedHistory = formatChatHistoryForContext(chatHistory);
                          finalPromptOutgoingImage = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                          console.log(`âœ… Added ${chatHistory.length} messages as context to image analysis (outgoing)`);
                        }
                      } catch (historyError) {
                        console.error('âŒ Error fetching chat history:', historyError);
                      }
                    }
                    
                    const result = await analyzeImageWithText(finalPromptOutgoingImage, base64Image);
                    if (result.success) {
                      await sendTextMessage(chatId, result.text);
                    } else {
                      await sendTextMessage(chatId, `âŒ ${result.error}`);
                    }
                  }
                } catch (error) {
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×ª××•× ×”: ${error.message}`);
                }
              } else if (normalized.hasVideo) {
                // This is video analysis - use analyzeVideoWithText
                const { analyzeVideoWithText } = require('../services/geminiService');
                
                try {
                  // Get video URL (either from quoted message or current message)
                  const finalVideoUrl = videoUrl || messageData.fileMessageData?.downloadUrl || messageData.videoMessageData?.downloadUrl;
                  if (!finalVideoUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×•×™×“××• ×œ× ×™×ª×•×—');
                    return;
                  }
                  
                  // Download video buffer
                  const videoBuffer = await downloadFile(finalVideoUrl);
                  
                  // Check if user wants to reference previous messages
                  let finalPromptOutgoingVideo = prompt;
                  if (decision.args?.needsChatHistory) {
                    try {
                      console.log(`ğŸ“œ User requested chat history context for video analysis (outgoing), fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                      const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                      
                      if (chatHistory && chatHistory.length > 0) {
                        const formattedHistory = formatChatHistoryForContext(chatHistory);
                        finalPromptOutgoingVideo = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                        console.log(`âœ… Added ${chatHistory.length} messages as context to video analysis (outgoing)`);
                      }
                    } catch (historyError) {
                      console.error('âŒ Error fetching chat history:', historyError);
                    }
                  }
                  
                  const result = await analyzeVideoWithText(finalPromptOutgoingVideo, videoBuffer);
                  if (result.success) {
                    await sendTextMessage(chatId, result.text);
                  } else {
                    await sendTextMessage(chatId, `âŒ ${result.error}`);
                  }
                } catch (error) {
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×•×™×“××•: ${error.message}`);
                }
              } else if (normalized.hasAudio && decision.args?.needsTranscription) {
                // Audio processing with transcription (outgoing - same logic as incoming)
                console.log('ğŸ¤ [Outgoing] Audio message with transcription request');
                
                try {
                  // Get audio URL (either from quoted message or current message)
                  const finalAudioUrl = audioUrl || messageData.fileMessageData?.downloadUrl || messageData.audioMessageData?.downloadUrl;
                  if (!finalAudioUrl) {
                    await sendTextMessage(chatId, 'âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×§×‘×œ ××ª ×”×”×§×œ×˜×”');
                    return;
                  }
                  
                  // Step 1: Download and transcribe audio
                  console.log('ğŸ”„ [Outgoing] Transcribing audio...');
                  const audioBuffer = await downloadFile(finalAudioUrl);
                  
                  const transcriptionOptions = TRANSCRIPTION_DEFAULTS;
                  
                  const transcriptionResult = await speechService.speechToText(audioBuffer, transcriptionOptions);
                  
                  if (transcriptionResult.error) {
                    await sendTextMessage(chatId, `âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×”: ${transcriptionResult.error}`);
                    return;
                  }
                  
                  const transcribedText = transcriptionResult.text;
                  const detectedLanguage = transcriptionResult.detectedLanguage || 'he';
                  console.log(`âœ… [Outgoing] Transcription complete: ${transcribedText.length} chars, language: ${detectedLanguage}`);
                  
                  // Step 2: Detect what user wants to do with the transcription
                  const isJustTranscription = JUST_TRANSCRIPTION_PATTERN.test(prompt.trim());
                  if (isJustTranscription) {
                    console.log('ğŸ“ [Outgoing] Just transcription requested');
                    await sendTextMessage(chatId, `ğŸ“ ×ª××œ×•×œ:\n\n${transcribedText}`);
                    return;
                  }
                  
                  // Support ALL Hebrew conjugations (male/female/plural) per rule 7
                  const hasTTSKeywords = TTS_KEYWORDS_PATTERN.test(prompt);
                  const hasTextKeywords = TRANSLATE_KEYWORDS_PATTERN.test(prompt) && !hasTTSKeywords;
                  
                  // Detect target language
                  // NOTE: Don't use \b before Hebrew words - it doesn't work in JavaScript
                  const languagePatterns = {
                    'en': /(×‘?×× ×’×œ×™×ª|\benglish\b|\bin\s+english\b)/i,
                    'es': /(×‘?×¡×¤×¨×“×™×ª|\bspanish\b|\bin\s+spanish\b)/i,
                    'fr': /(×‘?×¦×¨×¤×ª×™×ª|\bfrench\b|\bin\s+french\b)/i,
                    'de': /(×‘?×’×¨×× ×™×ª|\bgerman\b|\bin\s+german\b)/i,
                    'it': /(×‘?××™×˜×œ×§×™×ª|\bitalian\b|\bin\s+italian\b)/i,
                    'pt': /(×‘?×¤×•×¨×˜×•×’×–×™×ª|\bportuguese\b|\bin\s+portuguese\b)/i,
                    'ru': /(×‘?×¨×•×¡×™×ª|\brussian\b|\bin\s+russian\b)/i,
                    'zh': /(×‘?×¡×™× ×™×ª|×‘?×× ×“×¨×™× ×™×ª|\bchinese\b|\bmandarin\b|\bin\s+chinese\b)/i,
                    'ja': /(×‘?×™×¤× ×™×ª|\bjapanese\b|\bin\s+japanese\b)/i,
                    'ko': /(×‘?×§×•×¨×™×× ×™×ª|\bkorean\b|\bin\s+korean\b)/i,
                    'ar': /(×‘?×¢×¨×‘×™×ª|\barabic\b|\bin\s+arabic\b)/i,
                    'hi': /(×‘?×”×™× ×“×™×ª|\bhindi\b|\bin\s+hindi\b)/i,
                    'tr': /(×‘?×˜×•×¨×§×™×ª|\bturkish\b|\bin\s+turkish\b)/i,
                    'pl': /(×‘?×¤×•×œ× ×™×ª|\bpolish\b|\bin\s+polish\b)/i,
                    'nl': /(×‘?×”×•×œ× ×“×™×ª|\bdutch\b|\bin\s+dutch\b)/i,
                    'sv': /(×‘?×©×•×•×“×™×ª|\bswedish\b|\bin\s+swedish\b)/i,
                    'fi': /(×‘?×¤×™× ×™×ª|\bfinnish\b|\bin\s+finnish\b)/i,
                    'no': /(×‘?× ×•×¨×•×•×’×™×ª|\bnorwegian\b|\bin\s+norwegian\b)/i,
                    'da': /(×‘?×“× ×™×ª|\bdanish\b|\bin\s+danish\b)/i,
                    'cs': /(×‘?×¦'×›×™×ª|\bczech\b|\bin\s+czech\b)/i,
                    'he': /(×‘?×¢×‘×¨×™×ª|\bhebrew\b|\bin\s+hebrew\b)/i
                  };
                  
                  let targetLanguage = null;
                  let targetLanguageCode = null;
                  for (const [code, pattern] of Object.entries(languagePatterns)) {
                    if (pattern.test(prompt)) {
                      targetLanguageCode = code;
                      targetLanguage = prompt.match(pattern)[0];
                      break;
                    }
                  }
                  
                  console.log(`ğŸŒ Language detection - Target: ${targetLanguageCode || 'none'} (${targetLanguage || 'N/A'})`);
                  
                  // Case 3: Translation with TTS
                  if (hasTTSKeywords && targetLanguageCode) {
                    console.log(`ğŸ”Š [Outgoing] Translation + TTS requested to ${targetLanguageCode}`);
                    
                    const translationPrompt = `Translate the following text to ${targetLanguage}. Return ONLY the translated text, nothing else:\n\n${transcribedText}`;
                    const translationResult = await generateGeminiResponse(translationPrompt, []);
                    
                    if (translationResult.error) {
                      await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
                      return;
                    }
                    
                    const translatedText = translationResult.text;
                    console.log(`âœ… [Outgoing] Translated to ${targetLanguageCode}`);
                    
                    // Check audio duration and decide whether to clone voice
                    const audioDuration = await getAudioDuration(audioBuffer);
                    let quotedVoiceId = null;
                    let shouldCloneQuotedVoice = audioDuration >= MIN_DURATION_FOR_CLONING;
                    
                    if (shouldCloneQuotedVoice) {
                      console.log(`ğŸ¤ [Outgoing] Attempting voice clone (duration: ${audioDuration.toFixed(2)}s >= ${MIN_DURATION_FOR_CLONING}s)...`);
                      
                      const voiceCloneOptions = {
                        name: `WhatsApp Quoted Voice Clone ${Date.now()}`,
                        description: `Voice clone from quoted audio`,
                        removeBackgroundNoise: true,
                        labels: JSON.stringify({
                          accent: 'natural',
                          use_case: 'conversational',
                          quality: 'high',
                          style: 'natural',
                          language: targetLanguageCode
                        })
                      };
                      
                      const voiceCloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
                      
                      if (voiceCloneResult.error) {
                        console.warn(`âš ï¸ Voice cloning failed: ${voiceCloneResult.error}. Falling back to random voice.`);
                        shouldCloneQuotedVoice = false;
                      } else {
                        quotedVoiceId = voiceCloneResult.voiceId;
                        console.log(`âœ… Voice cloned: ${quotedVoiceId} for ${targetLanguageCode}`);
                      }
                    } else {
                      console.log(`â­ï¸ Skipping voice clone (duration: ${audioDuration.toFixed(2)}s < ${MIN_DURATION_FOR_CLONING}s) - will use random voice`);
                    }
                    
                    // If voice wasn't cloned, get random voice for target language
                    if (!shouldCloneQuotedVoice || !quotedVoiceId) {
                      console.log(`ğŸ”„ [Outgoing] Getting random voice for ${targetLanguageCode}...`);
                      const voiceResult = await voiceService.getVoiceForLanguage(targetLanguageCode);
                      if (voiceResult.error) {
                        await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translatedText}\n\nâš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×§×•×œ: ${voiceResult.error}`);
                        return;
                      }
                      quotedVoiceId = voiceResult.voiceId;
                    }
                    
                    // Generate speech with cloned or random voice
                    const ttsResult = await voiceService.textToSpeech(quotedVoiceId, translatedText, ELEVENLABS_TTS_DEFAULTS);
                    
                    if (!ttsResult.error && ttsResult.audioBuffer) {
                      const conversionResult = await audioConverterService.convertAndSaveAsOpus(ttsResult.audioBuffer, 'mp3');
                      if (conversionResult.success && conversionResult.fileName) {
                        const fullUrl = getStaticFileUrl(conversionResult.fileName);
                        await sendFileByUrl(chatId, fullUrl, conversionResult.fileName, `ğŸŒ ${targetLanguage}`);
                      } else {
                        await sendTextMessage(chatId, `âŒ ${conversionResult.error}`);
                      }
                    } else {
                      await sendTextMessage(chatId, `âŒ ${ttsResult.error || '×©×’×™××” ×‘×™×¦×™×¨×ª ×”×§×•×œ'}`);
                    }
                    
                    // Cleanup cloned voice if needed
                    if (shouldCloneQuotedVoice && quotedVoiceId) {
                      try {
                        await voiceService.deleteVoice(quotedVoiceId);
                        console.log(`ğŸ§¹ Quoted voice clone ${quotedVoiceId} deleted`);
                      } catch (cleanupError) {
                        console.warn('âš ï¸ Could not delete quoted voice clone:', cleanupError.message);
                      }
                    }
                    
                    return;
                  }
                  
                  // Case 4: Text translation only
                  if (hasTextKeywords && targetLanguageCode) {
                    console.log(`ğŸ“ [Outgoing] Text translation requested to ${targetLanguageCode}`);
                    
                    const translationPrompt = `Translate the following text to ${targetLanguage}. Return ONLY the translated text, nothing else:\n\n${transcribedText}`;
                    const translationResult = await generateGeminiResponse(translationPrompt, []);
                    
                    if (translationResult.error) {
                      await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
                    } else {
                      await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translationResult.text}`);
                    }
                    return;
                  }
                  
                  // Case 5: General request - use transcription as context
                  console.log('ğŸ“ [Outgoing] General request with transcription');
                  const fullPrompt = `×”×ª××œ×•×œ ×©×œ ×”×”×§×œ×˜×”:\n\n"${transcribedText}"\n\n${prompt}`;
                  
                  const contextMessages = await conversationManager.getConversationHistory(chatId);
                  await conversationManager.addMessage(chatId, 'user', fullPrompt);
                  // Check if Google Search should be used
                  const useGoogleSearchOutgoingAudio = decision.args?.useGoogleSearch === true;
                  const result = await generateGeminiResponse(fullPrompt, contextMessages, { useGoogleSearch: useGoogleSearchOutgoingAudio });
                  
                  if (!result.error) {
                    await conversationManager.addMessage(chatId, 'assistant', result.text);
                    await sendTextMessage(chatId, result.text);
                  } else {
                    await sendTextMessage(chatId, `âŒ ${result.error}`);
                  }
                  
                } catch (audioError) {
                  console.error('âŒ [Outgoing] Error processing audio:', audioError);
                  await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”××•×“×™×•: ${audioError.message}`);
                }
              } else {
                // Regular text chat
                let finalPromptOutgoing = prompt;
                
                // Check if user wants to reference previous messages in the chat/group
                if (decision.args?.needsChatHistory) {
                  try {
                    console.log(`ğŸ“œ User requested chat history context (outgoing), fetching last ${CHAT_HISTORY_LIMIT} messages...`);
                    const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
                    
                    if (chatHistory && chatHistory.length > 0) {
                      const formattedHistory = formatChatHistoryForContext(chatHistory);
                      
                      // Prepend chat history to the prompt
                      finalPromptOutgoing = `×œ×”×œ×Ÿ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×‘×©×™×—×”/×§×‘×•×¦×”:\n\n${formattedHistory}\n\n×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×•×“×¢×•×ª ×œ×¢×™×œ, ${prompt}`;
                      console.log(`âœ… Added ${chatHistory.length} messages as context to prompt (outgoing)`);
                    } else {
                      console.log('âš ï¸ No chat history available, proceeding without context');
                    }
                  } catch (historyError) {
                    console.error('âŒ Error fetching chat history:', historyError);
                    // Continue without history if fetch fails
                  }
                }
                
                const contextMessages = await conversationManager.getConversationHistory(chatId);
                await conversationManager.addMessage(chatId, 'user', finalPromptOutgoing);
                // Check if Google Search should be used
                const useGoogleSearchOutgoing = decision.args?.useGoogleSearch === true;
                const result = await generateGeminiResponse(finalPromptOutgoing, contextMessages, { useGoogleSearch: useGoogleSearchOutgoing });
                if (!result.error) {
                  await conversationManager.addMessage(chatId, 'assistant', result.text);
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              }
              return;
            }
            case 'openai_chat': {
              await saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'openai_chat' });
              const contextMessages = await conversationManager.getConversationHistory(chatId);
              await conversationManager.addMessage(chatId, 'user', prompt);
              const result = await generateOpenAIResponse(prompt, contextMessages);
              if (!result.error) {
                await conversationManager.addMessage(chatId, 'assistant', result.text);
                await sendTextMessage(chatId, result.text);
              }
              return;
            }
            case 'grok_chat': {
              await saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'grok_chat' });
              // Note: Grok doesn't use conversation history (causes issues)
              await conversationManager.addMessage(chatId, 'user', prompt);
              const result = await generateGrokResponse(prompt, []);
              if (!result.error) {
                await conversationManager.addMessage(chatId, 'assistant', result.text);
                await sendTextMessage(chatId, result.text);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'gemini_image': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'gemini_image' });
              const imageResult = await generateImageForWhatsApp(prompt);
              if (imageResult.success && imageResult.imageUrl) {
                await sendFileByUrl(chatId, imageResult.imageUrl, `gemini_image_${Date.now()}.png`, imageResult.description || '');
              } else {
                await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
              }
              return;
            }
            case 'openai_image': {
              await saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'openai_image' });
              const imageResult = await generateOpenAIImage(prompt);
              if (imageResult.success && imageResult.imageUrl) {
                await sendFileByUrl(chatId, imageResult.imageUrl, `openai_image_${Date.now()}.png`, imageResult.description || '');
              } else {
                await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
              }
              return;
            }
            case 'grok_image': {
              await saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'grok_image' });
              const imageResult = await generateGrokImage(prompt);
              if (imageResult.success && imageResult.imageUrl) {
                await sendFileByUrl(chatId, imageResult.imageUrl, `grok_image_${Date.now()}.png`, imageResult.description || '');
              } else {
                await sendTextMessage(chatId, `âŒ ${imageResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”'}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VIDEO GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'veo3_video': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'veo3_video' });
              const videoResult = await generateVideoForWhatsApp(prompt);
              if (videoResult.success && videoResult.videoUrl) {
                await sendFileByUrl(chatId, videoResult.videoUrl, `veo3_video_${Date.now()}.mp4`, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            case 'sora_video': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'sora_video', model: decision.args?.model });
              // Pass model from decision args (defaults to sora-2 in the function)
              const options = decision.args?.model ? { model: decision.args.model } : {};
              const videoResult = await generateVideoWithSoraForWhatsApp(prompt, null, options);
              if (videoResult.success && videoResult.videoUrl) {
                await sendFileByUrl(chatId, videoResult.videoUrl, videoResult.fileName || `sora_video_${Date.now()}.mp4`, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            case 'kling_text_to_video': {
              await sendAck(chatId, { type: 'kling_text_to_video' });
              saveLastCommand(chatId, decision, { normalized });
              const videoResult = await generateKlingVideoFromText(prompt);
              if (videoResult.success && videoResult.videoUrl) {
                await sendFileByUrl(chatId, videoResult.videoUrl, videoResult.fileName || `kling_video_${Date.now()}.mp4`, '');
              } else {
                await sendTextMessage(chatId, `âŒ ${videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××•'}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE/VIDEO EDITING â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'image_edit':
              if (hasImage) {
                const service = decision.args?.service || 'gemini';
                const finalImageUrl = imageUrl || (messageData.fileMessageData || messageData.imageMessageData || messageData.stickerMessageData)?.downloadUrl;
                // Persist last command so retry (# ×©×•×‘) works for outgoing image edits
                await saveLastCommand(chatId, decision, { imageUrl: finalImageUrl, normalized });
                processImageEditAsync({
                  chatId, senderId, senderName,
                  imageUrl: finalImageUrl,
                  prompt: decision.args.prompt || prompt,
                  service: service
                });
              }
              return;
              
            case 'video_to_video':
              if (hasVideo) {
                const finalVideoUrl = videoUrl || (messageData.fileMessageData || messageData.videoMessageData)?.downloadUrl;
                // Persist last command so retry (# ×©×•×‘) works for outgoing video edits
                await saveLastCommand(chatId, decision, { videoUrl: finalVideoUrl, normalized });
                processVideoToVideoAsync({
                  chatId, senderId, senderName,
                  videoUrl: finalVideoUrl,
                  prompt: decision.args?.prompt || prompt
                });
              }
              return;
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• TEXT TRANSLATION (NO TTS) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'translate_text': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'translate_text' });
              
              // Detect target language from prompt (e.g., "×ª×¨×’× ×œ×™×¤× ×™×ª: ×˜×§×¡×˜")
              const languagePatterns = {
                'English': /(×œ?×× ×’×œ×™×ª|\bto\s+english\b|\benglish\b)/i,
                'Spanish': /(×œ?×¡×¤×¨×“×™×ª|\bto\s+spanish\b|\bspanish\b)/i,
                'French': /(×œ?×¦×¨×¤×ª×™×ª|\bto\s+french\b|\bfrench\b)/i,
                'German': /(×œ?×’×¨×× ×™×ª|\bto\s+german\b|\bgerman\b)/i,
                'Italian': /(×œ?××™×˜×œ×§×™×ª|\bto\s+italian\b|\bitalian\b)/i,
                'Portuguese': /(×œ?×¤×•×¨×˜×•×’×–×™×ª|\bto\s+portuguese\b|\bportuguese\b)/i,
                'Russian': /(×œ?×¨×•×¡×™×ª|\bto\s+russian\b|\brussian\b)/i,
                'Chinese': /(×œ?×¡×™× ×™×ª|×œ?×× ×“×¨×™× ×™×ª|\bto\s+chinese\b|\bchinese\b|\bmandarin\b)/i,
                'Japanese': /(×œ?×™×¤× ×™×ª|\bto\s+japanese\b|\bjapanese\b)/i,
                'Korean': /(×œ?×§×•×¨×™×× ×™×ª|\bto\s+korean\b|\bkorean\b)/i,
                'Arabic': /(×œ?×¢×¨×‘×™×ª|\bto\s+arabic\b|\barabic\b)/i,
                'Hindi': /(×œ?×”×™× ×“×™×ª|\bto\s+hindi\b|\bhindi\b)/i,
                'Turkish': /(×œ?×˜×•×¨×§×™×ª|\bto\s+turkish\b|\bturkish\b)/i,
                'Polish': /(×œ?×¤×•×œ× ×™×ª|\bto\s+polish\b|\bpolish\b)/i,
                'Dutch': /(×œ?×”×•×œ× ×“×™×ª|\bto\s+dutch\b|\bdutch\b)/i,
                'Swedish': /(×œ?×©×•×•×“×™×ª|\bto\s+swedish\b|\bswedish\b)/i,
                'Finnish': /(×œ?×¤×™× ×™×ª|\bto\s+finnish\b|\bfinnish\b)/i,
                'Norwegian': /(×œ?× ×•×¨×•×•×’×™×ª|\bto\s+norwegian\b|\bnorwegian\b)/i,
                'Danish': /(×œ?×“× ×™×ª|\bto\s+danish\b|\bdanish\b)/i,
                'Czech': /(×œ?×¦'×›×™×ª|\bto\s+czech\b|\bczech\b)/i,
                'Hebrew': /(×œ?×¢×‘×¨×™×ª|\bto\s+hebrew\b|\bhebrew\b)/i
              };
              
              let targetLanguage = 'English'; // Default
              for (const [langName, pattern] of Object.entries(languagePatterns)) {
                if (pattern.test(prompt)) {
                  targetLanguage = langName;
                  break;
                }
              }
              
              // Extract text to translate (remove translation instructions)
              let textToTranslate = prompt
                .replace(/^(×ª×¨×’×|×ª×¨×’××™|×ª×¨×’××•|×ª×ª×¨×’×|translate)\s+/i, '')
                .replace(new RegExp(`(×œ|to)\\s*${targetLanguage}`, 'i'), '')
                .replace(/[:ï¼š]\s*/, '')
                .trim();
              
              // If text is too short, use the full prompt
              if (textToTranslate.length < 2) {
                textToTranslate = prompt;
              }
              
              console.log(`ğŸŒ Text translation: "${textToTranslate}" â†’ ${targetLanguage}`);
              
              // Translate using Gemini
              const translationResult = await translateText(textToTranslate, targetLanguage);
              
              if (translationResult.success) {
                await sendTextMessage(chatId, `ğŸŒ ×ª×¨×’×•× ×œ${targetLanguage}:\n\n${translationResult.translatedText}`);
              } else {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×ª×¨×’×•×: ${translationResult.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• TEXT-TO-SPEECH â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'text_to_speech': {
              // Ensure decision.args.prompt contains the full prompt for retry functionality
              decision.args.prompt = prompt;
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'text_to_speech' });
              
              // Parse the TTS request to check if translation is needed
              // Use full prompt (not decision.args.text) to include quoted message text
              const originalText = prompt;
              const parseResult = await parseTextToSpeechRequest(originalText);
              
              let textToSpeak = parseResult.text;
              let targetLanguageCode = parseResult.languageCode;
              
              // If translation is needed, translate the text first
              if (parseResult.needsTranslation && parseResult.targetLanguage) {
                console.log(`ğŸŒ Translation requested to ${parseResult.targetLanguage}`);
                const translationResult = await translateText(parseResult.text, parseResult.targetLanguage);
                
                if (translationResult.success) {
                  textToSpeak = translationResult.translatedText;
                  console.log(`âœ… Using translated text: "${textToSpeak}"`);
                } else {
                  await sendTextMessage(chatId, `âŒ ${translationResult.error}`);
                  return;
                }
              } else {
                // No translation needed - detect language from original text
                targetLanguageCode = voiceService.detectLanguage(textToSpeak);
              }
              
              // Get appropriate voice for the target language
              const voiceResult = await voiceService.getVoiceForLanguage(targetLanguageCode);
              if (voiceResult.error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×‘×—×™×¨×ª ×§×•×œ: ${voiceResult.error}`);
                return;
              }
              
              const voiceId = voiceResult.voiceId;
              const ttsResult = await voiceService.textToSpeech(voiceId, textToSpeak, {
                modelId: 'eleven_v3',
                outputFormat: 'mp3_44100_128',
                languageCode: targetLanguageCode
              });
              
              if (!ttsResult.error) {
                const conversionResult = await audioConverterService.convertUrlToOpus(ttsResult.audioUrl, 'mp3');
                if (conversionResult.success) {
                  await sendFileByUrl(chatId, getStaticFileUrl(conversionResult.fileName), conversionResult.fileName, '');
                } else {
                  const fallbackUrl = ttsResult.audioUrl.startsWith('http') ? ttsResult.audioUrl : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
                  await sendFileByUrl(chatId, fallbackUrl, `tts_${Date.now()}.mp3`, '');
                }
              } else {
                await sendTextMessage(chatId, `âŒ ${ttsResult.error}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MUSIC GENERATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'music_generation': {
              saveLastCommand(chatId, decision, { normalized });
              // Parse music request to check if video is requested
              const musicParsing = await parseMusicRequest(prompt);
              const cleanMusicPrompt = musicParsing.cleanPrompt || prompt;
              const wantsVideo = musicParsing.wantsVideo || false;
              
              // Send customized ACK based on whether video is requested
              const ackMsg = wantsVideo 
                ? 'ğŸµğŸ¬ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× ×§×œ×™×¤/×•×™×“××• ×‘×××¦×¢×•×ª Suno AI... ğŸ¶'
                : 'ğŸµ ×§×™×‘×œ×ª×™! ××ª×—×™×œ ×™×¦×™×¨×ª ×©×™×¨ ×¢× Suno AI... ğŸ¶';
              await sendTextMessage(chatId, ackMsg);
              
              const musicResult = await generateMusicWithLyrics(cleanMusicPrompt, {
                callbackUrl: null,
                whatsappContext: { chatId, senderId, senderName },
                makeVideo: wantsVideo
              });
              if (musicResult.error) {
                await sendTextMessage(chatId, `âŒ ${musicResult.error}`);
              } else if (musicResult.message) {
                await sendTextMessage(chatId, musicResult.message);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• POLL CREATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'create_poll': {
              saveLastCommand(chatId, decision, { normalized });
              // Check if user explicitly requested NO rhyming
              // Note: \b word boundaries don't work with Hebrew, so we use a more flexible pattern
              const noRhymePatterns = /(×‘×œ×™|×œ×œ×|×œ×|without|no)\s+(×—×¨×™×–×”|×—×¨×•×–×™×|rhyme|rhymes|rhyming)/i;
              const withRhyme = !noRhymePatterns.test(prompt);
              
              await sendAck(chatId, { type: 'create_poll', withRhyme });
              
              // Extract topic from prompt
              let topic = prompt
                .replace(/^#\s*/, '') // Remove # prefix first
                .replace(/^(×¦×•×¨|×™×¦×¨|×”×›×Ÿ|create|make)\s+(×¡×§×¨|poll)\s+(×¢×œ|×‘× ×•×©×|about)?\s*/i, '')
                .replace(noRhymePatterns, '') // Remove "×‘×œ×™ ×—×¨×™×–×”" etc. from topic
                .trim();
              
              if (!topic || topic.length < 2) {
                topic = prompt;
              }
              
              const pollResult = await generateCreativePoll(topic, withRhyme);
              
              if (!pollResult.success) {
                await sendTextMessage(chatId, `âŒ ${pollResult.error}`);
                return;
              }
              
              // Send the poll using Green API
              try {
                const pollOptions = pollResult.options.map(opt => ({ optionName: opt }));
                
                console.log(`ğŸ“Š Sending poll with ${pollOptions.length} ${withRhyme ? 'rhyming' : 'non-rhyming'} options (outgoing)`);
                await sendPoll(chatId, pollResult.question, pollOptions, false);
                console.log(`âœ… Poll sent successfully to ${chatId}`);
              } catch (pollError) {
                console.error('âŒ Error sending poll:', pollError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”×¡×§×¨: ${pollError.message}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• RANDOM LOCATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'send_random_location': {
              saveLastCommand(chatId, decision, { normalized });
              
              // Check if user requested a specific region
              // Use the prompt text (not normalized object) to extract region
              console.log(`ğŸ“ [OUTGOING] Extracting region from prompt: "${prompt}"`);
              const requestedRegion = await extractRequestedRegion(prompt);
              const requestedRegionName = requestedRegion ? requestedRegion.continentName : null;
              const displayName = requestedRegion ? requestedRegion.displayName : null;
              const isCity = requestedRegion ? requestedRegion.isCity : false;
              console.log(`ğŸ“ [OUTGOING] Extracted region: ${displayName ? `${displayName}${requestedRegionName ? ` (${requestedRegionName})` : isCity ? ' (×¢×™×¨)' : ''}` : 'none'}`);
              const ackMessage = displayName 
                ? `ğŸŒ ×§×™×‘×œ×ª×™! ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ${isCity ? '×‘×¢×™×¨' : '×‘××–×•×¨'} ${displayName}...`
                : 'ğŸŒ ×§×™×‘×œ×ª×™! ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×¢×œ ×›×“×•×¨ ×”××¨×¥...';
              await sendTextMessage(chatId, ackMessage);
              
              // Generate truly random coordinates within populated land areas
              // Using tighter bounding boxes to avoid oceans/seas - subdivided into smaller regions
              // Will retry up to 15 times if location falls in water
              let locationInfo = null;
              let attempts = 0;
              const maxAttempts = 15;
              
              const continents = [
                // EUROPE - subdivided to avoid Mediterranean/Atlantic/Black Sea
                { name: 'Western Europe', minLat: 42, maxLat: 60, minLng: -5, maxLng: 15, weight: 2 },
                { name: 'Eastern Europe', minLat: 44, maxLat: 60, minLng: 15, maxLng: 40, weight: 2 },
                { name: 'Southern Europe', minLat: 36, maxLat: 46, minLng: -9, maxLng: 28, weight: 2 },
                { name: 'Scandinavia', minLat: 55, maxLat: 71, minLng: 5, maxLng: 31, weight: 1 },
                { name: 'UK & Ireland', minLat: 50, maxLat: 60, minLng: -10, maxLng: 2, weight: 1 },
                
                // ASIA - East Asia (subdivided)
                { name: 'China Mainland', minLat: 18, maxLat: 53, minLng: 73, maxLng: 135, weight: 3 },
                { name: 'Japan', minLat: 30, maxLat: 46, minLng: 129, maxLng: 146, weight: 1 },
                { name: 'Korea', minLat: 33, maxLat: 43, minLng: 124, maxLng: 131, weight: 1 },
                
                // ASIA - Southeast Asia (subdivided to avoid Pacific Ocean)
                { name: 'Mainland Southeast Asia', minLat: 5, maxLat: 28, minLng: 92, maxLng: 109, weight: 2 },
                { name: 'Indonesia West', minLat: -11, maxLat: 6, minLng: 95, maxLng: 120, weight: 1 },
                { name: 'Philippines', minLat: 5, maxLat: 19, minLng: 117, maxLng: 127, weight: 1 },
                
                // ASIA - South Asia (tightened to avoid Indian Ocean)
                { name: 'India', minLat: 8, maxLat: 35, minLng: 68, maxLng: 97, weight: 2 },
                { name: 'Pakistan & Afghanistan', minLat: 24, maxLat: 38, minLng: 60, maxLng: 75, weight: 1 },
                
                // MIDDLE EAST (subdivided)
                { name: 'Levant & Turkey', minLat: 31, maxLat: 42, minLng: 26, maxLng: 45, weight: 1 },
                { name: 'Arabian Peninsula', minLat: 12, maxLat: 32, minLng: 34, maxLng: 60, weight: 1 },
                { name: 'Iran', minLat: 25, maxLat: 40, minLng: 44, maxLng: 63, weight: 1 },
                
                // NORTH AMERICA (subdivided to avoid Atlantic/Pacific)
                { name: 'Eastern USA', minLat: 25, maxLat: 50, minLng: -98, maxLng: -67, weight: 2 },
                { name: 'Western USA', minLat: 31, maxLat: 49, minLng: -125, maxLng: -102, weight: 2 },
                { name: 'Eastern Canada', minLat: 43, maxLat: 62, minLng: -95, maxLng: -52, weight: 1 },
                { name: 'Western Canada', minLat: 49, maxLat: 62, minLng: -140, maxLng: -95, weight: 1 },
                
                // CENTRAL AMERICA & MEXICO (tightened)
                { name: 'Mexico', minLat: 14, maxLat: 32, minLng: -118, maxLng: -86, weight: 1 },
                { name: 'Central America', minLat: 7, maxLat: 18, minLng: -93, maxLng: -77, weight: 1 },
                
                // SOUTH AMERICA (subdivided)
                { name: 'Brazil North', minLat: -10, maxLat: 5, minLng: -74, maxLng: -35, weight: 2 },
                { name: 'Brazil South', minLat: -34, maxLat: -10, minLng: -58, maxLng: -35, weight: 1 },
                { name: 'Andean Countries', minLat: -18, maxLat: 12, minLng: -81, maxLng: -66, weight: 1 },
                { name: 'Chile & Argentina', minLat: -55, maxLat: -22, minLng: -75, maxLng: -53, weight: 1 },
                
                // AFRICA (subdivided)
                { name: 'North Africa', minLat: 15, maxLat: 37, minLng: -17, maxLng: 52, weight: 2 },
                { name: 'West Africa', minLat: 4, maxLat: 20, minLng: -17, maxLng: 16, weight: 1 },
                { name: 'East Africa', minLat: -12, maxLat: 16, minLng: 22, maxLng: 51, weight: 1 },
                { name: 'Southern Africa', minLat: -35, maxLat: -15, minLng: 11, maxLng: 42, weight: 1 },
                
                // OCEANIA (tightened)
                { name: 'Australia', minLat: -44, maxLat: -10, minLng: 113, maxLng: 154, weight: 2 },
                { name: 'New Zealand', minLat: -47, maxLat: -34, minLng: 166, maxLng: 179, weight: 1 }
              ];
              
              // Check if specific country/city bounds are available (more precise than continent)
              const hasSpecificBounds = requestedRegion && requestedRegion.bounds;
              const isCityLocation = requestedRegion && requestedRegion.isCity === true;
              
              // Filter continents if specific region requested (but use country/city bounds if available)
              let availableContinents = continents;
              
              // Check if this is a multi-region request (e.g., "Europe", "Asia")
              const hasMultiRegions = requestedRegion && requestedRegion.multiRegions && Array.isArray(requestedRegion.multiRegions);
              
              if (requestedRegionName && !hasSpecificBounds) {
                if (hasMultiRegions) {
                  // Multi-region: filter to multiple specific continents
                  console.log(`ğŸ¯ [OUTGOING] Multi-region request: "${displayName}" includes ${requestedRegion.multiRegions.length} regions`);
                  availableContinents = continents.filter(c => requestedRegion.multiRegions.includes(c.name));
                  console.log(`ğŸ¯ [OUTGOING] Filtered to ${availableContinents.length} continents: ${availableContinents.map(c => c.name).join(', ')}`);
                  
                  if (availableContinents.length === 0) {
                    console.log(`âš ï¸ [OUTGOING] No continents found for multi-region "${displayName}", falling back to all regions`);
                    await sendTextMessage(chatId, `âŒ ×œ× ××¦××ª×™ ××–×•×¨×™× ×¢×‘×•×¨ "${displayName}". ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×‘×›×œ ×”×¢×•×œ×...`);
                    availableContinents = continents; // Fallback to all regions
                  } else {
                    console.log(`âœ… [OUTGOING] Multi-region filtered successfully: ${displayName} (${availableContinents.length} regions)`);
                  }
                } else {
                  // Single region/continent
                  console.log(`ğŸ¯ [OUTGOING] Filtering continents to region: "${requestedRegionName}"`);
                  console.log(`ğŸ¯ [OUTGOING] Available continent names: ${continents.map(c => c.name).join(', ')}`);
                  availableContinents = continents.filter(c => c.name === requestedRegionName);
                  console.log(`ğŸ¯ [OUTGOING] Filtered continents count: ${availableContinents.length}`);
                  if (availableContinents.length === 0) {
                    console.log(`âš ï¸ [OUTGOING] No continent found matching "${requestedRegionName}", falling back to all regions`);
                    await sendTextMessage(chatId, `âŒ ×œ× ××¦××ª×™ ××–×•×¨ ×‘×©× "${requestedRegionName}". ×‘×•×—×¨ ××™×§×•× ××§×¨××™ ×‘×›×œ ×”×¢×•×œ×...`);
                    availableContinents = continents; // Fallback to all regions
                  } else {
                    console.log(`âœ… [OUTGOING] Filtered to region: ${requestedRegionName} (${availableContinents.length} continent(s))`);
                  }
                }
              } else if (hasSpecificBounds) {
                if (isCityLocation) {
                  console.log(`ğŸ¯ [OUTGOING] Using specific city bounds for ${displayName}: lat ${requestedRegion.bounds.minLat}-${requestedRegion.bounds.maxLat}, lng ${requestedRegion.bounds.minLng}-${requestedRegion.bounds.maxLng}`);
                } else {
                  console.log(`ğŸ¯ [OUTGOING] Using specific country bounds for ${displayName}: lat ${requestedRegion.bounds.minLat}-${requestedRegion.bounds.maxLat}, lng ${requestedRegion.bounds.minLng}-${requestedRegion.bounds.maxLng}`);
                }
              } else {
                console.log(`ğŸŒ [OUTGOING] No region filter - using all continents`);
              }
              
              // Retry loop to avoid water locations
              // Track if we should use bounds or fallback to continent
              let useBoundsForGeneration = hasSpecificBounds;
              
              while (attempts < maxAttempts && !locationInfo) {
                attempts++;
                console.log(`ğŸ² [OUTGOING] Attempt ${attempts}/${maxAttempts} to find land location...`);
                
                let latitude, longitude, regionName;
                
                if (useBoundsForGeneration && requestedRegion && requestedRegion.bounds) {
                  // Use specific country/city bounds with validation
                  const bounds = requestedRegion.bounds;
                  
                  // Validate bounds before using
                  if (bounds && 
                      typeof bounds.minLat === 'number' && typeof bounds.maxLat === 'number' &&
                      typeof bounds.minLng === 'number' && typeof bounds.maxLng === 'number' &&
                      bounds.minLat < bounds.maxLat && bounds.minLng < bounds.maxLng &&
                      bounds.minLat >= -90 && bounds.maxLat <= 90 &&
                      bounds.minLng >= -180 && bounds.maxLng <= 180) {
                    latitude = (Math.random() * (bounds.maxLat - bounds.minLat) + bounds.minLat).toFixed(6);
                    longitude = (Math.random() * (bounds.maxLng - bounds.minLng) + bounds.minLng).toFixed(6);
                    regionName = displayName;
                  } else {
                    console.warn(`âš ï¸ [OUTGOING] Invalid bounds detected, falling back to continent-based generation`);
                    useBoundsForGeneration = false; // Fallback to continent-based
                    // Will continue to else block below
                  }
                }
                
                // If bounds were invalid or not available, use continent-based generation
                if (!useBoundsForGeneration || !latitude || !longitude) {
                  // Weighted random selection from continents (some regions more populous than others)
                  const totalWeight = availableContinents.reduce((sum, c) => sum + c.weight, 0);
                  if (totalWeight === 0) {
                    console.error(`âŒ [OUTGOING] No available continents, using first continent as fallback`);
                    availableContinents = [continents[0]];
                  }
                  
                  let randomWeight = Math.random() * availableContinents.reduce((sum, c) => sum + c.weight, 0);
                  let selectedContinent = availableContinents[0];
                  
                  for (const continent of availableContinents) {
                    randomWeight -= continent.weight;
                    if (randomWeight <= 0) {
                      selectedContinent = continent;
                      break;
                    }
                  }
                  
                  // Generate random coordinates within the selected region
                  latitude = (Math.random() * (selectedContinent.maxLat - selectedContinent.minLat) + selectedContinent.minLat).toFixed(6);
                  longitude = (Math.random() * (selectedContinent.maxLng - selectedContinent.minLng) + selectedContinent.minLng).toFixed(6);
                  regionName = selectedContinent.name;
                }
                
                console.log(`ğŸŒ [OUTGOING] Generated random location in ${regionName}: ${latitude}, ${longitude}`);
                
                // Get location information from Gemini with Google Maps grounding
                const tempLocationInfo = await getLocationInfo(parseFloat(latitude), parseFloat(longitude));
                
                // Check if location is valid (not in water/ocean)
                if (tempLocationInfo.success && tempLocationInfo.description) {
                  if (isLandLocation(tempLocationInfo.description)) {
                    // Valid land location found!
                    locationInfo = { ...tempLocationInfo, latitude, longitude };
                    console.log(`âœ… Found valid land location on attempt ${attempts}`);
                  } else {
                    console.log(`âš ï¸ Location is in open water, retrying... (${tempLocationInfo.description.substring(0, 80)})`);
                  }
                } else {
                  console.log(`âš ï¸ Location info failed, retrying...`);
                }
              }
              
              // If no valid location found after max attempts, use last one anyway
              if (!locationInfo) {
                await sendTextMessage(chatId, `âŒ ×œ× ×”×¦×œ×—×ª×™ ×œ××¦×•× ××™×§×•× ×ª×§×™×Ÿ ××—×¨×™ ${maxAttempts} × ×™×¡×™×•× ×•×ª`);
                return;
              }
              
              // Send the location with description
              try {
                await sendLocation(chatId, parseFloat(locationInfo.latitude), parseFloat(locationInfo.longitude), '', '');
                await sendTextMessage(chatId, `ğŸ“ ${locationInfo.description}`);
                console.log(`âœ… Random location sent to ${chatId}`);
              } catch (locationError) {
                console.error('âŒ Error sending location:', locationError);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”××™×§×•×: ${locationError.message}`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CHAT SUMMARY â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'chat_summary': {
              saveLastCommand(chatId, decision, { normalized });
              await sendAck(chatId, { type: 'chat_summary' });
              const chatHistory = await getChatHistory(chatId, CHAT_HISTORY_LIMIT);
              if (chatHistory && chatHistory.length > 0) {
                const summaryResult = await generateChatSummary(chatHistory);
                if (!summaryResult.error) {
                  await sendTextMessage(chatId, `ğŸ“ **×¡×™×›×•× ×”×©×™×—×”:**\n\n${summaryResult.text}`);
                }
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• HELP / COMMAND LIST â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'show_help': {
              const helpText = `
ğŸ¤– **××¢×¨×›×ª AI ××ª×§×“××ª**

**×¤×§×•×“×•×ª AI (××ª×—×™×œ×•×ª ×‘-"# "):**
â€¢ # ×”×™×™ - ×©×™×—×” ×¢× Gemini
â€¢ # ×¦×•×¨ ×ª××•× ×” ×©×œ... - ×™×¦×™×¨×ª ×ª××•× ×”
â€¢ # ×¦×•×¨ ×•×™×“××• ×©×œ... - ×™×¦×™×¨×ª ×•×™×“××•
â€¢ # ×¦×•×¨ ×©×™×¨ ×¢×œ... - ×™×¦×™×¨×ª ××•×–×™×§×”
â€¢ # ×”××¨ ×œ×“×™×‘×•×¨: ×˜×§×¡×˜ - Text-to-Speech
â€¢ # ×¡×›× ×©×™×—×” - ×¡×™×›×•× ×”×©×™×—×”
â€¢ # ×¦×•×¨ ×¡×§×¨ ×¢×œ/×‘× ×•×©×... - ×™×¦×™×¨×ª ×¡×§×¨ ×¢× ×—×¨×•×–×™× (×‘×¨×™×¨×ª ××—×“×œ)
â€¢ # ×¦×•×¨ ×¡×§×¨ ×¢×œ/×‘× ×•×©×... ×‘×œ×™ ×—×¨×™×–×” - ×™×¦×™×¨×ª ×¡×§×¨ ×œ×œ× ×—×¨×•×–×™×
â€¢ # ×©×œ×— ××™×§×•× / # ××™×§×•× ××§×¨××™ - ××™×§×•× ××§×¨××™ ×¢×œ ××¤×ª ×”×¢×•×œ×
â€¢ # × ×¡×” ×©×•×‘ / # ×©×•×‘ - ×‘×™×¦×•×¢ ××—×“×© ×¤×§×•×“×” ××—×¨×•× ×”
â€¢ # ×¦×•×¨/×¤×ª×—/×”×§× ×§×‘×•×¦×” ×‘×©× "×©×" ×¢× ×©×1, ×©×2 - ×™×¦×™×¨×ª ×§×‘×•×¦×”
â€¢ (××•×¤×¦×™×”) + ×¢× ×ª××•× ×” ×©×œ... - ×”×•×¡×¤×ª ×ª××•× ×ª ×¤×¨×•×¤×™×œ
â€¢ ×ª××•× ×” + # ×¢×¨×•×š... - ×¢×¨×™×›×ª ×ª××•× ×”
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×¢×¨×‘×‘/××™×§×¡ - ××™×§×¡ ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™×
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×¢× ×” ×œ×–×”/×ª×’×™×‘ - ×ª×’×•×‘×” ×§×•×œ×™×ª ×¢× ×©×™×‘×•×˜ ×§×•×œ
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×ª××œ×œ - ×ª××œ×•×œ ×‘×œ×‘×“
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×ª×¨×’× ×œ×©×•×•×“×™×ª - ×ª××œ×•×œ + ×ª×¨×’×•× (×˜×§×¡×˜)
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª + # ×××•×¨ ×‘×™×¤× ×™×ª - ×ª××œ×•×œ + ×ª×¨×’×•× + TTS
â€¢ ×•×™×“××• + # ×¢×¨×•×š... - ×¢×¨×™×›×ª ×•×™×“××•
â€¢ ×”×•×“×¢×” ×§×•×œ×™×ª - ×ª××œ×•×œ ×•×ª×©×•×‘×” ×§×•×œ×™×ª

**×¤×§×•×“×•×ª × ×™×”×•×œ:**
â€¢ ×”×¦×’ ×”×™×¡×˜×•×¨×™×” - ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”
â€¢ ×¡×˜×˜×•×¡ ×™×¦×™×¨×” - ×”×¨×©××•×ª ×™×¦×™×¨×ª ××“×™×”
â€¢ ×”×•×¡×£ ×œ×™×¦×™×¨×” [×©×] - ×”×•×¡×£ ×”×¨×©××ª ××“×™×”
â€¢ ×”×¡×¨ ××™×¦×™×¨×” [×©×] - ×”×¡×¨ ×”×¨×©××ª ××“×™×”
â€¢ ×¡×˜×˜×•×¡ ×§×‘×•×¦×•×ª - ×”×¨×©××•×ª ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª
â€¢ ×”×•×¡×£ ×œ×§×‘×•×¦×•×ª [×©×] - ×”×•×¡×£ ×”×¨×©××ª ×§×‘×•×¦×•×ª
â€¢ ×”×¡×¨ ××§×‘×•×¦×•×ª [×©×] - ×”×¡×¨ ×”×¨×©××ª ×§×‘×•×¦×•×ª
â€¢ ×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨ - ×¡× ×›×¨×•×Ÿ ×× ×©×™ ×§×©×¨
              `;
              await sendTextMessage(chatId, helpText.trim());
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• IMAGE/VIDEO GENERATION FROM TEXT â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'veo3_image_to_video':
            case 'sora_image_to_video':
            case 'kling_image_to_video': {
              // These require an image - check if one was provided via quoted message
              if (hasImage && imageUrl) {
                let service;
                if (decision.tool === 'veo3_image_to_video') {
                  service = 'veo3';
                } else if (decision.tool === 'sora_image_to_video') {
                  service = 'sora';
                } else {
                  service = 'kling';
                }
                const model = decision.args?.model;
                console.log(`ğŸ¬ ${service} image-to-video request from text command (outgoing)`);
                // Persist last command so retry (# ×©×•×‘) works for outgoing image-to-video
                await saveLastCommand(chatId, decision, { imageUrl, normalized });
                processImageToVideoAsync({
                  chatId, senderId, senderName,
                  imageUrl: imageUrl,
                  prompt: prompt,
                  service: service,
                  model: model
                });
              } else {
                await sendTextMessage(chatId, 'âŒ ×¤×§×•×“×” ×–×• ×“×•×¨×©×ª ×ª××•× ×”. ×× × ×¢× ×” ×¢×œ ×”×•×“×¢×” ×¢× ×ª××•× ×” ××• ×©×œ×— ×ª××•× ×” ×¢× caption.');
              }
              return;
            }
            
            case 'veo3_video':
            case 'kling_text_to_video': {
              saveLastCommand(chatId, decision, { normalized });
              const service = decision.tool === 'veo3_video' ? 'veo3' : 'kling';
              console.log(`ğŸ¬ ${service} text-to-video request (outgoing)`);
              await sendAck(chatId, { type: decision.tool });
              
              // Text-to-video
              const videoGenFunction = service === 'veo3' ? generateVideoForWhatsApp : generateKlingVideoFromText;
              const result = await videoGenFunction(prompt);
              
              if (result.error) {
                await sendTextMessage(chatId, `âŒ ${result.error}`);
              } else if (result.success && result.videoUrl) {
                const fullUrl = result.videoUrl.startsWith('http') ? result.videoUrl : getStaticFileUrl(result.videoUrl.replace('/static/', ''));
                await sendFileByUrl(chatId, fullUrl, result.fileName, result.description || prompt);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CREATE GROUP (OUTGOING) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'create_group': {
              saveLastCommand(chatId, decision, { normalized });
              try {
                await sendTextMessage(chatId, 'ğŸ‘¥ ××ª×—×™×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”...');
                
                const { parseGroupCreationPrompt, resolveParticipants } = require('../services/groupService');
                const { createGroup, setGroupPicture } = require('../services/greenApiService');
                const { generateImageForWhatsApp } = require('../services/geminiService');
                
                // Step 1: Parse the prompt to extract group name, participants, and picture description
                await sendTextMessage(chatId, 'ğŸ” ×× ×ª×— ××ª ×”×‘×§×©×”...');
                const parsed = await parseGroupCreationPrompt(prompt);
                
                let statusMsg = `ğŸ“‹ ×©× ×”×§×‘×•×¦×”: "${parsed.groupName}"\nğŸ‘¥ ××—×¤×© ${parsed.participants.length} ××©×ª×ª×¤×™×...`;
                if (parsed.groupPicture) {
                  statusMsg += `\nğŸ¨ ×ª××•× ×”: ${parsed.groupPicture}`;
                }
                await sendTextMessage(chatId, statusMsg);
                
                // Step 2: Resolve participant names to WhatsApp IDs
                const resolution = await resolveParticipants(parsed.participants);
                
                // Check if we found all participants
                if (resolution.notFound.length > 0) {
                  let errorMsg = `âš ï¸ ×œ× ××¦××ª×™ ××ª ×”××©×ª×ª×¤×™× ×”×‘××™×:\n`;
                  resolution.notFound.forEach(name => {
                    errorMsg += `â€¢ ${name}\n`;
                  });
                  errorMsg += `\nğŸ’¡ ×˜×™×¤: ×•×•×“× ×©×”×©××•×ª × ×›×•× ×™× ××• ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ×× ×©×™ ×§×©×¨`;
                  
                  if (resolution.resolved.length === 0) {
                    await sendTextMessage(chatId, errorMsg + '\n\nâŒ ×œ× × ××¦××• ××©×ª×ª×¤×™× - ×‘×™×˜×•×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”');
                    return;
                  }
                  
                  await sendTextMessage(chatId, errorMsg);
                }
                
                // Step 3: Show found participants
                if (resolution.resolved.length > 0) {
                  let foundMsg = `âœ… × ××¦××• ${resolution.resolved.length} ××©×ª×ª×¤×™×:\n`;
                  resolution.resolved.forEach(p => {
                    foundMsg += `â€¢ ${p.searchName} â†’ ${p.contactName}\n`;
                  });
                  await sendTextMessage(chatId, foundMsg);
                }
                
                // Step 4: Create the group
                await sendTextMessage(chatId, 'ğŸ”¨ ×™×•×¦×¨ ××ª ×”×§×‘×•×¦×”...');
                
                // Filter out the current user (group creator) - WhatsApp adds them automatically
                const participantIds = resolution.resolved
                  .map(p => p.contactId)
                  .filter(id => id !== senderId); // Remove group creator from participants list
                
                if (participantIds.length === 0) {
                  await sendTextMessage(chatId, 'âš ï¸ ×œ× × ××¦××• ××©×ª×ª×¤×™× × ×•×¡×¤×™× (×—×•×¥ ×××š). ×¦×¨×™×š ×œ×¤×—×•×ª ××©×ª×ª×£ ××—×“ × ×•×¡×£ ×œ×™×¦×™×¨×ª ×§×‘×•×¦×”.');
                  return;
                }
                
                console.log(`ğŸ‘¥ Final participants (excluding creator ${senderId}): ${participantIds.join(', ')}`);
                const groupResult = await createGroup(parsed.groupName, participantIds);
                
                // Step 5: Generate and set group picture if requested
                if (parsed.groupPicture && groupResult.chatId) {
                  try {
                    await sendTextMessage(chatId, `ğŸ¨ ×™×•×¦×¨ ×ª××•× ×ª ×¤×¨×•×¤×™×œ ×œ×§×‘×•×¦×”...\n"${parsed.groupPicture}"`);
                    
                    // Generate image with Gemini
                    const imageResult = await generateImageForWhatsApp(parsed.groupPicture);
                    
                    if (imageResult.success && imageResult.fileName) {
                      // Read the generated image file
                      const fs = require('fs');
                      const path = require('path');
                      const imagePath = path.join(__dirname, '..', 'public', 'tmp', imageResult.fileName);
                      const imageBuffer = fs.readFileSync(imagePath);
                      
                      // Set as group picture
                      await sendTextMessage(chatId, 'ğŸ–¼ï¸ ××¢×œ×” ×ª××•× ×” ×œ×§×‘×•×¦×”...');
                      const pictureResult = await setGroupPicture(groupResult.chatId, imageBuffer);
                      
                      if (pictureResult.setGroupPicture) {
                        await sendTextMessage(chatId, 'âœ… ×ª××•× ×ª ×”×§×‘×•×¦×” ×”×•×¢×œ×ª×” ×‘×”×¦×œ×—×”!');
                      } else {
                        await sendTextMessage(chatId, `âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×¢×œ×•×ª ×ª××•× ×”: ${pictureResult.reason || '×¡×™×‘×” ×œ× ×™×“×•×¢×”'}`);
                      }
                      
                      // Clean up the image file
                      try {
                        fs.unlinkSync(imagePath);
                        console.log(`ğŸ§¹ Cleaned up group picture file: ${imageResult.fileName}`);
                      } catch (cleanupError) {
                        console.warn('âš ï¸ Could not clean up group picture file:', cleanupError.message);
                      }
                    } else {
                      await sendTextMessage(chatId, `âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª××•× ×”: ${imageResult.error || '×©×’×™××” ×œ× ×™×“×•×¢×”'}`);
                    }
                  } catch (pictureError) {
                    console.error('âŒ Error setting group picture:', pictureError);
                    await sendTextMessage(chatId, `âš ï¸ ×”×§×‘×•×¦×” × ×•×¦×¨×” ××‘×œ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×•×¡×™×£ ×ª××•× ×”: ${pictureError.message}`);
                  }
                }
                
                // Step 6: Success!
                const successMsg = `âœ… ×”×§×‘×•×¦×” "${parsed.groupName}" × ×•×¦×¨×” ×‘×”×¦×œ×—×”! ğŸ‰\n\nğŸ‘¥ ${participantIds.length + 1} ××©×ª×ª×¤×™× ×‘×§×‘×•×¦×” (×›×•×œ×œ ××ª×”)`;
                await sendTextMessage(chatId, successMsg);
                
                console.log(`âœ… Group created successfully by ${senderName}: "${parsed.groupName}" with ${participantIds.length} other participants${parsed.groupPicture ? ' (with picture)' : ''}`);
                
              } catch (error) {
                console.error('âŒ Error creating group (outgoing):', error);
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×§×‘×•×¦×”: ${error.message}\n\nğŸ’¡ ×•×•×“× ×©×”×¤×•×¨××˜ × ×›×•×Ÿ, ×œ×“×•×’××”:\n# ×¦×•×¨/×¤×ª×—/×”×§× ×§×‘×•×¦×” ×‘×©× "×©× ×”×§×‘×•×¦×”" ×¢× ×©×1, ×©×2, ×©×3\n# ×¦×•×¨ ×§×‘×•×¦×” ×‘×©× "×©×" ×¢× ×©×1, ×©×2 ×¢× ×ª××•× ×” ×©×œ ×—×ª×•×œ`);
              }
              return;
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VOICE/AUDIO PROCESSING (OUTGOING) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            case 'creative_voice_processing': {
              // Creative audio processing with effects and background music (outgoing)
              if (!audioUrl) {
                await sendTextMessage(chatId, 'âŒ ×œ× × ××¦× ×§×•×‘×¥ ××•×“×™×• ××¦×•×˜×˜. ×¦×˜×˜ ×”×•×“×¢×” ×§×•×œ×™×ª ×•× ×¡×” ×©×•×‘.');
                return;
              }
              
              saveLastCommand(chatId, decision, { audioUrl, normalized });
              await sendAck(chatId, { type: 'creative_voice_processing' });
              
              await handleCreativeVoiceMessage({ chatId, senderId, senderName, audioUrl });
              return;
            }
            
            case 'voice_cloning_response': {
              // Voice cloning with Gemini response (outgoing)
              if (!audioUrl) {
                await sendTextMessage(chatId, 'âŒ ×œ× × ××¦× ×§×•×‘×¥ ××•×“×™×• ××¦×•×˜×˜. ×¦×˜×˜ ×”×•×“×¢×” ×§×•×œ×™×ª ×•× ×¡×” ×©×•×‘.');
                return;
              }
              
              saveLastCommand(chatId, decision, { audioUrl, normalized });
              await sendAck(chatId, { type: 'voice_cloning_response' });
              
              await handleVoiceMessage({ chatId, senderId, senderName, audioUrl });
              return;
            }
            
            default:
              console.log(`âš ï¸ Unknown tool from router (outgoing): ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unknown tool from router (outgoing): ${decision.tool}`);
              break;
          }
          
          // Break out of while loop after successful execution (unless retry continues)
          break;
          
          } // End of while loop
        } catch (toolError) {
          console.error(`âŒ Error executing tool ${decision.tool} (outgoing):`, toolError);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”: ${toolError.message || toolError}`);
        }
      } catch (routerError) {
        console.error('âŒ Intent router (outgoing text) error:', routerError.message || routerError);
        await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×‘ ×”×‘×§×©×”: ${routerError.message || routerError}`);
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle IMAGE/STICKER messages with caption starting with "# " (OUTGOING)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if (messageData.typeMessage === 'imageMessage' || messageData.typeMessage === 'stickerMessage') {
      const imageData = messageData.fileMessageData || messageData.imageMessageData || messageData.stickerMessageData;
      const caption = imageData?.caption || '';
      
      if (/^#\s+/.test(caption.trim())) {
        try {
          const chatId = senderData.chatId;
          const senderId = senderData.sender;
          const senderName = senderData.senderName || senderId;
          const senderContactName = senderData.senderContactName || "";
          const chatName = senderData.chatName || "";
          
          // Extract the prompt (remove "# " prefix)
          const basePrompt = caption.trim().replace(/^#\s+/, '').trim();
          
          // Check if this is a quoted/replied message
          const quotedMessage = messageData.quotedMessage;
          // Validate that quotedMessage has actual content (not just leftover metadata)
          const isActualQuote = quotedMessage && quotedMessage.stanzaId && quotedMessage.typeMessage;
          let finalPrompt = basePrompt;
          let hasImage = true; // Current message is image
          let hasVideo = false;
          let imageUrl = imageData.downloadUrl; // Start with current image
          let videoUrl = null;
          
          if (isActualQuote) {
            console.log(`ğŸ”— Outgoing Image: Detected quoted message with stanzaId: ${quotedMessage.stanzaId}`);
            
            // Handle quoted message - merge content
            const quotedResult = await handleQuotedMessage(quotedMessage, basePrompt, chatId);
            
            // Check if there was an error processing the quoted message
            if (quotedResult.error) {
              await sendTextMessage(chatId, quotedResult.error);
              return;
            }
            
            finalPrompt = quotedResult.prompt;
            // Note: hasImage stays true for current message, but we might override with quoted
            if (quotedResult.hasImage || quotedResult.hasVideo) {
              // Quoted message has media - use that instead
              hasImage = quotedResult.hasImage;
              hasVideo = quotedResult.hasVideo;
              imageUrl = quotedResult.imageUrl;
              videoUrl = quotedResult.videoUrl;
            }
          }
          
          const normalized = {
            userText: `# ${finalPrompt}`,
            hasImage: hasImage,
            hasVideo: hasVideo,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: { media_creation: true, group_creation: true, voice_allowed: true } // Outgoing = admin
          };

          const decision = await routeIntent(normalized);
          const prompt = normalized.userText.replace(/^#\s+/, '').trim();

          switch (decision.tool) {
            case 'image_edit': {
              const service = decision.args?.service || 'gemini';
              console.log(`ğŸ¨ ${service} image edit request (outgoing, via router)`);
              // Persist last command so retry (# ×©×•×‘) works for outgoing image edits
              await saveLastCommand(chatId, decision, { imageUrl, normalized });
              processImageEditAsync({
                chatId, senderId, senderName,
                imageUrl: imageUrl, // Use the URL (either from current message or quoted)
                prompt: decision.args?.prompt || prompt,
                service: service
              });
              return;
            }
            
            case 'veo3_video':
            case 'veo3_image_to_video':
            case 'sora_image_to_video':
            case 'kling_text_to_video':
            case 'kling_image_to_video': {
              let service;
              if (decision.tool === 'veo3_video' || decision.tool === 'veo3_image_to_video') {
                service = 'veo3';
              } else if (decision.tool === 'sora_image_to_video') {
                service = 'sora';
              } else {
                service = 'kling';
              }
              console.log(`ğŸ¬ ${service} image-to-video request (outgoing, via router)`);
              const model = decision.args?.model; // Pass model for Sora Pro/regular
              await saveLastCommand(chatId, decision, { imageUrl, normalized });
              processImageToVideoAsync({
                chatId, senderId, senderName,
                imageUrl: imageUrl, // Use the URL (either from current message or quoted)
                prompt: decision.args?.prompt || prompt,
                service: service,
                model: model
              });
              return;
            }
            
            case 'gemini_chat': {
              saveLastCommand(chatId, decision, { imageUrl, normalized });
              await sendAck(chatId, { type: 'gemini_chat' });
              // Image analysis - use analyzeImageWithText
              const { analyzeImageWithText } = require('../services/geminiService');
              try {
                // Download the image from URL
                const imageBuffer = await downloadFile(imageUrl);
                const base64Image = imageBuffer.toString('base64');
                
                const result = await analyzeImageWithText(prompt, base64Image);
                if (result.success) {
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              } catch (error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×ª××•× ×”: ${error.message}`);
              }
              return;
            }
            
            default:
              console.log(`âš ï¸ Unexpected tool for image (outgoing): ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unexpected tool for image (outgoing): ${decision.tool}`);
              return;
          }
        } catch (error) {
          console.error('âŒ Error routing outgoing image message:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×ª××•× ×”: ${error.message || error}`);
        }
      }
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle VIDEO messages with caption starting with "# " (OUTGOING)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else if (messageData.typeMessage === 'videoMessage') {
      const videoData = messageData.fileMessageData || messageData.videoMessageData;
      const caption = videoData?.caption || '';
      
      if (/^#\s+/.test(caption.trim())) {
        try {
          const chatId = senderData.chatId;
          const senderId = senderData.sender;
          const senderName = senderData.senderName || senderId;
          const senderContactName = senderData.senderContactName || "";
          const chatName = senderData.chatName || "";
          
          // Extract the prompt (remove "# " prefix)
          const basePrompt = caption.trim().replace(/^#\s+/, '').trim();
          
          // Check if this is a quoted/replied message
          const quotedMessage = messageData.quotedMessage;
          // Validate that quotedMessage has actual content (not just leftover metadata)
          const isActualQuote = quotedMessage && quotedMessage.stanzaId && quotedMessage.typeMessage;
          let finalPrompt = basePrompt;
          let hasImage = false;
          let hasVideo = true; // Current message is video
          let imageUrl = null;
          let videoUrl = videoData.downloadUrl; // Start with current video
          
          if (isActualQuote) {
            console.log(`ğŸ”— Outgoing Video: Detected quoted message with stanzaId: ${quotedMessage.stanzaId}`);
            
            // Handle quoted message - merge content
            const quotedResult = await handleQuotedMessage(quotedMessage, basePrompt, chatId);
            
            // Check if there was an error processing the quoted message
            if (quotedResult.error) {
              await sendTextMessage(chatId, quotedResult.error);
              return;
            }
            
            finalPrompt = quotedResult.prompt;
            // Note: hasVideo stays true for current message, but we might override with quoted
            if (quotedResult.hasImage || quotedResult.hasVideo) {
              // Quoted message has media - use that instead
              hasImage = quotedResult.hasImage;
              hasVideo = quotedResult.hasVideo;
              imageUrl = quotedResult.imageUrl;
              videoUrl = quotedResult.videoUrl;
            }
          }
          
          const normalized = {
            userText: `# ${finalPrompt}`,
            hasImage: hasImage,
            hasVideo: hasVideo,
            hasAudio: false,
            chatType: chatId && chatId.endsWith('@g.us') ? 'group' : chatId && chatId.endsWith('@c.us') ? 'private' : 'unknown',
            language: 'he',
            authorizations: { media_creation: true, group_creation: true, voice_allowed: true } // Outgoing = admin
          };

          const decision = await routeIntent(normalized);
          const prompt = decision.args?.prompt || finalPrompt;

          switch (decision.tool) {
            case 'gemini_chat': {
              saveLastCommand(chatId, decision, { videoUrl, normalized });
              await sendAck(chatId, { type: 'gemini_chat' });
              // Video analysis - use analyzeVideoWithText
              const { analyzeVideoWithText } = require('../services/geminiService');
              try {
                // Download the video from URL
                const videoBuffer = await downloadFile(videoUrl);
                
                const result = await analyzeVideoWithText(prompt, videoBuffer);
                if (result.success) {
                  await sendTextMessage(chatId, result.text);
                } else {
                  await sendTextMessage(chatId, `âŒ ${result.error}`);
                }
              } catch (error) {
                await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”×•×™×“××•: ${error.message}`);
              }
              return;
            }
            
            case 'video_to_video': {
              console.log(`ğŸ¬ RunwayML Gen4 video-to-video request (outgoing, via router)`);
              await saveLastCommand(chatId, decision, { videoUrl, normalized });
              processVideoToVideoAsync({
                chatId, senderId, senderName,
                videoUrl: videoUrl, // Use the URL (either from current message or quoted)
                prompt: decision.args?.prompt || prompt
              });
              return;
            }
            
            default:
              console.log(`âš ï¸ Unexpected tool for video (outgoing): ${decision.tool}`);
              await sendTextMessage(chatId, `âš ï¸ Unexpected tool for video (outgoing): ${decision.tool}`);
              return;
          }
        } catch (error) {
          console.error('âŒ Error routing outgoing video message:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×•×™×“××•: ${error.message || error}`);
        }
      }
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Handle voice messages - but skip processing for outgoing messages
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else if (messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage') {
      const audioData = messageData.fileMessageData || messageData.audioMessageData;
      
      console.log(`ğŸ¤ Outgoing voice message received - skipping voice processing (only process incoming voice messages)`);
      // Don't process outgoing voice messages to avoid unwanted transcription
    } else if (messageText) {
      // Handle admin shortcut commands that use current contact (no explicit name)
      const trimmed = messageText.trim();
      if (trimmed === '×”×•×¡×£ ×œ×™×¦×™×¨×”') {
        // Resolve current contact name using same priority logic as auth store
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for add to media authorization');
        } else {
          const wasAdded = await authStore.addAuthorizedUser(contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Added ${contactName} to media creation authorization (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×•×¡×£ ×œ×ª××œ×•×œ') {
        // Resolve current contact name as above
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for add to transcription');
        } else {
          const wasAdded = await conversationManager.addToVoiceAllowList(contactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${contactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Added ${contactName} to voice allow list (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×¡×¨ ××™×¦×™×¨×”') {
        // Resolve current contact name
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for remove from media authorization');
        } else {
          const wasRemoved = await authStore.removeAuthorizedUser(contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Removed ${contactName} from media creation authorization (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        }
        return; // Stop further processing for this message
      }

      if (trimmed === '×”×¡×¨ ××ª××œ×•×œ') {
        // Resolve current contact name
        const isGroupChat = chatId && chatId.endsWith('@g.us');
        const isPrivateChat = chatId && chatId.endsWith('@c.us');
        let contactName = '';
        if (isGroupChat) {
          contactName = senderData.chatName || senderName;
        } else if (isPrivateChat) {
          if (senderData.senderContactName && senderData.senderContactName.trim()) {
            contactName = senderData.senderContactName;
          } else if (senderData.chatName && senderData.chatName.trim()) {
            contactName = senderData.chatName;
          } else {
            contactName = senderName;
          }
        } else {
          contactName = senderData.senderContactName || senderData.chatName || senderName;
        }

        if (!contactName || !contactName.trim()) {
          console.warn('âš ï¸ Could not resolve contact name for remove from transcription');
        } else {
          const wasRemoved = await conversationManager.removeFromVoiceAllowList(contactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${contactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Removed ${contactName} from voice allow list (current chat) by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${contactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        }
        return; // Stop further processing for this message
      }

      // Non-"#" text messages - handle management commands only
      const command = parseTextCommand(messageText);
      if (command) {
        await handleManagementCommand(command, chatId, senderId, senderName, senderContactName, chatName);
      } else {
        console.log(`â„¹ï¸ Outgoing text message without '# ' prefix - ignored (not a management command)`);
      }
    } else {
      console.log(`â„¹ï¸ Unsupported outgoing message type: ${messageData.typeMessage}`);
    }
  } catch (error) {
    console.error('âŒ Error handling outgoing message:', error.message || error);
  }
}

/**
 * Process image edit message asynchronously (no await from webhook)
 */
function processImageEditAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageEdit(imageData).catch(async error => {
    console.error('âŒ Error in async image edit processing:', error.message || error);
    try {
      await sendTextMessage(imageData.chatId, `âŒ ×©×’×™××” ×‘×¢×¨×™×›×ª ×”×ª××•× ×”: ${error.message || error}`);
    } catch (sendError) {
      console.error('âŒ Failed to send error message to user:', sendError);
    }
  });
}

/**
 * Process image-to-video message asynchronously (no await from webhook)
 */
function processImageToVideoAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageToVideo(imageData).catch(async error => {
    console.error('âŒ Error in async image-to-video processing:', error.message || error);
    try {
      await sendTextMessage(imageData.chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×•×™×“××• ××”×ª××•× ×”: ${error.message || error}`);
    } catch (sendError) {
      console.error('âŒ Failed to send error message to user:', sendError);
    }
  });
}

/**
 * Process creative voice message asynchronously (no await from webhook) - COMMENTED OUT FOR VOICE-TO-VOICE PROCESSING
 */
/*
function processCreativeVoiceAsync(voiceData) {
  // Run in background without blocking webhook response
  handleCreativeVoiceMessage(voiceData).catch(async error => {
    console.error('âŒ Error in async creative voice processing:', error.message || error);
    try {
      await sendTextMessage(voiceData.chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×”×§×œ×˜×”: ${error.message || error}`);
    } catch (sendError) {
      console.error('âŒ Failed to send error message to user:', sendError);
    }
  });
}
*/

/**
 * Process voice message asynchronously (no await from webhook)
 */
function processVoiceMessageAsync(voiceData) {
  // Run in background without blocking webhook response
  handleVoiceMessage(voiceData).catch(error => {
    console.error('âŒ Error in async voice processing:', error.message || error);
  });
}

/**
 * Process video-to-video message asynchronously (no await from webhook)
 */
function processVideoToVideoAsync(videoData) {
  // Run in background without blocking webhook response
  handleVideoToVideo(videoData).catch(async error => {
    console.error('âŒ Error in async video-to-video processing:', error.message || error);
    try {
      await sendTextMessage(videoData.chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×•×™×“××•: ${error.message || error}`);
    } catch (sendError) {
      console.error('âŒ Failed to send error message to user:', sendError);
    }
  });
}

/**
 * Handle image edit with AI (Gemini or OpenAI)
 */
async function handleImageEdit({ chatId, senderId, senderName, imageUrl, prompt, service }) {
  console.log(`ğŸ¨ Processing ${service} image edit request from ${senderName}`);
  
  try {
    // Send immediate ACK
    const ackMessage = service === 'gemini' 
      ? 'ğŸ¨ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ××¢×‘×“ ××•×ª×” ×¢× Gemini...'
      : 'ğŸ–¼ï¸ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ××¢×‘×“ ××•×ª×” ×¢× OpenAI...';
    await sendTextMessage(chatId, ackMessage);
    
    // Note: Image editing commands do NOT add to conversation history
    
    if (!imageUrl) {
      throw new Error('No image URL provided');
    }
    
    // Download the image
    const imageBuffer = await downloadFile(imageUrl);
    
    const base64Image = imageBuffer.toString('base64');
    
    // Edit image with selected AI service
    let editResult;
    if (service === 'gemini') {
      editResult = await editImageForWhatsApp(prompt, base64Image);
    } else if (service === 'openai') {
      editResult = await editOpenAIImage(prompt, base64Image);
    }
    
    if (editResult.success) {
      let sentSomething = false;
      
      // Send text response if available
      if (editResult.description && editResult.description.trim()) {
        await sendTextMessage(chatId, editResult.description);
        
        // Note: Image editing results do NOT add to conversation history
        
        console.log(`âœ… ${service} edit text response sent to ${senderName}: ${editResult.description}`);
        sentSomething = true;
      }
      
      // Send image if available (even if we already sent text)
      if (editResult.imageUrl) {
        const fileName = editResult.fileName || `${service}_edit_${Date.now()}.png`;
        
        await sendFileByUrl(chatId, editResult.imageUrl, fileName, '');
        
        console.log(`âœ… ${service} edited image sent to ${senderName}`);
        sentSomething = true;
      }
      
      // If nothing was sent, it means we have success but no content
      if (!sentSomething) {
        await sendTextMessage(chatId, 'âœ… ×”×¢×™×‘×•×“ ×”×•×©×œ× ×‘×”×¦×œ×—×”');
        console.log(`âœ… ${service} edit completed but no content to send to ${senderName}`);
      }
    } else {
      const errorMsg = editResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×¨×•×š ××ª ×”×ª××•× ×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ ${service} image edit failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`âŒ Error in ${service} image editing:`, error.message || error);
    await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×¨×™×›×ª ×”×ª××•× ×”: ${error.message || error}`);
  }
}

/**
 * Handle image-to-video with Veo 3, Sora 2, or Kling
 */
async function handleImageToVideo({ chatId, senderId, senderName, imageUrl, prompt, service = 'veo3', model = null }) {
  let serviceName;
  if (service === 'veo3') {
    serviceName = 'Veo 3';
  } else if (service === 'sora') {
    serviceName = model === 'sora-2-pro' ? 'Sora 2 Pro' : 'Sora 2';
  } else {
    serviceName = 'Kling 2.1 Master';
  }
  console.log(`ğŸ¬ Processing ${serviceName} image-to-video request from ${senderName}`);
  
  try {
    // Send immediate ACK
    let ackMessage;
    if (service === 'veo3') {
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”! ×™×•×¦×¨ ×•×™×“××• ×¢× Veo 3...';
    } else if (service === 'sora') {
      ackMessage = model === 'sora-2-pro' 
        ? 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2 Pro...'
        : 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Sora 2...';
    } else {
      ackMessage = 'ğŸ¬ ×§×™×‘×œ×ª×™ ××ª ×”×ª××•× ×”. ××™×“ ×™×•×¦×¨ ×•×™×“××• ×¢× Kling 2.1...';
    }
    await sendTextMessage(chatId, ackMessage);
    
    // Note: Image-to-video commands do NOT add to conversation history
    
    if (!imageUrl) {
      throw new Error('No image URL provided');
    }
    
    // Download the image
    const imageBuffer = await downloadFile(imageUrl);
    
    // Generate video with selected service
    let videoResult;
    if (service === 'veo3') {
      videoResult = await generateVideoFromImageForWhatsApp(prompt, imageBuffer);
    } else if (service === 'sora') {
      // Sora 2 image-to-video with image_reference
      const options = model ? { model } : {};
      videoResult = await generateVideoWithSoraFromImageForWhatsApp(prompt, imageBuffer, options);
    } else {
      videoResult = await generateKlingVideoFromImage(imageBuffer, prompt);
    }
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `${service}_image_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Add AI response to conversation history
      await conversationManager.addMessage(chatId, 'assistant', `×•×™×“××• × ×•×¦×¨ ××ª××•× ×” (${serviceName}): ${videoResult.description || '×•×™×“××• ×—×“×©'}`);
      
      console.log(`âœ… ${serviceName} image-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || `×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××• ××”×ª××•× ×” ×¢× ${serviceName}. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.`;
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ ${serviceName} image-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`âŒ Error in ${serviceName} image-to-video:`, error.message || error);
    await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×•×™×“××• ××”×ª××•× ×”: ${error.message || error}`);
  }
}

/**
 * Handle video-to-video with RunwayML Gen4
 */
async function handleVideoToVideo({ chatId, senderId, senderName, videoUrl, prompt }) {
  console.log(`ğŸ¬ Processing RunwayML Gen4 video-to-video request from ${senderName}`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'runway_video_to_video' });
    
    // Note: Video-to-video commands do NOT add to conversation history
    
    if (!videoUrl) {
      throw new Error('No video URL provided');
    }
    
    // Download the video
    const videoBuffer = await downloadFile(videoUrl);
    
    // Generate video with RunwayML Gen4
    const videoResult = await generateRunwayVideoFromVideo(videoBuffer, prompt);
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `runway_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Note: Video-to-video results do NOT add to conversation history
      
      console.log(`âœ… RunwayML Gen4 video-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ×¢×‘×“ ××ª ×”×•×•×™×“××•. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.';
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ${errorMsg}`);
      console.log(`âŒ RunwayML Gen4 video-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error('âŒ Error in RunwayML Gen4 video-to-video:', error.message || error);
    await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×•×™×“××•: ${error.message || error}`);
  }
}

// âŒ REMOVED: handleCreativeVoiceMessage - no longer needed, voice-to-voice processing is used instead

/**
 * Get audio duration in seconds using ffprobe
 * @param {Buffer} audioBuffer - Audio buffer
 * @returns {Promise<number>} - Duration in seconds, or 0 if failed
 */
async function getAudioDuration(audioBuffer) {
  try {
    // Write buffer to temp file
    const tempFilePath = path.join(os.tmpdir(), `audio_check_${Date.now()}.ogg`);
    fs.writeFileSync(tempFilePath, audioBuffer);
    
    try {
      // Use ffprobe to get duration
      const { stdout } = await execAsync(`ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${tempFilePath}"`);
      const duration = parseFloat(stdout.trim());
      
      // Cleanup
      fs.unlinkSync(tempFilePath);
      
      console.log(`â±ï¸ Audio duration: ${duration.toFixed(2)} seconds`);
      return duration;
    } catch (err) {
      // Cleanup on error
      if (fs.existsSync(tempFilePath)) {
        fs.unlinkSync(tempFilePath);
      }
      console.error(`âŒ Could not get audio duration: ${err.message}`);
      return 0;
    }
  } catch (err) {
    console.error(`âŒ Error in getAudioDuration: ${err.message}`);
    return 0;
  }
}

/**
 * Handle voice message with full voice-to-voice processing
 * Flow: Speech-to-Text â†’ Voice Clone â†’ Gemini Response â†’ Text-to-Speech
 */
async function handleVoiceMessage({ chatId, senderId, senderName, audioUrl }) {
  console.log(`ğŸ¤ Processing voice-to-voice request from ${senderName}`);
  
  try {
    // No ACK - user should only receive the final voice response
    
    // Step 1: Download audio file
    const audioBuffer = await downloadFile(audioUrl);
    
    // Step 2: Speech-to-Text transcription
    console.log(`ğŸ”„ Step 1: Transcribing speech...`);
    const transcriptionOptions = TRANSCRIPTION_DEFAULTS;
    
    const transcriptionResult = await speechService.speechToText(audioBuffer, transcriptionOptions);
    
    if (transcriptionResult.error) {
      console.error('âŒ Transcription failed:', transcriptionResult.error);
      // We don't know the language yet, so use Hebrew as default for error messages
      await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×”: ${transcriptionResult.error}`);
      return;
    }

    const transcribedText = transcriptionResult.text;
    console.log(`âœ… Step 1 complete: Transcribed ${transcribedText.length} characters`);
    console.log(`ğŸ“ Transcription complete`);

    // Use our own language detection on the transcribed text for consistency
    const originalLanguage = voiceService.detectLanguage(transcribedText);
    console.log(`ğŸŒ STT detected: ${transcriptionResult.detectedLanguage}, Our detection: ${originalLanguage}`);

    // Don't send transcription to user - they should only receive the final voice response

    // Step 2: Check audio duration and decide whether to clone voice
    const audioDuration = await getAudioDuration(audioBuffer);
    let voiceId = null;
    let shouldCloneVoice = audioDuration >= MIN_DURATION_FOR_CLONING;
    
    if (shouldCloneVoice) {
      console.log(`ğŸ”„ Step 2: Creating voice clone (duration: ${audioDuration.toFixed(2)}s >= ${MIN_DURATION_FOR_CLONING}s)...`);
      
      const voiceCloneOptions = {
        name: `WhatsApp Voice Clone ${Date.now()}`,
        description: `Voice clone from WhatsApp audio`,
        removeBackgroundNoise: true,
        labels: JSON.stringify({
          accent: originalLanguage === 'he' ? 'hebrew' : 'natural',
          use_case: 'conversational',
          quality: 'high',
          style: 'natural',
          language: originalLanguage
        })
      };
      
      const voiceCloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
      
      if (voiceCloneResult.error) {
        console.warn(`âš ï¸ Voice cloning failed: ${voiceCloneResult.error}. Falling back to random voice.`);
        shouldCloneVoice = false;
      } else {
        voiceId = voiceCloneResult.voiceId;
        console.log(`âœ… Step 2 complete: Voice cloned (ID: ${voiceId}), Language: ${originalLanguage}`);
      }
    } else {
      console.log(`â­ï¸ Step 2: Skipping voice clone (duration: ${audioDuration.toFixed(2)}s < ${MIN_DURATION_FOR_CLONING}s) - will use random voice`);
    }
    
    const detectedLanguage = transcriptionResult.detectedLanguage || 'he';

    // Step 3: Generate Gemini response in the same language as the original
    console.log(`ğŸ”„ Step 3: Generating Gemini response in ${originalLanguage}...`);
    
    // Create language-aware prompt for Gemini
    const languageInstruction = originalLanguage === 'he' 
      ? '' // Hebrew is default, no need for special instruction
      : originalLanguage === 'en' 
        ? 'Please respond in English. ' 
        : originalLanguage === 'ar' 
          ? 'ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. '
          : originalLanguage === 'ru' 
            ? 'ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹Ñ‚Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. '
            : originalLanguage === 'es' 
              ? 'Por favor responde en espaÃ±ol. '
              : originalLanguage === 'fr' 
                ? 'Veuillez rÃ©pondre en franÃ§ais. '
                : originalLanguage === 'de' 
                  ? 'Bitte antworten Sie auf Deutsch. '
                  : `Please respond in the same language as this message. `;
    
    const geminiPrompt = languageInstruction + transcribedText;
    // Voice processing doesn't need conversation history - treat each voice message independently
    const geminiResult = await generateGeminiResponse(geminiPrompt, []);
    
    // Add user message to conversation AFTER getting Gemini response to avoid duplication
    await conversationManager.addMessage(chatId, 'user', `×”×§×œ×˜×” ×§×•×œ×™×ª: ${transcribedText}`);
    
    if (geminiResult.error) {
      console.error('âŒ Gemini generation failed:', geminiResult.error);
      const errorMessage = originalLanguage === 'he' 
        ? `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª×’×•×‘×”: ${geminiResult.error}`
        : `âŒ Sorry, I couldn't generate a response: ${geminiResult.error}`;
      await sendTextMessage(chatId, errorMessage);
      
      // Clean up voice clone before returning (only if we cloned)
      if (shouldCloneVoice && voiceId) {
        try {
          await voiceService.deleteVoice(voiceId);
          console.log(`ğŸ§¹ Voice clone ${voiceId} deleted (cleanup after Gemini error)`);
        } catch (cleanupError) {
          console.warn('âš ï¸ Could not delete voice clone:', cleanupError.message);
        }
      }
      return;
    }

    const geminiResponse = geminiResult.text;
    console.log(`âœ… Step 3 complete: Gemini response generated`);
    
    // Add AI response to conversation history
    await conversationManager.addMessage(chatId, 'assistant', geminiResponse);

    // Step 4: Text-to-Speech with cloned voice or random voice
    const responseLanguage = originalLanguage; // Force same language as original
    console.log(`ğŸŒ Language consistency enforced:`);
    console.log(`   - Original (from user): ${originalLanguage}`);
    console.log(`   - TTS (forced same): ${responseLanguage}`);
    
    // If voice wasn't cloned, get a random voice for the target language
    if (!shouldCloneVoice || !voiceId) {
      console.log(`ğŸ”„ Step 4: Getting random voice for ${responseLanguage} (no cloning)...`);
      const randomVoiceResult = await voiceService.getVoiceForLanguage(responseLanguage);
      if (randomVoiceResult.error) {
        console.error(`âŒ Could not get random voice: ${randomVoiceResult.error}`);
        await sendTextMessage(chatId, `âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª×’×•×‘×” ×§×•×œ×™×ª`);
        return;
      }
      voiceId = randomVoiceResult.voiceId;
      console.log(`âœ… Using random voice: ${voiceId} for language ${responseLanguage}`);
    } else {
      console.log(`ğŸ”„ Step 4: Converting text to speech with cloned voice...`);
    }
    
    const ttsOptions = {
      modelId: 'eleven_v3', // Use the most advanced model
      outputFormat: 'mp3_44100_128', // ElevenLabs doesn't support ogg_vorbis
      languageCode: responseLanguage
    };

    const ttsResult = await voiceService.textToSpeech(voiceId, geminiResponse, ttsOptions);
    
    if (ttsResult.error) {
      console.error('âŒ Text-to-speech failed:', ttsResult.error);
      // If TTS fails, send error message (don't send the Gemini response as text)
      const errorMessage = originalLanguage === 'he' 
        ? 'âŒ ×¡×œ×™×—×”, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×ª×’×•×‘×” ×§×•×œ×™×ª. × ×¡×” ×©×•×‘.'
        : 'âŒ Sorry, I couldn\'t generate voice response. Please try again.';
      await sendTextMessage(chatId, errorMessage);
      
      // Clean up voice clone before returning (only if we cloned)
      if (shouldCloneVoice && voiceId) {
        try {
          await voiceService.deleteVoice(voiceId);
          console.log(`ğŸ§¹ Voice clone ${voiceId} deleted (cleanup after TTS error)`);
        } catch (cleanupError) {
          console.warn('âš ï¸ Could not delete voice clone:', cleanupError.message);
        }
      }
      return;
    }

    console.log(`âœ… Step 4 complete: Audio generated at ${ttsResult.audioUrl}`);

    // Step 5: Convert and send voice response back to user as voice note
    console.log(`ğŸ”„ Converting voice-to-voice to Opus format for voice note...`);
    const conversionResult = await audioConverterService.convertUrlToOpus(ttsResult.audioUrl, 'mp3');
    
    if (!conversionResult.success) {
      console.error('âŒ Audio conversion failed:', conversionResult.error);
      // Fallback: send as regular MP3 file
      const fullAudioUrl = ttsResult.audioUrl.startsWith('http') 
        ? ttsResult.audioUrl 
        : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
      await sendFileByUrl(chatId, fullAudioUrl, `voice_${Date.now()}.mp3`, '');
    } else {
      // Send as voice note with Opus format
      const fullAudioUrl = getStaticFileUrl(conversionResult.fileName);
      await sendFileByUrl(chatId, fullAudioUrl, conversionResult.fileName, '');
      console.log(`âœ… Voice-to-voice sent as voice note: ${conversionResult.fileName}`);
    }
    
    console.log(`âœ… Voice-to-voice processing complete for ${senderName}`);

    // Cleanup: Delete the cloned voice (only if we cloned - ElevenLabs has limits)
    if (shouldCloneVoice && voiceId) {
      try {
        await voiceService.deleteVoice(voiceId);
        console.log(`ğŸ§¹ Cleanup: Voice ${voiceId} deleted`);
      } catch (cleanupError) {
        console.warn('âš ï¸ Voice cleanup failed:', cleanupError.message);
      }
    }

  } catch (error) {
    console.error('âŒ Error in voice-to-voice processing:', error.message || error);
    await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×”×§×œ×˜×” ×”×§×•×œ×™×ª: ${error.message || error}`);
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// LEGACY FUNCTION handleTextMessage - REMOVED
// All functionality moved to router-based direct execution (lines 279-510)
// Management commands handled in handleOutgoingMessage (lines 1022+)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Parse text message to extract MANAGEMENT COMMANDS ONLY
 * All AI commands (chat, image, video, music, TTS) now go through router with "# " prefix
 */
function parseTextCommand(text) {
  if (!text || typeof text !== 'string') {
    return null;
  }

  text = text.trim();

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MANAGEMENT COMMANDS ONLY â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // All AI commands (chat, image, video, music, TTS) now go through router with "# " prefix
  
  // Clear conversation history (admin command)
  if (text === '× ×§×” ×”×™×¡×˜×•×¨×™×”') {
    return { type: 'clear_all_conversations' };
  }

  // Show history
  if (text === '×”×¦×’ ×”×™×¡×˜×•×¨×™×”') {
    return { type: 'show_history' };
  }

  // Media creation status
  if (text === '×¡×˜×˜×•×¡ ×™×¦×™×¨×”') {
    return { type: 'media_creation_status' };
  }

  // Voice transcription controls
  if (text === '×¡×˜×˜×•×¡ ×ª××œ×•×œ') {
    return { type: 'voice_transcription_status' };
  }

  // Group creation status
  if (text === '×¡×˜×˜×•×¡ ×§×‘×•×¦×•×ª') {
    return { type: 'group_creation_status' };
  }

  // Sync contacts from Green API
  if (text === '×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨') {
    return { type: 'sync_contacts' };
  }

  // Media creation authorization commands
  if (text.startsWith('×”×•×¡×£ ×œ×™×¦×™×¨×” ')) {
    const contactName = text.substring('×”×•×¡×£ ×œ×™×¦×™×¨×” '.length).trim();
    if (contactName) {
      return { 
        type: 'add_media_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  if (text.startsWith('×”×¡×¨ ××™×¦×™×¨×” ')) {
    const contactName = text.substring('×”×¡×¨ ××™×¦×™×¨×” '.length).trim();
    if (contactName) {
      return { 
        type: 'remove_media_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  // Group creation authorization commands
  if (text.startsWith('×”×•×¡×£ ×œ×§×‘×•×¦×•×ª ')) {
    const contactName = text.substring('×”×•×¡×£ ×œ×§×‘×•×¦×•×ª '.length).trim();
    if (contactName) {
      return { 
        type: 'add_group_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  if (text.startsWith('×”×¡×¨ ××§×‘×•×¦×•×ª ')) {
    const contactName = text.substring('×”×¡×¨ ××§×‘×•×¦×•×ª '.length).trim();
    if (contactName) {
      return { 
        type: 'remove_group_authorization', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  // Shortcut: "×”×•×¡×£ ×œ×§×‘×•×¦×•×ª" without name - infer from current chat
  if (text === '×”×•×¡×£ ×œ×§×‘×•×¦×•×ª') {
    return { 
      type: 'add_group_authorization_current',
      originalMessage: text 
    };
  }

  // Voice transcription exclude list management
  if (text.startsWith('×”×¡×¨ ××ª××œ×•×œ ')) {
    const contactName = text.substring('×”×¡×¨ ××ª××œ×•×œ '.length).trim();
    if (contactName) {
      return { 
        type: 'exclude_from_transcription', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  if (text.startsWith('×”×•×¡×£ ×œ×ª××œ×•×œ ')) {
    const contactName = text.substring('×”×•×¡×£ ×œ×ª××œ×•×œ '.length).trim();
    if (contactName) {
      return { 
        type: 'include_in_transcription', 
        contactName: contactName,
        originalMessage: text 
      };
    }
  }

  return null;
}

/**
 * Handle management commands (non-AI commands that don't go through router)
 */
async function handleManagementCommand(command, chatId, senderId, senderName, senderContactName, chatName) {
  try {
    switch (command.type) {
      case 'clear_all_conversations': {
        await conversationManager.clearAllConversations();
        await sendTextMessage(chatId, 'âœ… ×›×œ ×”×”×™×¡×˜×•×¨×™×•×ª × ×•×§×• ×‘×”×¦×œ×—×”');
        console.log(`ğŸ—‘ï¸ All conversation histories cleared by ${senderName}`);
        break;
      }

      case 'show_history': {
        const history = await conversationManager.getConversationHistory(chatId);
        if (history && history.length > 0) {
          let historyText = 'ğŸ“œ **×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”:**\n\n';
          history.forEach((msg, i) => {
            const role = msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–';
            historyText += `${role} ${msg.content}\n\n`;
          });
          await sendTextMessage(chatId, historyText);
        } else {
          await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”');
        }
        break;
      }

      case 'media_creation_status': {
        const authorizedUsers = await authStore.getAuthorizedUsers();
        if (authorizedUsers && authorizedUsers.length > 0) {
          let statusText = 'âœ… **××©×ª××©×™× ××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”:**\n\n';
          authorizedUsers.forEach(contactName => {
            statusText += `â€¢ ${contactName}\n`;
          });
          await sendTextMessage(chatId, statusText);
        } else {
          await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ××©×ª××©×™× ××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”');
        }
        break;
      }

      case 'voice_transcription_status': {
        const allowList = await conversationManager.getVoiceAllowList();
        if (allowList && allowList.length > 0) {
          let statusText = 'âœ… **××©×ª××©×™× ××•×¨×©×™× ×œ×ª××œ×•×œ:**\n\n';
          allowList.forEach(contactName => {
            statusText += `â€¢ ${contactName}\n`;
          });
          await sendTextMessage(chatId, statusText);
        } else {
          await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ××©×ª××©×™× ××•×¨×©×™× ×œ×ª××œ×•×œ');
        }
        break;
      }

      case 'group_creation_status': {
        const authorizedUsers = await groupAuthStore.getAuthorizedUsers();
        if (authorizedUsers && authorizedUsers.length > 0) {
          let statusText = 'âœ… **××©×ª××©×™× ××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª:**\n\n';
          authorizedUsers.forEach(contactName => {
            statusText += `â€¢ ${contactName}\n`;
          });
          await sendTextMessage(chatId, statusText);
        } else {
          await sendTextMessage(chatId, 'â„¹ï¸ ××™×Ÿ ××©×ª××©×™× ××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª');
        }
        break;
      }

      case 'sync_contacts': {
        try {
          await sendTextMessage(chatId, 'ğŸ“‡ ××¢×“×›×Ÿ ×¨×©×™××ª ×× ×©×™ ×§×©×¨...');
          
          // Fetch contacts from Green API
          const { getContacts } = require('../services/greenApiService');
          const contacts = await getContacts();
          
          if (!contacts || contacts.length === 0) {
            await sendTextMessage(chatId, 'âš ï¸ ×œ× × ××¦××• ×× ×©×™ ×§×©×¨');
            return;
          }
          
          // Sync to database
          const syncResult = await conversationManager.syncContacts(contacts);
          
          const resultMessage = `âœ… ×¢×“×›×•×Ÿ ×× ×©×™ ×§×©×¨ ×”×•×©×œ×!

ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×”:
â€¢ ×—×“×©×™×: ${syncResult.inserted}
â€¢ ×¢×•×“×›× ×•: ${syncResult.updated}  
â€¢ ×¡×”"×›: ${syncResult.total}

ğŸ’¾ ×›×œ ×× ×©×™ ×”×§×©×¨ × ×©××¨×• ×‘××¡×“ ×”× ×ª×•× ×™×`;
          
          await sendTextMessage(chatId, resultMessage);
          console.log(`âœ… Contacts synced successfully by ${senderName}`);
        } catch (error) {
          console.error('âŒ Error syncing contacts:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×“×›×•×Ÿ ×× ×©×™ ×§×©×¨: ${error.message}`);
        }
        break;
      }

      case 'add_media_authorization': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasAdded = await authStore.addAuthorizedUser(exactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${exactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Added ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) to media creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        } catch (error) {
          console.error('âŒ Error in add_media_authorization:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ×”×¨×©××”: ${error.message}`);
        }
        break;
      }

      case 'remove_media_authorization': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasRemoved = await authStore.removeAuthorizedUser(exactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${exactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
            console.log(`âœ… Removed ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) from media creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ××“×™×”`);
          }
        } catch (error) {
          console.error('âŒ Error in remove_media_authorization:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×¡×¨×ª ×”×¨×©××”: ${error.message}`);
        }
        break;
      }

      case 'add_group_authorization': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasAdded = await groupAuthStore.addAuthorizedUser(exactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${exactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
            console.log(`âœ… Added ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) to group creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
          }
        } catch (error) {
          console.error('âŒ Error in add_group_authorization:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ×”×¨×©××”: ${error.message}`);
        }
        break;
      }

      case 'remove_group_authorization': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasRemoved = await groupAuthStore.removeAuthorizedUser(exactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${exactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
            console.log(`âœ… Removed ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) from group creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
          }
        } catch (error) {
          console.error('âŒ Error in remove_group_authorization:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×¡×¨×ª ×”×¨×©××”: ${error.message}`);
        }
        break;
      }

      case 'include_in_transcription': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasAdded = await conversationManager.addToVoiceAllowList(exactName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${exactName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Added ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) to voice allow list by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        } catch (error) {
          console.error('âŒ Error in include_in_transcription:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ×”×¨×©××ª ×ª××œ×•×œ: ${error.message}`);
        }
        break;
      }

      case 'exclude_from_transcription': {
        try {
          const { findContactByName } = require('../services/groupService');
          
          // Use fuzzy search to find exact contact/group name
          await sendTextMessage(chatId, `ğŸ” ××—×¤×© ××™×© ×§×©×¨ ××• ×§×‘×•×¦×”: "${command.contactName}"...`);
          const foundContact = await findContactByName(command.contactName);
          
          if (!foundContact) {
            await sendTextMessage(chatId, `âŒ ×œ× × ××¦× ××™×© ×§×©×¨ ××• ×§×‘×•×¦×” ×ª×•×××™× ×œ-"${command.contactName}"\n\nğŸ’¡ ×˜×™×¤: ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ××• ×•×•×“× ×©×”×©× × ×›×•×Ÿ`);
            break;
          }
          
          // Use the exact contact name found in DB
          const exactName = foundContact.contactName;
          const entityType = foundContact.isGroup ? 'ğŸ‘¥ ×§×‘×•×¦×”' : 'ğŸ‘¤ ××™×© ×§×©×¨';
          await sendTextMessage(chatId, `âœ… × ××¦× ${entityType}: "${command.contactName}" â†’ "${exactName}"`);
          
          const wasRemoved = await conversationManager.removeFromVoiceAllowList(exactName);
          if (wasRemoved) {
            await sendTextMessage(chatId, `ğŸš« ${exactName} ×”×•×¡×¨ ××¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
            console.log(`âœ… Removed ${exactName} ${foundContact.isGroup ? '(group)' : '(contact)'} (searched: ${command.contactName}) from voice allow list by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${exactName} ×œ× × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×ª××œ×•×œ`);
          }
        } catch (error) {
          console.error('âŒ Error in exclude_from_transcription:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×¡×¨×ª ×”×¨×©××ª ×ª××œ×•×œ: ${error.message}`);
        }
        break;
      }

      case 'add_group_authorization_current': {
        try {
          // Auto-detect contact/group name from current chat
          const isGroupChat = chatId && chatId.endsWith('@g.us');
          const isPrivateChat = chatId && chatId.endsWith('@c.us');
          
          let targetName = '';
          if (isGroupChat) {
            targetName = chatName || senderName;
          } else if (isPrivateChat) {
            targetName = senderContactName || chatName || senderName;
          } else {
            await sendTextMessage(chatId, 'âŒ ×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××ª ×”×©×™×—×” ×”× ×•×›×—×™×ª');
            break;
          }
          
          await sendTextMessage(chatId, `ğŸ“ ××–×”×” ××•×˜×•××˜×™×ª: "${targetName}"`);
          
          const wasAdded = await groupAuthStore.addAuthorizedUser(targetName);
          if (wasAdded) {
            await sendTextMessage(chatId, `âœ… ${targetName} × ×•×¡×£ ×œ×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
            console.log(`âœ… Added ${targetName} (auto-detected from current chat) to group creation authorization by ${senderName}`);
          } else {
            await sendTextMessage(chatId, `â„¹ï¸ ${targetName} ×›×‘×¨ × ××¦× ×‘×¨×©×™××ª ×”××•×¨×©×™× ×œ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª`);
          }
        } catch (error) {
          console.error('âŒ Error in add_group_authorization_current:', error);
          await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ×”×¨×©××”: ${error.message}`);
        }
        break;
      }

      default:
        console.log(`âš ï¸ Unknown management command type: ${command.type}`);
        await sendTextMessage(chatId, `âš ï¸ Unknown management command type: ${command.type}`);
    }
  } catch (error) {
    console.error(`âŒ Error handling management command ${command.type}:`, error);
    await sendTextMessage(chatId, `âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×¤×§×•×“×”: ${error.message || error}`);
  }
}

module.exports = router;
