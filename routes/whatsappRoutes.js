const express = require('express');
const router = express.Router();
const { sendTextMessage, sendFileByUrl, downloadFile } = require('../services/greenApiService');
const { getStaticFileUrl } = require('../utils/urlUtils');
const { generateTextResponse: generateOpenAIResponse, generateImageForWhatsApp: generateOpenAIImage, editImageForWhatsApp: editOpenAIImage } = require('../services/openaiService');
const { generateTextResponse: generateGeminiResponse, generateImageForWhatsApp, editImageForWhatsApp, generateVideoForWhatsApp, generateVideoFromImageForWhatsApp } = require('../services/geminiService');
const { generateVideoFromImageForWhatsApp: generateKlingVideoFromImage, generateVideoFromVideoForWhatsApp: generateRunwayVideoFromVideo } = require('../services/replicateService');
const speechService = require('../services/speechService');
const { voiceService } = require('../services/voiceService');
const conversationManager = require('../services/conversationManager');

// Message deduplication cache - prevent processing duplicate messages
const processedMessages = new Set();

// Clean up old processed messages every 30 minutes
setInterval(() => {
  if (processedMessages.size > 1000) {
    processedMessages.clear();
    console.log('üßπ Cleared processed messages cache');
  }
}, 30 * 60 * 1000);

/**
 * Send immediate acknowledgment for long-running commands
 */
async function sendAck(chatId, command) {
  let ackMessage = '';
  
  switch (command.type) {
    case 'gemini_image':
      ackMessage = 'üé® ◊ß◊ô◊ë◊ú◊™◊ô. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊™◊û◊ï◊†◊î';
      break;
    case 'openai_image':
      ackMessage = 'üñºÔ∏è ◊ß◊ô◊ë◊ú◊™◊ô. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊™◊û◊ï◊†◊î';
      break;
    case 'veo3_video':
      ackMessage = 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Veo 3';
      break;
    case 'veo3_image_to_video':
      ackMessage = 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Veo 3';
      break;
    case 'kling_image_to_video':
      ackMessage = 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Kling 2.1';
      break;
    case 'voice_processing':
      ackMessage = 'üé§ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊î◊ß◊ú◊ò◊î. ◊û◊™◊ó◊ô◊ú ◊¢◊ô◊ë◊ï◊ì ◊ß◊ï◊ú◊ô...';
      break;
    case 'runway_video_to_video':
      ackMessage = 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊ï◊ï◊ô◊ì◊ê◊ï. ◊û◊ô◊ì ◊¢◊ï◊ë◊ì ◊¢◊ú◊ô◊ï ◊¢◊ù RunwayML Gen4';
      break;
    case 'voice_generation':
      ackMessage = 'üé§ ◊ß◊ô◊ë◊ú◊™◊ô. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ß◊ï◊ú';
      break;
    default:
      return; // No ACK needed for this command
  }
  
  try {
    await sendTextMessage(chatId, ackMessage);
    console.log(`‚úÖ ACK sent for ${command.type}`);
  } catch (error) {
    console.error('‚ùå Error sending ACK:', error.message || error);
  }
}

/**
 * WhatsApp Green API Integration Routes
 * 
 * üö® BACKWARD COMPATIBILITY RULE:
 * Any new WhatsApp functionality MUST maintain backward compatibility
 * with Tasker Android polling system (/api/start-task + /api/task-status).
 */

/**
 * Webhook endpoint for receiving WhatsApp messages from Green API
 */
router.post('/webhook', async (req, res) => {
  try {
    // Security check: Verify webhook token
    const token = req.headers['authorization']?.replace('Bearer ', '') ||
                  req.query.token || 
                  req.body.token;
    
    const expectedToken = process.env.GREEN_API_WEBHOOK_TOKEN;
    
    if (!expectedToken) {
      console.error('‚ùå GREEN_API_WEBHOOK_TOKEN not configured in environment');
      return res.status(500).json({ error: 'Webhook token not configured' });
    }
    
    if (token !== expectedToken) {
      console.error('‚ùå Unauthorized webhook request - invalid token');
      return res.status(401).json({ error: 'Unauthorized' });
    }

    const webhookData = req.body;
    console.log('üì± Green API webhook received:', JSON.stringify(webhookData, null, 2));

    // Handle different webhook types asynchronously
    if (webhookData.typeWebhook === 'incomingMessageReceived') {
      // Process in background - don't await
      handleIncomingMessage(webhookData).catch(error => {
        console.error('‚ùå Error in async webhook processing:', error.message || error);
      });
    }

    // Return 200 OK immediately
    res.status(200).json({ status: 'ok' });
  } catch (error) {
    console.error('‚ùå Error processing webhook:', error.message || error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

/**
 * Handle incoming WhatsApp message
 */
async function handleIncomingMessage(webhookData) {
  try {
    const messageData = webhookData.messageData;
    const senderData = webhookData.senderData;
    
    // Extract message ID for deduplication
    const messageId = webhookData.idMessage;
    
    // Check if we already processed this message
    if (processedMessages.has(messageId)) {
      console.log(`üîÑ Duplicate message detected, skipping: ${messageId}`);
      return;
    }
    
    // Mark message as processed
    processedMessages.add(messageId);
    
    const chatId = senderData.chatId;
    const senderId = senderData.sender;
    const senderName = senderData.senderName || senderId;
    
    console.log(`üì± Message from: ${senderName} (${chatId})`);
    console.log(`üìã Message type: ${messageData.typeMessage}`);
    console.log(`üÜî Message ID: ${messageId}`);
    
    // Handle text messages (both regular and extended)
    let messageText = null;
    
    if (messageData.typeMessage === 'textMessage') {
      messageText = messageData.textMessageData?.textMessage;
      console.log(`üìù Regular text message: "${messageText}"`);
    } else if (messageData.typeMessage === 'extendedTextMessage') {
      messageText = messageData.extendedTextMessageData?.text;
      console.log(`üìù Extended text message: "${messageText}"`);
    }
    
    // Handle image messages for image-to-image editing
    if (messageData.typeMessage === 'imageMessage') {
      const imageData = messageData.fileMessageData || messageData.imageMessageData;
      const caption = imageData?.caption || '';
      
      console.log(`üñºÔ∏è Image message received with caption: "${caption}"`);
      
      // Check if caption starts with "### " for Veo 3 image-to-video
      if (caption.startsWith('### ')) {
        const prompt = caption.substring(4).trim(); // Remove "### "
        console.log(`üé¨ Veo 3 image-to-video request with prompt: "${prompt}"`);
        
        // Process Veo 3 image-to-video asynchronously
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'veo3'
        });
      }
      // Check if caption starts with "## " for Kling image-to-video
      else if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`üé¨ Kling 2.1 image-to-video request with prompt: "${prompt}"`);
        
        // Process Kling image-to-video asynchronously
        processImageToVideoAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'kling'
        });
      }
      // Check if caption starts with "*" for Gemini image editing
      else if (caption.startsWith('* ')) {
        const prompt = caption.substring(2).trim(); // Remove "* "
        console.log(`üé® Gemini image edit request with prompt: "${prompt}"`);
        
        // Process Gemini image editing asynchronously
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'gemini'
        });
      } 
      // Check if caption starts with "#" for OpenAI image editing
      else if (caption.startsWith('# ')) {
        const prompt = caption.substring(2).trim(); // Remove "# "
        console.log(`üñºÔ∏è OpenAI image edit request with prompt: "${prompt}"`);
        
        // Process OpenAI image editing asynchronously
        processImageEditAsync({
          chatId,
          senderId,
          senderName,
          imageUrl: imageData.downloadUrl,
          prompt: prompt,
          service: 'openai'
        });
      } else {
        console.log(`‚ÑπÔ∏è Image received but no command (use "### " for Veo 3 video, "## " for Kling video, "* " for Gemini edit, or "# " for OpenAI edit)`);
      }
    }
    // Handle video messages for video-to-video processing
    else if (messageData.typeMessage === 'videoMessage') {
      const videoData = messageData.fileMessageData || messageData.videoMessageData;
      const caption = videoData?.caption || '';
      
      console.log(`üé¨ Video message received with caption: "${caption}"`);
      
      // Check if caption starts with "## " for RunwayML Gen4 video-to-video
      if (caption.startsWith('## ')) {
        const prompt = caption.substring(3).trim(); // Remove "## "
        console.log(`üé¨ RunwayML Gen4 video-to-video request with prompt: "${prompt}"`);
        
        // Process RunwayML video-to-video asynchronously
        processVideoToVideoAsync({
          chatId,
          senderId,
          senderName,
          videoUrl: videoData.downloadUrl,
          prompt: prompt
        });
      } else {
        console.log(`‚ÑπÔ∏è Video received but no command (use "## " for RunwayML Gen4 video-to-video)`);
      }
    }
    // Handle voice messages for voice-to-voice processing
    else if (messageData.typeMessage === 'audioMessage' || messageData.typeMessage === 'voiceMessage') {
      const audioData = messageData.fileMessageData || messageData.audioMessageData;
      
      console.log(`üé§ Voice message received`);
      
      // Process voice-to-voice asynchronously
      processVoiceMessageAsync({
        chatId,
        senderId,
        senderName,
        audioUrl: audioData.downloadUrl
      });
    } else if (messageText) {
      // Process text message asynchronously - don't await
      processTextMessageAsync({
        chatId,
        senderId,
        senderName,
        messageText: messageText.trim()
      });
    } else {
      console.log(`‚ÑπÔ∏è Unsupported message type: ${messageData.typeMessage}`);
    }
  } catch (error) {
    console.error('‚ùå Error handling incoming message:', error.message || error);
  }
}

/**
 * Process text message asynchronously (no await from webhook)
 */
function processTextMessageAsync(messageData) {
  // Run in background without blocking webhook response
  handleTextMessage(messageData).catch(error => {
    console.error('‚ùå Error in async message processing:', error.message || error);
  });
}

/**
 * Process image edit message asynchronously (no await from webhook)
 */
function processImageEditAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageEdit(imageData).catch(error => {
    console.error('‚ùå Error in async image edit processing:', error.message || error);
  });
}

/**
 * Process image-to-video message asynchronously (no await from webhook)
 */
function processImageToVideoAsync(imageData) {
  // Run in background without blocking webhook response
  handleImageToVideo(imageData).catch(error => {
    console.error('‚ùå Error in async image-to-video processing:', error.message || error);
  });
}

/**
 * Process voice message asynchronously (no await from webhook)
 */
function processVoiceMessageAsync(voiceData) {
  // Run in background without blocking webhook response
  handleVoiceMessage(voiceData).catch(error => {
    console.error('‚ùå Error in async voice processing:', error.message || error);
  });
}

/**
 * Process video-to-video message asynchronously (no await from webhook)
 */
function processVideoToVideoAsync(videoData) {
  // Run in background without blocking webhook response
  handleVideoToVideo(videoData).catch(error => {
    console.error('‚ùå Error in async video-to-video processing:', error.message || error);
  });
}

/**
 * Handle image edit with AI (Gemini or OpenAI)
 */
async function handleImageEdit({ chatId, senderId, senderName, imageUrl, prompt, service }) {
  console.log(`üé® Processing ${service} image edit request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    const ackMessage = service === 'gemini' 
      ? 'üé® ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊¢◊ï◊®◊ö ◊ê◊ï◊™◊î ◊¢◊ù Gemini...'
      : 'üñºÔ∏è ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊¢◊ï◊®◊ö ◊ê◊ï◊™◊î ◊¢◊ù OpenAI...';
    await sendTextMessage(chatId, ackMessage);
    
    // Add user message to conversation
    conversationManager.addMessage(chatId, 'user', `◊¢◊®◊ô◊õ◊™ ◊™◊û◊ï◊†◊î (${service}): ${prompt}`);
    
    // Download the image first
    const imageBuffer = await downloadFile(imageUrl);
    const base64Image = imageBuffer.toString('base64');
    
    // Edit image with selected AI service
    let editResult;
    if (service === 'gemini') {
      editResult = await editImageForWhatsApp(prompt, base64Image);
    } else if (service === 'openai') {
      editResult = await editOpenAIImage(prompt, base64Image);
    }
    
    if (editResult.success && editResult.imageUrl) {
      // Send the edited image with caption
      const fileName = `${service}_edit_${Date.now()}.png`;
      const caption = editResult.description && editResult.description.length > 0 
        ? editResult.description 
        : '';
      
      await sendFileByUrl(chatId, editResult.imageUrl, fileName, caption);
      
      // Add AI response to conversation history
      if (caption) {
        conversationManager.addMessage(chatId, 'assistant', caption);
      }
      
      console.log(`‚úÖ ${service} edited image sent to ${senderName}${caption ? ' with caption: ' + caption : ''}`);
    } else {
      const errorMsg = editResult.error || '◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊¢◊®◊ï◊ö ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.';
      await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
      console.log(`‚ùå ${service} image edit failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`‚ùå Error in ${service} image editing:`, error.message || error);
    await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊¢◊®◊ô◊õ◊™ ◊î◊™◊û◊ï◊†◊î.');
  }
}

/**
 * Handle image-to-video with Veo 3 or Kling
 */
async function handleImageToVideo({ chatId, senderId, senderName, imageUrl, prompt, service = 'veo3' }) {
  const serviceName = service === 'veo3' ? 'Veo 3' : 'Kling 2.1 Master';
  console.log(`üé¨ Processing ${serviceName} image-to-video request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    const ackMessage = service === 'veo3' 
      ? 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Veo 3...'
      : 'üé¨ ◊ß◊ô◊ë◊ú◊™◊ô ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊û◊ô◊ì ◊ô◊ï◊¶◊® ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Kling 2.1...';
    await sendTextMessage(chatId, ackMessage);
    
    // Add user message to conversation
    conversationManager.addMessage(chatId, 'user', `◊ô◊¶◊ô◊®◊™ ◊ï◊ô◊ì◊ê◊ï ◊û◊™◊û◊ï◊†◊î (${serviceName}): ${prompt}`);
    
    // Download the image first
    const imageBuffer = await downloadFile(imageUrl);
    
    // Generate video with selected service
    let videoResult;
    if (service === 'veo3') {
      videoResult = await generateVideoFromImageForWhatsApp(prompt, imageBuffer);
    } else {
      videoResult = await generateKlingVideoFromImage(imageBuffer, prompt);
    }
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `${service}_image_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Add AI response to conversation history
      conversationManager.addMessage(chatId, 'assistant', `◊ï◊ô◊ì◊ê◊ï ◊†◊ï◊¶◊® ◊û◊™◊û◊ï◊†◊î (${serviceName}): ${videoResult.description || '◊ï◊ô◊ì◊ê◊ï ◊ó◊ì◊©'}`);
      
      console.log(`‚úÖ ${serviceName} image-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || `◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊ô◊¶◊ï◊® ◊ï◊ô◊ì◊ê◊ï ◊û◊î◊™◊û◊ï◊†◊î ◊¢◊ù ${serviceName}. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.`;
      await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
      console.log(`‚ùå ${serviceName} image-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error(`‚ùå Error in ${serviceName} image-to-video:`, error.message || error);
    await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊ô◊¶◊ô◊®◊™ ◊î◊ï◊ô◊ì◊ê◊ï ◊û◊î◊™◊û◊ï◊†◊î ◊¢◊ù ${serviceName}.`);
  }
}

/**
 * Handle video-to-video with RunwayML Gen4
 */
async function handleVideoToVideo({ chatId, senderId, senderName, videoUrl, prompt }) {
  console.log(`üé¨ Processing RunwayML Gen4 video-to-video request from ${senderName}: "${prompt}"`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'runway_video_to_video' });
    
    // Add user message to conversation
    conversationManager.addMessage(chatId, 'user', `◊¢◊ô◊ë◊ï◊ì ◊ï◊ô◊ì◊ê◊ï: ${prompt}`);
    
    // Download the video first
    const videoBuffer = await downloadFile(videoUrl);
    
    // Generate video with RunwayML Gen4
    const videoResult = await generateRunwayVideoFromVideo(videoBuffer, prompt);
    
    if (videoResult.success && videoResult.videoUrl) {
      // Send the generated video without caption
      const fileName = `runway_video_${Date.now()}.mp4`;
      
      await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
      
      // Add AI response to conversation history
      conversationManager.addMessage(chatId, 'assistant', `◊ï◊ô◊ì◊ê◊ï ◊¢◊ï◊ë◊ì ◊û◊ó◊ì◊©: ${videoResult.description || '◊ï◊ô◊ì◊ê◊ï ◊ó◊ì◊©'}`);
      
      console.log(`‚úÖ RunwayML Gen4 video-to-video sent to ${senderName}`);
    } else {
      const errorMsg = videoResult.error || '◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊¢◊ë◊ì ◊ê◊™ ◊î◊ï◊ï◊ô◊ì◊ê◊ï. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.';
      await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
      console.log(`‚ùå RunwayML Gen4 video-to-video failed for ${senderName}: ${errorMsg}`);
    }
  } catch (error) {
    console.error('‚ùå Error in RunwayML Gen4 video-to-video:', error.message || error);
    await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊¢◊ô◊ë◊ï◊ì ◊î◊ï◊ï◊ô◊ì◊ê◊ï.');
  }
}

/**
 * Handle voice message with full voice-to-voice processing
 * Flow: Speech-to-Text ‚Üí Voice Clone ‚Üí Gemini Response ‚Üí Text-to-Speech
 */
async function handleVoiceMessage({ chatId, senderId, senderName, audioUrl }) {
  console.log(`üé§ Processing voice-to-voice request from ${senderName}`);
  
  try {
    // Send immediate ACK
    await sendAck(chatId, { type: 'voice_processing' });
    
    // Step 1: Download audio file
    const audioBuffer = await downloadFile(audioUrl);
    
    // Step 2: Speech-to-Text transcription
    console.log(`üîÑ Step 1: Transcribing speech...`);
    const transcriptionOptions = {
      model: 'scribe_v1',
      language: null, // Auto-detect
      removeNoise: true,
      removeFiller: true,
      optimizeLatency: 0,
      format: 'ogg' // WhatsApp audio format
    };
    
    const transcriptionResult = await speechService.speechToText(audioBuffer, transcriptionOptions);
    
    if (transcriptionResult.error) {
      console.error('‚ùå Transcription failed:', transcriptionResult.error);
      await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊™◊û◊ú◊ú ◊ê◊™ ◊î◊î◊ß◊ú◊ò◊î: ${transcriptionResult.error}`);
      return;
    }

    const transcribedText = transcriptionResult.text;
    console.log(`‚úÖ Step 1 complete: Transcribed ${transcribedText.length} characters`);
    console.log(`üìù Transcribed: "${transcribedText}"`);

    // Send transcription to user first
    await sendTextMessage(chatId, `üìù ◊™◊û◊ú◊ï◊ú: "${transcribedText}"`);

    // Step 2: Create Instant Voice Clone
    console.log(`üîÑ Step 2: Creating voice clone...`);
    const voiceCloneOptions = {
      name: `WhatsApp Voice Clone ${Date.now()}`,
      description: `Voice clone from WhatsApp audio`,
      removeBackgroundNoise: true,
      labels: JSON.stringify({
        accent: transcriptionResult.detectedLanguage === 'he' ? 'hebrew' : 'natural',
        use_case: 'conversational',
        quality: 'high',
        style: 'natural',
        language: transcriptionResult.detectedLanguage || 'he'
      })
    };
    
    const voiceCloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
    
    if (voiceCloneResult.error) {
      console.error('‚ùå Voice cloning failed:', voiceCloneResult.error);
      await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊ô◊¶◊ï◊® ◊©◊ô◊ë◊ï◊ò ◊ß◊ï◊ú: ${voiceCloneResult.error}`);
      return;
    }

    const voiceId = voiceCloneResult.voiceId;
    const detectedLanguage = transcriptionResult.detectedLanguage || 'he';
    console.log(`‚úÖ Step 2 complete: Voice cloned (ID: ${voiceId}), Language: ${detectedLanguage}`);

    // Add user message to conversation
    conversationManager.addMessage(chatId, 'user', `◊î◊ß◊ú◊ò◊î ◊ß◊ï◊ú◊ô◊™: ${transcribedText}`);

    // Step 3: Generate Gemini response
    console.log(`üîÑ Step 3: Generating Gemini response...`);
    const history = conversationManager.getHistory(chatId);
    const geminiResult = await generateGeminiResponse(transcribedText, history);
    
    let textForTTS = transcribedText; // Default to original text
    
    if (geminiResult.error) {
      console.warn('‚ö†Ô∏è Gemini generation failed:', geminiResult.error);
      console.log('üìù Using original transcribed text for TTS');
    } else {
      textForTTS = geminiResult.text;
      console.log(`‚úÖ Step 3 complete: Gemini generated ${textForTTS.length} characters`);
      console.log(`üí¨ Gemini response: "${textForTTS.substring(0, 100)}..."`);
      
      // Add AI response to conversation history
      conversationManager.addMessage(chatId, 'assistant', textForTTS);
    }

    // Step 4: Text-to-Speech with cloned voice
    console.log(`üîÑ Step 4: Converting text to speech with cloned voice...`);
    
    const ttsOptions = {
      modelId: 'eleven_v3', // Use the most advanced model
      outputFormat: 'mp3_44100_128',
      languageCode: detectedLanguage !== 'auto' ? detectedLanguage : 'he'
    };

    const ttsResult = await voiceService.textToSpeech(voiceId, textForTTS, ttsOptions);
    
    if (ttsResult.error) {
      console.error('‚ùå Text-to-speech failed:', ttsResult.error);
      // If TTS fails, send text response instead
      await sendTextMessage(chatId, `üí¨ ${textForTTS}`);
      return;
    }

    console.log(`‚úÖ Step 4 complete: Audio generated at ${ttsResult.audioUrl}`);

    // Step 5: Send voice response back to user
    const fileName = `voice_response_${Date.now()}.mp3`;
    
    // Convert relative URL to full URL for Green API
    const fullAudioUrl = ttsResult.audioUrl.startsWith('http') 
      ? ttsResult.audioUrl 
      : getStaticFileUrl(ttsResult.audioUrl.replace('/static/', ''));
    
    await sendFileByUrl(chatId, fullAudioUrl, fileName, '');
    
    console.log(`‚úÖ Voice-to-voice processing complete for ${senderName}`);

    // Cleanup: Delete the cloned voice (optional - ElevenLabs has limits)
    try {
      await voiceService.deleteVoice(voiceId);
      console.log(`üßπ Cleanup: Voice ${voiceId} deleted`);
    } catch (cleanupError) {
      console.warn('‚ö†Ô∏è Voice cleanup failed:', cleanupError.message);
    }

  } catch (error) {
    console.error('‚ùå Error in voice-to-voice processing:', error.message || error);
    await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊¢◊ô◊ë◊ï◊ì ◊î◊î◊ß◊ú◊ò◊î ◊î◊ß◊ï◊ú◊ô◊™.');
  }
}

/**
 * Handle text message with AI chat functionality
 */
async function handleTextMessage({ chatId, senderId, senderName, messageText }) {
  console.log(`üí¨ Processing text: "${messageText}"`);
  
  const command = parseTextCommand(messageText);
  
  if (!command) {
    console.log('‚ÑπÔ∏è Not a recognized command, ignoring');
    return;
  }

  console.log(`ü§ñ Executing command: ${command.type}`);

  // Send immediate ACK for long-running commands
  await sendAck(chatId, command);

  try {
    switch (command.type) {
      case 'gemini_chat':
        console.log(`ü§ñ Processing Gemini chat request from ${senderName}`);
        
        try {
          // Add user message to conversation
          conversationManager.addMessage(chatId, 'user', command.prompt);
          
          // Get conversation history for context
          const history = conversationManager.getHistory(chatId);
          
          // Generate Gemini response
          const geminiResponse = await generateGeminiResponse(command.prompt, history);
          
          if (geminiResponse.error) {
            await sendTextMessage(chatId, geminiResponse.error);
            console.log(`‚ùå Gemini error for ${senderName}: ${geminiResponse.error}`);
          } else {
            // Add AI response to conversation
            conversationManager.addMessage(chatId, 'assistant', geminiResponse.text);
            await sendTextMessage(chatId, geminiResponse.text);
          }
        } catch (geminiError) {
          console.error('‚ùå Error in Gemini chat:', geminiError.message || geminiError);
          await sendTextMessage(chatId, `‚ùå ${geminiError.message || geminiError}`);
        }
        break;

      case 'openai_chat':
        console.log(`ü§ñ Processing OpenAI chat request from ${senderName}`);
        
        try {
          // Add user message to conversation
          conversationManager.addMessage(chatId, 'user', command.prompt);
          
          // Get conversation history for context
          const openaiHistory = conversationManager.getHistory(chatId);
          
          // Generate OpenAI response
          const openaiResponse = await generateOpenAIResponse(command.prompt, openaiHistory);
          
          if (openaiResponse.error) {
            await sendTextMessage(chatId, openaiResponse.error);
            console.log(`‚ùå OpenAI error for ${senderName}: ${openaiResponse.error}`);
          } else {
            // Add AI response to conversation
            conversationManager.addMessage(chatId, 'assistant', openaiResponse.text);
            await sendTextMessage(chatId, openaiResponse.text);
          }
        } catch (openaiError) {
          console.error('‚ùå Error in OpenAI chat:', openaiError.message || openaiError);
          await sendTextMessage(chatId, `‚ùå ${openaiError.message || openaiError}`);
        }
        break;

      case 'openai_image':
        console.log(`üñºÔ∏è Processing OpenAI image generation request from ${senderName}`);
        
        try {
          // Add user message to conversation
          conversationManager.addMessage(chatId, 'user', `◊ô◊¶◊ô◊®◊™ ◊™◊û◊ï◊†◊î: ${command.prompt}`);
          
          // Generate image with OpenAI (WhatsApp format)
          const openaiImageResult = await generateOpenAIImage(command.prompt);
          
          if (openaiImageResult.success && openaiImageResult.imageUrl) {
            // Send the generated image with text as caption (if exists)
            const fileName = `openai_image_${Date.now()}.png`;
            const caption = openaiImageResult.description && openaiImageResult.description.length > 0 
              ? openaiImageResult.description 
              : '';
            
            await sendFileByUrl(chatId, openaiImageResult.imageUrl, fileName, caption);
            
            // Add AI response to conversation history
            if (caption) {
              conversationManager.addMessage(chatId, 'assistant', caption);
            }
            
            console.log(`‚úÖ OpenAI image sent to ${senderName}${caption ? ' with caption: ' + caption : ''}`);
          } else {
            const errorMsg = openaiImageResult.error || '◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊ô◊¶◊ï◊® ◊™◊û◊ï◊†◊î. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.';
            await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
            console.log(`‚ùå OpenAI image generation failed for ${senderName}: ${errorMsg}`);
          }
        } catch (openaiImageError) {
          console.error('‚ùå Error in OpenAI image generation:', openaiImageError.message || openaiImageError);
          await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊ô◊¶◊ô◊®◊™ ◊î◊™◊û◊ï◊†◊î.');
        }
        break;

      case 'gemini_image':
        console.log(`üé® Processing Gemini image generation request from ${senderName}`);
        
        try {
          // Add user message to conversation
          conversationManager.addMessage(chatId, 'user', `◊ô◊¶◊ô◊®◊™ ◊™◊û◊ï◊†◊î: ${command.prompt}`);
          
          // Generate image with Gemini (WhatsApp format)
          const imageResult = await generateImageForWhatsApp(command.prompt);
          
          if (imageResult.success && imageResult.imageUrl) {
            // Send the generated image with text as caption
            const fileName = `gemini_image_${Date.now()}.png`;
            const caption = imageResult.description && imageResult.description.length > 0 
              ? imageResult.description 
              : '';
            
            await sendFileByUrl(chatId, imageResult.imageUrl, fileName, caption);
            
            // Add both user request and AI response to conversation history
            if (caption) {
              conversationManager.addMessage(chatId, 'assistant', caption);
            }
            
            console.log(`‚úÖ Gemini image sent to ${senderName}${caption ? ' with caption: ' + caption : ''}`);
          } else {
            // Check if Gemini returned text instead of image
            if (imageResult.textResponse) {
              console.log('üìù Gemini returned text instead of image, sending text response');
              await sendTextMessage(chatId, imageResult.textResponse);
              
              // Add Gemini's text response to conversation history
              conversationManager.addMessage(chatId, 'assistant', imageResult.textResponse);
            } else {
              const errorMsg = imageResult.error || '◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊ô◊¶◊ï◊® ◊™◊û◊ï◊†◊î. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.';
              await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
              console.log(`‚ùå Gemini image generation failed for ${senderName}: ${errorMsg}`);
            }
          }
        } catch (imageError) {
          console.error('‚ùå Error in Gemini image generation:', imageError.message || imageError);
          await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊ô◊¶◊ô◊®◊™ ◊î◊™◊û◊ï◊†◊î.');
        }
        break;

      case 'veo3_video':
        console.log(`üé¨ Processing Veo 3 video generation request from ${senderName}`);
        
        try {
          // Add user message to conversation
          conversationManager.addMessage(chatId, 'user', `◊ô◊¶◊ô◊®◊™ ◊ï◊ô◊ì◊ê◊ï: ${command.prompt}`);
          
          // Generate video with Veo 3 (WhatsApp format)
          const videoResult = await generateVideoForWhatsApp(command.prompt);
          
          if (videoResult.success && videoResult.videoUrl) {
            // Send the generated video without caption
            const fileName = `veo3_video_${Date.now()}.mp4`;
            
            await sendFileByUrl(chatId, videoResult.videoUrl, fileName, '');
            
            // Add AI response to conversation history
            conversationManager.addMessage(chatId, 'assistant', `◊ï◊ô◊ì◊ê◊ï ◊†◊ï◊¶◊®: ${videoResult.description || '◊ï◊ô◊ì◊ê◊ï ◊ó◊ì◊©'}`);
            
            console.log(`‚úÖ Veo 3 video sent to ${senderName}`);
          } else {
            const errorMsg = videoResult.error || '◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊ô◊¶◊ï◊® ◊ï◊ô◊ì◊ê◊ï. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.';
            await sendTextMessage(chatId, `‚ùå ◊°◊ú◊ô◊ó◊î, ${errorMsg}`);
            console.log(`‚ùå Veo 3 video generation failed for ${senderName}: ${errorMsg}`);
          }
        } catch (videoError) {
          console.error('‚ùå Error in Veo 3 video generation:', videoError.message || videoError);
          await sendTextMessage(chatId, '‚ùå ◊°◊ú◊ô◊ó◊î, ◊î◊ô◊ô◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊ô◊¶◊ô◊®◊™ ◊î◊ï◊ô◊ì◊ê◊ï.');
        }
        break;

      case 'clear_conversation':
        const cleared = conversationManager.clearSession(chatId);
        if (cleared) {
          await sendTextMessage(chatId, 'üóëÔ∏è ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊î◊©◊ô◊ó◊î ◊†◊û◊ó◊ß◊î ◊ë◊î◊¶◊ú◊ó◊î');
        } else {
          await sendTextMessage(chatId, '‚ÑπÔ∏è ◊ê◊ô◊ü ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊©◊ô◊ó◊î ◊ú◊û◊ó◊ô◊ß◊î');
        }
        break;

      case 'show_history':
        const history = conversationManager.getHistory(chatId);
        if (history.length === 0) {
          await sendTextMessage(chatId, '‚ÑπÔ∏è ◊ê◊ô◊ü ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊©◊ô◊ó◊î');
        } else {
          let historyText = 'üìã ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊î◊©◊ô◊ó◊î:\n\n';
          history.forEach((msg, index) => {
            const role = msg.role === 'user' ? 'üë§ ◊ê◊™◊î' : 'ü§ñ AI';
            historyText += `${index + 1}. ${role}: ${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}\n\n`;
          });
          await sendTextMessage(chatId, historyText);
        }
        break;

      case 'help':
        const helpMessage = 'ü§ñ Green API Bot Commands:\n\nüí¨ AI Chat:\nüîÆ * [◊©◊ê◊ú◊î] - Gemini Chat\nü§ñ # [◊©◊ê◊ú◊î] - OpenAI Chat\n\nüé® ◊ô◊¶◊ô◊®◊™ ◊™◊û◊ï◊†◊ï◊™:\nüñºÔ∏è ** [◊™◊ô◊ê◊ï◊®] - ◊ô◊¶◊ô◊®◊™ ◊™◊û◊ï◊†◊î ◊¢◊ù Gemini\nüñºÔ∏è ## [◊™◊ô◊ê◊ï◊®] - ◊ô◊¶◊ô◊®◊™ ◊™◊û◊ï◊†◊î ◊¢◊ù OpenAI\n\nüé¨ ◊ô◊¶◊ô◊®◊™ ◊ï◊ô◊ì◊ê◊ï:\nüé• #### [◊™◊ô◊ê◊ï◊®] - ◊ô◊¶◊ô◊®◊™ ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù Veo 3 (9:16, ◊ê◊ô◊õ◊ï◊™ ◊û◊ß◊°◊ô◊û◊ú◊ô◊™)\nüé¨ ◊©◊ú◊ó ◊™◊û◊ï◊†◊î ◊¢◊ù ◊õ◊ï◊™◊®◊™: ### [◊™◊ô◊ê◊ï◊®] - ◊ï◊ô◊ì◊ê◊ï ◊û◊™◊û◊ï◊†◊î ◊¢◊ù Veo 3\nüé¨ ◊©◊ú◊ó ◊™◊û◊ï◊†◊î ◊¢◊ù ◊õ◊ï◊™◊®◊™: ## [◊™◊ô◊ê◊ï◊®] - ◊ï◊ô◊ì◊ê◊ï ◊û◊™◊û◊ï◊†◊î ◊¢◊ù Kling 2.1\nüé¨ ◊©◊ú◊ó ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù ◊õ◊ï◊™◊®◊™: ## [◊™◊ô◊ê◊ï◊®] - ◊¢◊ô◊ë◊ï◊ì ◊ï◊ô◊ì◊ê◊ï ◊¢◊ù RunwayML Gen4\n\nüé§ ◊¢◊ô◊ë◊ï◊ì ◊ß◊ï◊ú◊ô:\nüó£Ô∏è ◊©◊ú◊ó ◊î◊ß◊ú◊ò◊î ◊ß◊ï◊ú◊ô◊™ - ◊™◊û◊ú◊ï◊ú + ◊™◊í◊ï◊ë◊™ AI + ◊©◊ô◊ë◊ï◊ò ◊ß◊ï◊ú\nüìù Flow: ◊ß◊ï◊ú ‚Üí ◊™◊û◊ú◊ï◊ú ‚Üí Gemini ‚Üí ◊ß◊ï◊ú ◊ó◊ì◊© ◊ë◊ß◊ï◊ú◊ö\n\n‚ú® ◊¢◊®◊ô◊õ◊™ ◊™◊û◊ï◊†◊ï◊™:\nüé® ◊©◊ú◊ó ◊™◊û◊ï◊†◊î ◊¢◊ù ◊õ◊ï◊™◊®◊™: * [◊î◊ï◊®◊ê◊ï◊™ ◊¢◊®◊ô◊õ◊î] - Gemini\nüñºÔ∏è ◊©◊ú◊ó ◊™◊û◊ï◊†◊î ◊¢◊ù ◊õ◊ï◊™◊®◊™: # [◊î◊ï◊®◊ê◊ï◊™ ◊¢◊®◊ô◊õ◊î] - OpenAI\n\n‚öôÔ∏è ◊†◊ô◊î◊ï◊ú ◊©◊ô◊ó◊î:\nüóëÔ∏è /clear - ◊û◊ó◊ô◊ß◊™ ◊î◊ô◊°◊ò◊ï◊®◊ô◊î\nüìù /history - ◊î◊¶◊í◊™ ◊î◊ô◊°◊ò◊ï◊®◊ô◊î\n‚ùì /help - ◊î◊¶◊í◊™ ◊¢◊ñ◊®◊î ◊ñ◊ï\n\nüí° ◊ì◊ï◊í◊û◊ê◊ï◊™:\n* ◊û◊î ◊î◊î◊ë◊ì◊ú ◊ë◊ô◊ü AI ◊ú◊ë◊ô◊ü ML?\n# ◊õ◊™◊ï◊ë ◊ú◊ô ◊©◊ô◊® ◊¢◊ú ◊ó◊™◊ï◊ú\n** ◊ó◊™◊ï◊ú ◊õ◊™◊ï◊ù ◊©◊ô◊ï◊©◊ë ◊¢◊ú ◊¢◊•\n#### ◊©◊§◊ü ◊ê◊ï◊û◊® Hi\nüé® ◊™◊û◊ï◊†◊î + ◊õ◊ï◊™◊®◊™: * ◊î◊ï◊°◊£ ◊õ◊ï◊ë◊¢ ◊ê◊ì◊ï◊ù\nüñºÔ∏è ◊™◊û◊ï◊†◊î + ◊õ◊ï◊™◊®◊™: # ◊î◊§◊ï◊ö ◊®◊ß◊¢ ◊ú◊õ◊ó◊ï◊ú\nüé¨ ◊™◊û◊ï◊†◊î + ◊õ◊ï◊™◊®◊™: ### ◊î◊†◊§◊© ◊ê◊™ ◊î◊™◊û◊ï◊†◊î ◊¢◊ù Veo 3\nüé¨ ◊™◊û◊ï◊†◊î + ◊õ◊ï◊™◊®◊™: ## ◊î◊†◊§◊© ◊ê◊™ ◊î◊™◊û◊ï◊†◊î ◊¢◊ù Kling\nüé¨ ◊ï◊ô◊ì◊ê◊ï + ◊õ◊ï◊™◊®◊™: ## ◊©◊§◊® ◊ê◊™ ◊î◊ï◊ï◊ô◊ì◊ê◊ï ◊ï◊™◊ï◊°◊ô◊£ ◊ê◊§◊ß◊ò◊ô◊ù\nüé§ ◊©◊ú◊ó ◊î◊ß◊ú◊ò◊î ◊ß◊ï◊ú◊ô◊™ ◊ú◊¢◊ô◊ë◊ï◊ì ◊û◊ú◊ê';

        await sendTextMessage(chatId, helpMessage);
        break;

      default:
        console.log(`‚ùì Unknown command type: ${command.type}`);
    }
  } catch (error) {
    console.error('‚ùå Error executing command:', error.message || error);
    await sendTextMessage(chatId, `‚ùå ${error.message || error}`);
  }
}

/**
 * Parse text message to extract command
 */
function parseTextCommand(text) {
  if (!text || typeof text !== 'string') {
    return null;
  }

  text = text.trim();

  // Veo 3 Video Generation command: #### + space + text
  if (text.startsWith('#### ')) {
    const prompt = text.substring(5).trim(); // Remove "#### "
    return {
      type: 'veo3_video',
      prompt: prompt,
      originalMessage: text
    };
  }

  // OpenAI Image Generation command: ## + space + text
  if (text.startsWith('## ')) {
    const prompt = text.substring(3).trim(); // Remove "## "
    return {
      type: 'openai_image',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Gemini Image Generation command: ** + space + text
  if (text.startsWith('** ')) {
    const prompt = text.substring(3).trim(); // Remove "** "
    return {
      type: 'gemini_image',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Gemini Chat command: * + space + text
  if (text.startsWith('* ')) {
    const prompt = text.substring(2).trim(); // Remove "* "
    return {
      type: 'gemini_chat',
      prompt: prompt,
      originalMessage: text
    };
  }

  // OpenAI Chat command: # + space + text
  if (text.startsWith('# ')) {
    const prompt = text.substring(2).trim(); // Remove "# "
    return {
      type: 'openai_chat',
      prompt: prompt,
      originalMessage: text
    };
  }

  // Clear conversation
  if (text.toLowerCase() === '/clear') {
    return { type: 'clear_conversation' };
  }

  // Show history
  if (text.toLowerCase() === '/history') {
    return { type: 'show_history' };
  }

  // Help
  if (text.toLowerCase() === '/help') {
    return { type: 'help' };
  }

  return null;
}

module.exports = router;
