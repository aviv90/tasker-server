/**
 * Gemini AI Service
 */

const { GoogleGenerativeAI } = require('@google/generative-ai');
const genai = require('@google/genai');
const { sanitizeText } = require('../utils/textSanitizer');
const { getStaticFileUrl } = require('../utils/urlUtils');
const fs = require('fs');
const path = require('path');
const { v4: uuidv4 } = require('uuid');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const veoClient = new genai.GoogleGenAI({
    apiKey: process.env.GEMINI_API_KEY
});

/**
 * Extract the actual error message from Gemini response
 * Uses finishMessage if available, otherwise constructs from finishReason
 * @param {Object} candidate - Gemini candidate object
 * @param {Object} promptFeedback - Gemini promptFeedback object
 * @returns {string} - User-friendly error message
 */
function getGeminiErrorMessage(candidate, promptFeedback = null) {
    // Priority 1: Use finishMessage if available (contains detailed explanation)
    if (candidate?.finishMessage) {
        return candidate.finishMessage;
    }
    
    // Priority 2: Use promptFeedback blockReasonMessage if available
    if (promptFeedback?.blockReasonMessage) {
        return promptFeedback.blockReasonMessage;
    }
    
    // Priority 3: Construct from finishReason
    if (candidate?.finishReason) {
        const reason = candidate.finishReason;
        
        if (reason === 'SAFETY' || reason === 'IMAGE_SAFETY') {
            return 'Gemini blocked the request due to safety concerns. Try a different image or prompt.';
        }
        if (reason === 'RECITATION') {
            return 'Gemini blocked the request due to potential copyright issues. Try a different prompt.';
        }
        if (reason === 'PROHIBITED_CONTENT') {
            return 'Gemini blocked the request due to prohibited content. Try a different image or prompt.';
        }
        
        return `Gemini returned no content (reason: ${reason})`;
    }
    
    // Fallback
    return 'No response from Gemini';
}

async function generateImageWithText(prompt) {
    try {
        console.log('üé® Starting Gemini image generation');
        
        // Sanitize prompt as an extra safety measure
        let cleanPrompt = sanitizeText(prompt);
        
        // Remove image creation instructions from prompt (Gemini Image gets confused by them)
        // Hebrew patterns: "◊ú◊¶◊ô◊ô◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊¶◊ô◊ô◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊¶◊ï◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊î◊§◊ï◊ö ◊ú◊™◊û◊ï◊†◊î ◊ê◊™", etc.
        // English patterns: "draw image of", "create image of", "make image of", etc.
        cleanPrompt = cleanPrompt
            .replace(/^(◊ú)?(◊¶◊ô◊ô◊®|◊¶◊ï◊®|◊î◊§◊ï◊ö|◊¶◊®◊ô|◊™◊¶◊ô◊ô◊®|◊™◊¶◊ï◊®)\s+(◊™◊û◊ï◊†◊î\s+)?(◊©◊ú\s+)?/i, '')
            .replace(/^(to\s+)?(draw|create|make|generate|produce)\s+(an?\s+)?(image|picture|photo)\s+(of\s+)?/i, '')
            .trim();
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash-image-preview" 
        });
        
        const result = await model.generateContent({
            contents: [{ role: "user", parts: [{ text: cleanPrompt }] }],
            generationConfig: { 
                responseModalities: ["IMAGE", "TEXT"], // Allow both - Gemini can add description/caption
                temperature: 0.7
            }
        });
        
        const response = result.response;
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini: No candidates returned');
            const errorMsg = getGeminiErrorMessage(null, response.promptFeedback);
            return { error: errorMsg };
        }
        
        const cand = response.candidates[0];
        let text = '';
        let imageBuffer = null;
        
        // Check if content and parts exist
        if (!cand.content || !cand.content.parts) {
            console.log('‚ùå Gemini: No content or parts found in candidate');
            console.log('   Full candidate:', JSON.stringify(cand));
            const errorMsg = getGeminiErrorMessage(cand);
            return { error: errorMsg };
        }
        
        // Process all parts in the response
        for (const part of cand.content.parts) {
            if (part.text) {
                text += part.text;
            } else if (part.inlineData?.data) {
                imageBuffer = Buffer.from(part.inlineData.data, 'base64');
            }
        }
        
        if (!imageBuffer) {
            console.log('‚ùå Gemini: No image data found in response');
            
            // If we got text instead, it means Gemini failed to generate image
            if (text && text.trim().length > 0) {
                console.log('üìù Gemini returned text instead of image - generation failed');
                console.log(`   Gemini response: ${text.substring(0, 200)}...`);
                return { 
                    error: 'Gemini ◊ú◊ê ◊î◊¶◊ú◊ô◊ó ◊ú◊ô◊¶◊ï◊® ◊™◊û◊ï◊†◊î. ◊†◊°◊î prompt ◊ê◊ó◊® ◊ê◊ï ◊î◊©◊™◊û◊© ◊ë-OpenAI ◊ë◊û◊ß◊ï◊ù.'
                };
            }
            
            return { error: 'No image or text data found in response' };
        }
        
        console.log('‚úÖ Gemini image generated successfully');
        return { text: text || prompt, imageBuffer };
    } catch (err) {
        console.error('‚ùå Gemini image generation error:', err);
        // Throw the error so it gets caught by the route's catch block
        throw err;
    }
}

async function generateImageForWhatsApp(prompt, req = null) {
    try {
        console.log('üé® Starting Gemini image generation');
        
        // Sanitize prompt as an extra safety measure
        let cleanPrompt = sanitizeText(prompt);
        
        // Remove image creation instructions from prompt (Gemini Image gets confused by them)
        // Hebrew patterns: "◊ú◊¶◊ô◊ô◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊¶◊ô◊ô◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊¶◊ï◊® ◊™◊û◊ï◊†◊î ◊©◊ú", "◊î◊§◊ï◊ö ◊ú◊™◊û◊ï◊†◊î ◊ê◊™", etc.
        // English patterns: "draw image of", "create image of", "make image of", etc.
        cleanPrompt = cleanPrompt
            .replace(/^(◊ú)?(◊¶◊ô◊ô◊®|◊¶◊ï◊®|◊î◊§◊ï◊ö|◊¶◊®◊ô|◊™◊¶◊ô◊ô◊®|◊™◊¶◊ï◊®)\s+(◊™◊û◊ï◊†◊î\s+)?(◊©◊ú\s+)?/i, '')
            .replace(/^(to\s+)?(draw|create|make|generate|produce)\s+(an?\s+)?(image|picture|photo)\s+(of\s+)?/i, '')
            .trim();
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash-image-preview" 
        });
        
        const result = await model.generateContent({
            contents: [{ role: "user", parts: [{ text: cleanPrompt }] }],
            generationConfig: { 
                responseModalities: ["IMAGE", "TEXT"], // Allow text captions/descriptions alongside image
                temperature: 0.7
            }
        });
        
        
        const response = result.response;
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini: No candidates returned');
            const errorMsg = getGeminiErrorMessage(null, response.promptFeedback);
            return { 
                success: false, 
                error: errorMsg
            };
        }
        
        const cand = response.candidates[0];
        let text = '';
        let imageBuffer = null;
        
        // Check if content and parts exist
        if (!cand.content || !cand.content.parts) {
            console.log('‚ùå Gemini: No content or parts found in candidate');
            console.log('   Full candidate:', JSON.stringify(cand));
            const errorMsg = getGeminiErrorMessage(cand);
            return { 
                success: false, 
                error: errorMsg
            };
        }
        
        // Process all parts in the response
        for (const part of cand.content.parts) {
            if (part.text) {
                text += part.text;
            } else if (part.inlineData?.data) {
                imageBuffer = Buffer.from(part.inlineData.data, 'base64');
            }
        }
        
        if (!imageBuffer) {
            console.log('‚ùå Gemini: No image data found in response');
            
            // If we got text instead, it means Gemini failed to edit/generate image
            if (text && text.trim().length > 0) {
                console.log('üìù Gemini returned text instead of image - edit/generation failed');
                console.log(`   Gemini response: ${text.substring(0, 200)}...`);
                return { 
                    success: false, 
                    error: 'Gemini ◊ú◊ê ◊î◊¶◊ú◊ô◊ó ◊ú◊¢◊®◊ï◊ö/◊ú◊ô◊¶◊ï◊® ◊™◊û◊ï◊†◊î. ◊†◊°◊î prompt ◊ê◊ó◊® ◊ê◊ï ◊î◊©◊™◊û◊© ◊ë-OpenAI ◊ë◊û◊ß◊ï◊ù.'
                };
            }
            
            return { 
                success: false, 
                error: 'No image or text data found in response'
            };
        }
        
        // Save image to tmp folder and create accessible URL
        const fs = require('fs');
        const path = require('path');
        const { v4: uuidv4 } = require('uuid');
        
        const imageId = uuidv4();
        const fileName = `${imageId}.png`;
        const filePath = path.join(__dirname, '..', 'public', 'tmp', fileName);
        
        // Ensure tmp directory exists
        const tmpDir = path.dirname(filePath);
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        // Write image file
        fs.writeFileSync(filePath, imageBuffer);
        
        // Create public URL using centralized URL utility
        const imageUrl = getStaticFileUrl(fileName, req);
        
        console.log('‚úÖ Gemini image generated successfully');
        console.log(`üñºÔ∏è Image saved to: ${filePath}`);
        console.log(`üîó Public URL: ${imageUrl}`);
        
        return { 
            success: true,
            imageUrl: imageUrl,
            description: text.trim() || "", // Send exactly what Gemini writes
            fileName: fileName
        };
    } catch (err) {
        console.error('‚ùå Gemini image generation error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during image generation' 
        };
    }
}

async function editImageWithText(prompt, base64Image) {
    try {
        console.log('üñºÔ∏è Starting Gemini image editing');
        
        // Sanitize prompt as an extra safety measure
        const cleanPrompt = sanitizeText(prompt);
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash-image-preview" 
        });
        
        const result = await model.generateContent({
            contents: [
                { role: "user", parts: [{ inlineData: { mimeType: "image/jpeg", data: base64Image } }, { text: cleanPrompt }] }
            ],
            generationConfig: { responseModalities: ["TEXT", "IMAGE"] }
        });
        
        const response = result.response;
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini edit: No candidates returned');
            return { error: response.promptFeedback?.blockReasonMessage || 'No candidate returned' };
        }
        
        const cand = response.candidates[0];
        let text = '';
        let imageBuffer = null;
        
        // Log diagnostic info
        console.log(`   Finish reason: ${cand.finishReason}`);
        
        // Check if content and parts exist
        if (!cand.content || !cand.content.parts) {
            console.log('‚ùå Gemini edit: No content or parts found in candidate');
            console.log('   Full candidate:', JSON.stringify(cand));
            const errorMsg = getGeminiErrorMessage(cand);
            return { error: errorMsg };
        }
        
        // Process all parts in the response
        for (const part of cand.content.parts) {
            if (part.text) {
                text += part.text;
            } else if (part.inlineData?.data) {
                imageBuffer = Buffer.from(part.inlineData.data, 'base64');
            }
        }
        
        if (!imageBuffer) {
            console.log('‚ùå Gemini edit: No image data found in response');
            
            // If we got text instead, it means Gemini failed to generate image
            if (text && text.trim().length > 0) {
                console.log('üìù Gemini returned text instead of image - generation failed');
                console.log(`   Gemini response: ${text.substring(0, 200)}...`);
                return { 
                    error: 'Gemini ◊ú◊ê ◊î◊¶◊ú◊ô◊ó ◊ú◊ô◊¶◊ï◊® ◊™◊û◊ï◊†◊î. ◊†◊°◊î prompt ◊ê◊ó◊® ◊ê◊ï ◊î◊©◊™◊û◊© ◊ë-OpenAI ◊ë◊û◊ß◊ï◊ù.'
                };
            }
            
            return { error: 'No image or text data found in response' };
        }
        
        console.log('‚úÖ Gemini image edited successfully');
        return { text: text || prompt, imageBuffer };
    } catch (err) {
        console.error('‚ùå Gemini image edit error:', err);
        // Throw the error so it gets caught by the route's catch block
        throw err;
    }
}

async function editImageForWhatsApp(prompt, base64Image, req) {
    try {
        console.log('üñºÔ∏è Starting Gemini image editing');
        
        // Sanitize prompt as an extra safety measure
        const cleanPrompt = sanitizeText(prompt);
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash-image-preview" 
        });
        
        const result = await model.generateContent({
            contents: [
                { role: "user", parts: [{ inlineData: { mimeType: "image/jpeg", data: base64Image } }, { text: cleanPrompt }] }
            ],
            generationConfig: { responseModalities: ["TEXT", "IMAGE"] }
        });
        
        const response = result.response;
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini edit: No candidates returned');
            console.log('   Prompt feedback:', JSON.stringify(response.promptFeedback));
            return { 
                success: false, 
                error: response.promptFeedback?.blockReasonMessage || 'No candidate returned' 
            };
        }
        
        const cand = response.candidates[0];
        let text = '';
        let imageBuffer = null;
        
        // Log detailed diagnostic info
        console.log(`   Finish reason: ${cand.finishReason}`);
        if (cand.safetyRatings) {
            console.log(`   Safety ratings:`, JSON.stringify(cand.safetyRatings));
        }
        
        // Check if content and parts exist
        if (!cand.content || !cand.content.parts) {
            console.log('‚ùå Gemini edit: No content or parts found in candidate');
            console.log('   Full candidate:', JSON.stringify(cand));
            
            // Check for safety/policy blocks
            if (cand.finishReason === 'SAFETY' || 
                cand.finishReason === 'IMAGE_SAFETY' || 
                cand.finishReason === 'RECITATION' || 
                cand.finishReason === 'PROHIBITED_CONTENT') {
                
                // Use finishMessage if available (contains the actual error)
                const errorMessage = cand.finishMessage || 
                    `Gemini blocked the request due to: ${cand.finishReason}. Try a different image or prompt.`;
                
                return { 
                    success: false, 
                    error: errorMessage
                };
            }
            
            // Check for other finish reasons with messages
            if (cand.finishMessage) {
                return { 
                    success: false, 
                    error: cand.finishMessage
                };
            }
            
            return { 
                success: false, 
                error: `Gemini returned no content (reason: ${cand.finishReason || 'unknown'})` 
            };
        }
        
        // Process all parts in the response
        for (const part of cand.content.parts) {
            if (part.text) {
                text += part.text;
            } else if (part.inlineData?.data) {
                imageBuffer = Buffer.from(part.inlineData.data, 'base64');
            }
        }
        
        if (!imageBuffer) {
            console.log('‚ùå Gemini edit: No image data found in response');
            console.log(`   Got text response (${text.length} chars): ${text.substring(0, 200)}...`);
            
            // If we got text instead, it means Gemini failed to edit image
            if (text && text.trim().length > 0) {
                console.log('üìù Gemini returned text instead of image - edit failed');
                return { 
                    success: false, 
                    error: 'Gemini ◊ú◊ê ◊î◊¶◊ú◊ô◊ó ◊ú◊¢◊®◊ï◊ö ◊ê◊™ ◊î◊™◊û◊ï◊†◊î. ◊†◊°◊î prompt ◊ê◊ó◊® ◊ê◊ï ◊î◊©◊™◊û◊© ◊ë-OpenAI ◊ë◊û◊ß◊ï◊ù.'
                };
            }
            
            return { 
                success: false, 
                error: 'No image or text data found in response' 
            };
        }
        
        // Save to public directory
        const fileName = `gemini_edit_${uuidv4()}.png`;
        const filePath = path.join(__dirname, '..', 'public', 'tmp', fileName);
        
        // Ensure tmp directory exists
        const tmpDir = path.dirname(filePath);
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        // Write image file
        fs.writeFileSync(filePath, imageBuffer);
        
        // Create public URL using centralized URL utility
        const imageUrl = getStaticFileUrl(fileName, req);
        
        console.log('‚úÖ Gemini image edited successfully');
        console.log(`üñºÔ∏è Edited image saved to: ${filePath}`);
        console.log(`üîó Public URL: ${imageUrl}`);
        
        return { 
            success: true,
            imageUrl: imageUrl,
            description: text.trim() || "", // Include text description from Gemini
            fileName: fileName
        };
    } catch (err) {
        console.error('‚ùå Gemini image edit error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during image editing' 
        };
    }
}

async function analyzeImageWithText(prompt, base64Image) {
    try {
        console.log('üîç Starting Gemini image analysis (text-only response)');
        
        // Sanitize prompt as an extra safety measure
        const cleanPrompt = sanitizeText(prompt);
        
        // Detect if prompt is in Hebrew
        const hasHebrew = /[\u0590-\u05FF]/.test(cleanPrompt);
        const languageInstruction = hasHebrew 
            ? '\n\n◊ó◊©◊ï◊ë: ◊¢◊†◊î ◊ë◊¢◊ë◊®◊ô◊™ ◊ë◊ú◊ë◊ì.' 
            : '';
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" // Use regular model for text analysis
        });
        
        const result = await model.generateContent({
            contents: [
                { 
                    role: "user", 
                    parts: [
                        { inlineData: { mimeType: "image/jpeg", data: base64Image } }, 
                        { text: cleanPrompt + languageInstruction }
                    ] 
                }
            ],
            generationConfig: { 
                responseModalities: ["TEXT"], // Text-only response
                temperature: 0.7
            }
        });
        
        const response = result.response;
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini image analysis: No candidates returned');
            return { 
                success: false, 
                error: response.promptFeedback?.blockReasonMessage || 'No candidate returned' 
            };
        }
        
        const cand = response.candidates[0];
        let text = '';
        
        // Extract text from response
        if (cand.content && cand.content.parts) {
            for (const part of cand.content.parts) {
                if (part.text) {
                    text += part.text;
                }
            }
        }
        
        if (!text || text.trim().length === 0) {
            console.log('‚ùå Gemini image analysis: No text found in response');
            return { 
                success: false, 
                error: 'No text response from Gemini' 
            };
        }
        
        console.log('‚úÖ Gemini image analysis completed');
        return { 
            success: true,
            text: text.trim(),
            description: text.trim()
        };
    } catch (err) {
        console.error('‚ùå Gemini image analysis error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during image analysis' 
        };
    }
}

async function analyzeVideoWithText(prompt, videoBuffer) {
    try {
        console.log('üîç Starting Gemini video analysis (text-only response)');
        console.log(`üìπ Video size: ${(videoBuffer.length / 1024 / 1024).toFixed(2)} MB`);
        
        // Sanitize prompt as an extra safety measure
        const cleanPrompt = sanitizeText(prompt);
        
        // Detect if prompt is in Hebrew
        const hasHebrew = /[\u0590-\u05FF]/.test(cleanPrompt);
        const languageInstruction = hasHebrew 
            ? '\n\n◊ó◊©◊ï◊ë: ◊¢◊†◊î ◊ë◊¢◊ë◊®◊ô◊™ ◊ë◊ú◊ë◊ì.' 
            : '';
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" // Use regular model for text analysis
        });
        
        let videoPart;
        
        // For videos larger than 2MB, use Files API; otherwise use inline data
        if (videoBuffer.length > 2 * 1024 * 1024) {
            console.log('üì§ Video is large, uploading to Files API first...');
            
            // Save video to temporary file
            const tempFileName = `temp_analysis_video_${uuidv4()}.mp4`;
            const tempFilePath = path.join(__dirname, '..', 'public', 'tmp', tempFileName);
            const tmpDir = path.dirname(tempFilePath);
            
            if (!fs.existsSync(tmpDir)) {
                fs.mkdirSync(tmpDir, { recursive: true });
            }
            
            fs.writeFileSync(tempFilePath, videoBuffer);
            
            try {
                // Upload video file to Gemini Files API
                const uploadResult = await veoClient.files.upload({
                    file: {
                        path: tempFilePath,
                        mimeType: 'video/mp4'
                    }
                });
                
                console.log('‚úÖ Video uploaded to Files API');
                
                // Use fileData reference instead of inline data
                videoPart = { 
                    fileData: {
                        fileUri: uploadResult.file.uri,
                        mimeType: uploadResult.file.mimeType
                    }
                };
                
                // Clean up temp file after upload
                try {
                    fs.unlinkSync(tempFilePath);
                    console.log('üßπ Cleaned up temporary video file');
                } catch (cleanupErr) {
                    console.warn('‚ö†Ô∏è Could not delete temp file:', cleanupErr.message);
                }
                
            } catch (uploadErr) {
                console.error('‚ùå Failed to upload video to Files API:', uploadErr);
                // Fallback to inline data if upload fails
                console.log('üîÑ Falling back to inline data...');
                const base64Video = videoBuffer.toString('base64');
                videoPart = { inlineData: { mimeType: "video/mp4", data: base64Video } };
            }
        } else {
            console.log('üì¶ Video is small enough, using inline data');
            // Convert video buffer to base64 for inline data
            const base64Video = videoBuffer.toString('base64');
            videoPart = { inlineData: { mimeType: "video/mp4", data: base64Video } };
        }
        
        const result = await model.generateContent({
            contents: [
                { 
                    role: "user", 
                    parts: [
                        videoPart,
                        { text: cleanPrompt + languageInstruction }
                    ] 
                }
            ],
            generationConfig: { 
                responseModalities: ["TEXT"], // Text-only response
                temperature: 0.7
            }
        });
        
        const response = result.response;
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini video analysis: No candidates returned');
            return { 
                success: false, 
                error: response.promptFeedback?.blockReasonMessage || 'No candidate returned' 
            };
        }
        
        const cand = response.candidates[0];
        let text = '';
        
        // Extract text from response
        if (cand.content && cand.content.parts) {
            for (const part of cand.content.parts) {
                if (part.text) {
                    text += part.text;
                }
            }
        }
        
        if (!text || text.trim().length === 0) {
            console.log('‚ùå Gemini video analysis: No text found in response');
            return { 
                success: false, 
                error: 'No text response from Gemini' 
            };
        }
        
        console.log('‚úÖ Gemini video analysis completed');
        return { 
            success: true,
            text: text.trim(),
            description: text.trim()
        };
    } catch (err) {
        console.error('‚ùå Gemini video analysis error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during video analysis' 
        };
    }
}

async function generateVideoWithText(prompt) {
    try {
        console.log('üé¨ Starting Veo 3 text-to-video generation - Stable version');
        const cleanPrompt = sanitizeText(prompt);
        
        let operation = await veoClient.models.generateVideos({
            model: "veo-3.1-generate-preview", // Latest Veo 3 Preview (September 2025)
            prompt: cleanPrompt,
            config: {
                aspectRatio: "9:16" // Vertical format for mobile (720p resolution)
            }
        });
        
        console.log('‚è≥ Polling for video generation completion...');
        const maxWaitTime = 10 * 60 * 1000; // 10 minutes
        const startTime = Date.now();
        let pollAttempts = 0;
        
        while (!operation.done) {
            if (Date.now() - startTime > maxWaitTime) {
                console.error('‚ùå Veo 3 text-to-video generation timed out');
                return { error: 'Video generation timed out after 10 minutes' };
            }
            await new Promise(resolve => setTimeout(resolve, 10000));
            pollAttempts++;
            console.log(`üîÑ Polling attempt ${pollAttempts} for Veo 3 text-to-video generation`);
            operation = await veoClient.operations.getVideosOperation({ operation });
        }
        
        // Check if we have a valid response structure
        if (!operation.response || !operation.response.generatedVideos || 
            !operation.response.generatedVideos.length || 
            !operation.response.generatedVideos[0] || 
            !operation.response.generatedVideos[0].video) {
            console.error('‚ùå Invalid Veo 3 response structure:', operation);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'Invalid response from Veo 3 API';
            if (operation.response && operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return { error: errorMessage };
        }
        
        const videoFile = operation.response.generatedVideos[0].video;
        
        const tempFileName = `temp_video_${uuidv4()}.mp4`;
        const tempFilePath = path.join(__dirname, '..', 'public', 'tmp', tempFileName);
        const tmpDir = path.dirname(tempFilePath);
        
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        try {
            await veoClient.files.download({ file: videoFile, downloadPath: tempFilePath });
            console.log('üì• SDK download completed');
        } catch (downloadError) {
            console.error('‚ùå SDK download failed:', downloadError);
            return { error: `Failed to download video file: ${downloadError.message}` };
        }
        
        // Check if the file was created and is complete
        let retries = 0;
        let fileReady = false;
        
        while (!fileReady && retries < 15) {
            await new Promise(resolve => setTimeout(resolve, 200));
            
            if (fs.existsSync(tempFilePath)) {
                try {
                    const stats = fs.statSync(tempFilePath);
                    
                    // Check that the file is not empty and stable (size doesn't change)
                    if (stats.size > 0) {
                        await new Promise(resolve => setTimeout(resolve, 500));
                        const newStats = fs.statSync(tempFilePath);
                        
                        if (newStats.size === stats.size && stats.size > 10000) { // At least 10KB
                            fileReady = true;
                            break;
                        }
                    }
                } catch (statError) {
                    // Continue retrying
                }
            }
            retries++;
        }
        
        if (!fileReady) {
            console.error('‚ùå Video file was not properly downloaded');
            return { error: 'Video file was not downloaded successfully' };
        }
        
        // Don't delete the file, we need the download link
        // Return buffer, text and result path that will be prefixed in finalizeVideo
        console.log('‚úÖ Veo 3 text-to-video generated successfully.');
        
        const videoBuffer = fs.readFileSync(tempFilePath);
        const filename = path.basename(tempFilePath);
        const publicPath = `/static/${filename}`;
        
        return {
            text: cleanPrompt,
            videoBuffer: videoBuffer,
            result: publicPath // This will be processed by finalizeVideo to create full URL
        };
    } catch (err) {
        console.error('‚ùå Veo 3 text-to-video generation error:', err);
        return { error: err.message || 'Unknown error' };
    }
}

async function generateVideoWithImage(prompt, imageBuffer) {
    try {
        console.log('üé¨ Starting Veo 3 image-to-video generation');
        
        const cleanPrompt = sanitizeText(prompt);
        
        // Convert image buffer to base64 string as expected by the API
        const imageBase64 = imageBuffer.toString('base64');
        
        // Step 1: Generate video with Veo 3 using the provided image
        let operation = await veoClient.models.generateVideos({
            model: "veo-3.1-generate-preview", // Latest Veo 3 Preview (September 2025)
            prompt: cleanPrompt,
            image: {
                imageBytes: imageBase64,
                mimeType: "image/jpeg", // Try JPEG instead of PNG
            },
            config: {
                aspectRatio: "9:16" // Vertical format for mobile (720p resolution)
            }
        });
        
        console.log('‚è≥ Polling for video generation completion...');
        const maxWaitTime = 10 * 60 * 1000; // 10 minutes
        const startTime = Date.now();
        let pollAttempts = 0;
        
        while (!operation.done) {
            if (Date.now() - startTime > maxWaitTime) {
                console.error('‚ùå Veo 3 image-to-video generation timed out');
                return { error: 'Video generation timed out after 10 minutes' };
            }
            await new Promise(resolve => setTimeout(resolve, 10000));
            pollAttempts++;
            console.log(`üîÑ Polling attempt ${pollAttempts} for Veo 3 image-to-video generation`);
            operation = await veoClient.operations.getVideosOperation({ operation });
        }
        
        // Check if we have a valid response structure
        if (!operation.response || !operation.response.generatedVideos || 
            !operation.response.generatedVideos.length || 
            !operation.response.generatedVideos[0] || 
            !operation.response.generatedVideos[0].video) {
            console.error('‚ùå Invalid Veo 3 response structure:', operation);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'Invalid response from Veo 3 API';
            if (operation.response && operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return { error: errorMessage };
        }
        
        const videoFile = operation.response.generatedVideos[0].video;
        
        const tempFileName = `temp_video_${uuidv4()}.mp4`;
        const tempFilePath = path.join(__dirname, '..', 'public', 'tmp', tempFileName);
        const tmpDir = path.dirname(tempFilePath);
        
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        try {
            await veoClient.files.download({ file: videoFile, downloadPath: tempFilePath });
            console.log('üì• SDK download completed');
        } catch (downloadError) {
            console.error('‚ùå SDK download failed:', downloadError);
            return { error: `Failed to download video file: ${downloadError.message}` };
        }
        
        // Check that the file was created and is complete
        let retries = 0;
        let fileReady = false;
        
        while (!fileReady && retries < 15) {
            await new Promise(resolve => setTimeout(resolve, 200));
            
            if (fs.existsSync(tempFilePath)) {
                try {
                    const stats = fs.statSync(tempFilePath);
                    
                    // Check that the file is not empty and stable (size doesn't change)
                    if (stats.size > 0) {
                        await new Promise(resolve => setTimeout(resolve, 500));
                        const newStats = fs.statSync(tempFilePath);
                        
                        if (newStats.size === stats.size && stats.size > 10000) { // At least 10KB
                            fileReady = true;
                            break;
                        }
                    }
                } catch (statError) {
                    // Continue retrying
                }
            }
            retries++;
        }
        
        if (!fileReady) {
            console.error('‚ùå Video file was not properly downloaded');
            return { error: 'Video file was not downloaded successfully' };
        }
        
        console.log('‚úÖ Veo 3 image-to-video generated successfully.');
        
        const videoBuffer = fs.readFileSync(tempFilePath);
        const filename = path.basename(tempFilePath);
        const publicPath = `/static/${filename}`;
        
        return {
            text: cleanPrompt,
            videoBuffer: videoBuffer,
            result: publicPath // This will be processed by finalizeVideo to create full URL
        };
    } catch (err) {
        console.error('‚ùå Veo 3 image-to-video generation error:', err);
        return { error: err.message || 'Unknown error' };
    }
}

async function generateVideoForWhatsApp(prompt, req = null) {
    try {
        console.log('üé¨ Starting Veo 3 text-to-video generation - Preview version');
        const cleanPrompt = sanitizeText(prompt);
        
        let operation = await veoClient.models.generateVideos({
            model: "veo-3.1-generate-preview", // Latest Veo 3 Preview (September 2025)
            prompt: cleanPrompt,
            config: {
                aspectRatio: "9:16" // Vertical format for mobile (720p resolution)
            }
        });
        
        console.log('‚è≥ Polling for video generation completion...');
        const maxWaitTime = 10 * 60 * 1000; // 10 minutes
        const startTime = Date.now();
        let pollAttempts = 0;
        
        while (!operation.done) {
            if (Date.now() - startTime > maxWaitTime) {
                console.error('‚ùå Veo 3 text-to-video generation timed out');
                return { 
                    success: false, 
                    error: 'Video generation timed out after 10 minutes' 
                };
            }
            await new Promise(resolve => setTimeout(resolve, 10000));
            pollAttempts++;
            console.log(`üîÑ Polling attempt ${pollAttempts} for Veo 3 text-to-video generation`);
            operation = await veoClient.operations.getVideosOperation({ operation });
        }
        
        // Check if we have a valid response structure
        if (!operation.response) {
            console.error('‚ùå No response in operation:', operation);
            return {
                success: false,
                error: 'No response received from Veo 3 API'
            };
        }
        
        if (!operation.response.generatedVideos) {
            console.error('‚ùå No generatedVideos in response:', operation.response);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'No generated videos in Veo 3 response';
            if (operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return {
                success: false,
                error: errorMessage
            };
        }
        
        if (!operation.response.generatedVideos.length || !operation.response.generatedVideos[0]) {
            console.error('‚ùå Empty generatedVideos array:', operation.response.generatedVideos);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'No videos were generated by Veo 3';
            if (operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return {
                success: false,
                error: errorMessage
            };
        }
        
        if (!operation.response.generatedVideos[0].video) {
            console.error('‚ùå No video file in first generated video:', operation.response.generatedVideos[0]);
            return {
                success: false,
                error: 'Generated video has no file reference'
            };
        }
        
        const videoFile = operation.response.generatedVideos[0].video;
        
        const fileName = `veo3_video_${uuidv4()}.mp4`;
        const filePath = path.join(__dirname, '..', 'public', 'tmp', fileName);
        const tmpDir = path.dirname(filePath);
        
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        try {
            await veoClient.files.download({ file: videoFile, downloadPath: filePath });
            console.log('üì• SDK download completed');
        } catch (downloadError) {
            console.error('‚ùå SDK download failed:', downloadError);
            return { 
                success: false, 
                error: `Failed to download video file: ${downloadError.message}` 
            };
        }
        
        // Check if the file was created and is complete
        let retries = 0;
        let fileReady = false;
        
        while (!fileReady && retries < 15) {
            await new Promise(resolve => setTimeout(resolve, 200));
            
            if (fs.existsSync(filePath)) {
                try {
                    const stats = fs.statSync(filePath);
                    
                    // Check that the file is not empty and stable (size doesn't change)
                    if (stats.size > 0) {
                        await new Promise(resolve => setTimeout(resolve, 500));
                        const newStats = fs.statSync(filePath);
                        
                        if (newStats.size === stats.size && stats.size > 100000) { // At least 100KB for video
                            fileReady = true;
                            break;
                        }
                    }
                } catch (statError) {
                    // Continue retrying
                }
            }
            retries++;
        }
        
        if (!fileReady) {
            console.error('‚ùå Video file was not properly downloaded');
            return { 
                success: false, 
                error: 'Video file was not downloaded successfully' 
            };
        }
        
        // Create public URL using centralized URL utility
        const videoUrl = getStaticFileUrl(fileName, req);
        
        console.log('‚úÖ Veo 3 text-to-video generated successfully');
        console.log(`üé¨ Video saved to: ${filePath}`);
        console.log(`üîó Public URL: ${videoUrl}`);
        
        return { 
            success: true,
            videoUrl: videoUrl,
            description: cleanPrompt, // Include the prompt as description
            fileName: fileName
        };
    } catch (err) {
        console.error('‚ùå Veo 3 text-to-video generation error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during video generation' 
        };
    }
}

async function generateVideoFromImageForWhatsApp(prompt, imageBuffer, req = null) {
    try {
        console.log('üé¨ Starting Veo 3 image-to-video generation - Stable version');
        const cleanPrompt = sanitizeText(prompt);
        
        // Convert image buffer to base64 string as expected by the API
        const imageBase64 = imageBuffer.toString('base64');
        
        let operation = await veoClient.models.generateVideos({
            model: "veo-3.1-generate-preview", // Latest Veo 3 Preview (September 2025)
            prompt: cleanPrompt,
            image: {
                imageBytes: imageBase64,
                mimeType: "image/jpeg", // Try JPEG instead of PNG
            },
            config: {
                aspectRatio: "9:16" // Vertical format for mobile (720p resolution)
            }
        });
        
        console.log('‚è≥ Polling for video generation completion...');
        const maxWaitTime = 10 * 60 * 1000; // 10 minutes
        const startTime = Date.now();
        let pollAttempts = 0;
        
        while (!operation.done) {
            if (Date.now() - startTime > maxWaitTime) {
                console.error('‚ùå Veo 3 image-to-video generation timed out');
                return { 
                    success: false, 
                    error: 'Video generation timed out after 10 minutes' 
                };
            }
            await new Promise(resolve => setTimeout(resolve, 10000));
            pollAttempts++;
            console.log(`üîÑ Polling attempt ${pollAttempts} for Veo 3 image-to-video generation`);
            operation = await veoClient.operations.getVideosOperation({ operation });
        }
        
        // Check if we have a valid response structure
        if (!operation.response) {
            console.error('‚ùå No response in operation:', operation);
            return {
                success: false,
                error: 'No response received from Veo 3 API'
            };
        }
        
        if (!operation.response.generatedVideos) {
            console.error('‚ùå No generatedVideos in response:', operation.response);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'No generated videos in Veo 3 response';
            if (operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return {
                success: false,
                error: errorMessage
            };
        }
        
        if (!operation.response.generatedVideos.length || !operation.response.generatedVideos[0]) {
            console.error('‚ùå Empty generatedVideos array:', operation.response.generatedVideos);
            
            // Check if there are filtered reasons from Veo 3
            let errorMessage = 'No videos were generated by Veo 3';
            if (operation.response.raiMediaFilteredReasons && operation.response.raiMediaFilteredReasons.length > 0) {
                errorMessage = operation.response.raiMediaFilteredReasons[0]; // Use the original Veo 3 error message
            }
            
            return {
                success: false,
                error: errorMessage
            };
        }
        
        if (!operation.response.generatedVideos[0].video) {
            console.error('‚ùå No video file in first generated video:', operation.response.generatedVideos[0]);
            return {
                success: false,
                error: 'Generated video has no file reference'
            };
        }
        
        const videoFile = operation.response.generatedVideos[0].video;
        
        const fileName = `veo3_image_video_${uuidv4()}.mp4`;
        const filePath = path.join(__dirname, '..', 'public', 'tmp', fileName);
        const tmpDir = path.dirname(filePath);
        
        if (!fs.existsSync(tmpDir)) {
            fs.mkdirSync(tmpDir, { recursive: true });
        }
        
        try {
            await veoClient.files.download({ file: videoFile, downloadPath: filePath });
            console.log('üì• SDK download completed');
        } catch (downloadError) {
            console.error('‚ùå SDK download failed:', downloadError);
            return { 
                success: false, 
                error: `Failed to download video file: ${downloadError.message}` 
            };
        }
        
        // Check if the file was created and is complete
        let retries = 0;
        let fileReady = false;
        
        while (!fileReady && retries < 15) {
            await new Promise(resolve => setTimeout(resolve, 200));
            
            if (fs.existsSync(filePath)) {
                try {
                    const stats = fs.statSync(filePath);
                    
                    // Check that the file is not empty and stable (size doesn't change)
                    if (stats.size > 0) {
                        await new Promise(resolve => setTimeout(resolve, 500));
                        const newStats = fs.statSync(filePath);
                        
                        if (newStats.size === stats.size && stats.size > 100000) { // At least 100KB for video
                            fileReady = true;
                            break;
                        }
                    }
                } catch (statError) {
                    // Continue retrying
                }
            }
            retries++;
        }
        
        if (!fileReady) {
            console.error('‚ùå Video file was not properly downloaded');
            return { 
                success: false, 
                error: 'Video file was not downloaded successfully' 
            };
        }
        
        // Convert video to WhatsApp-compatible format using ffmpeg
        // WhatsApp requires MP4 with H.264 video and AAC audio
        console.log('üé¨ Converting video to WhatsApp-compatible format...');
        const { exec } = require('child_process');
        const convertedFileName = `veo3_image_video_converted_${uuidv4()}.mp4`;
        const convertedFilePath = path.join(__dirname, '..', 'public', 'tmp', convertedFileName);
        
        try {
            await new Promise((resolve, reject) => {
                exec(`ffmpeg -i "${filePath}" -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k -movflags +faststart "${convertedFilePath}" -y`, 
                    (error, stdout, stderr) => {
                        if (error) {
                            console.error('‚ùå FFmpeg conversion failed:', error);
                            console.error('‚ùå FFmpeg stderr:', stderr);
                            reject(error);
                        } else {
                            console.log('‚úÖ Video converted successfully');
                            // Delete original file
                            fs.unlinkSync(filePath);
                            resolve();
                        }
                    });
            });
        } catch (convertError) {
            console.error('‚ùå Video conversion failed:', convertError);
            // Fallback: use original file
            console.log('‚ö†Ô∏è Using original file without conversion');
            const originalVideoUrl = getStaticFileUrl(fileName, req);
            return { 
                success: true,
                videoUrl: originalVideoUrl,
                description: cleanPrompt,
                fileName: fileName
            };
        }
        
        // Create public URL using centralized URL utility
        const videoUrl = getStaticFileUrl(convertedFileName, req);
        
        console.log('‚úÖ Veo 3 image-to-video generated and converted successfully');
        console.log(`üé¨ Video saved to: ${convertedFilePath}`);
        console.log(`üîó Public URL: ${videoUrl}`);
        
        return { 
            success: true,
            videoUrl: videoUrl,
            description: cleanPrompt, // Include the prompt as description
            fileName: convertedFileName
        };
    } catch (err) {
        console.error('‚ùå Veo 3 image-to-video generation error:', err);
        return { 
            success: false, 
            error: err.message || 'Unknown error occurred during image-to-video generation' 
        };
    }
}

/**
 * Clean meta-linguistic thinking patterns and duplicate text from Gemini responses
 * Gemini sometimes ignores instructions and adds reasoning/thinking in English
 * @param {string} text - The raw text from Gemini
 * @returns {string} - Cleaned text without thinking patterns or duplicates
 */
function cleanThinkingPatterns(text) {
    if (!text || typeof text !== 'string') return text;
    
    let cleaned = text;
    const originalLength = text.length;
    
    // 1. Remove English meta-linguistic phrases that appear at the start
    // These often appear before the actual answer
    const metaPhrases = [
        /^This (directly )?addresses? the question[^.]*\.\s*/i,
        /^I('| a)m (understanding|explaining|providing|answering)[^.]*\.\s*/i,
        /^Let me (answer|explain|clarify|tell you)[^.]*\.\s*/i,
        /^As (an AI|requested)[^.]*\.\s*/i,
        /^My (response|answer) (is|should be)[^.]*\.\s*/i,
        /^I should (answer|respond|explain)[^.]*\.\s*/i,
        /^To answer (this|the question)[^.]*\.\s*/i,
        /^The (answer|response) (is|should be)[^.]*\.\s*/i,
        /^Based on (the question|what you asked)[^.]*\.\s*/i
    ];
    
    for (const pattern of metaPhrases) {
        cleaned = cleaned.replace(pattern, '');
    }
    
    // 2. Remove parenthetical thinking/reasoning in English
    // Example: "(without asking for more context)" or "(as the rules state...)"
    cleaned = cleaned.replace(/\([^)]*without asking[^)]*\)/gi, '');
    cleaned = cleaned.replace(/\([^)]*as the rules state[^)]*\)/gi, '');
    cleaned = cleaned.replace(/\([^)]*as requested[^)]*\)/gi, '');
    
    // 3. Remove duplicate paragraphs/sentences
    // Sometimes Gemini repeats the same text twice
    const lines = cleaned.split('\n');
    const uniqueLines = [];
    const seenLines = new Set();
    
    for (const line of lines) {
        const trimmedLine = line.trim();
        // Skip empty lines in deduplication (but keep them in output)
        if (trimmedLine === '') {
            uniqueLines.push(line);
            continue;
        }
        
        // Only add non-duplicate content lines
        if (!seenLines.has(trimmedLine)) {
            seenLines.add(trimmedLine);
            uniqueLines.push(line);
        } else {
            console.log(`üßπ Removed duplicate line: "${trimmedLine.substring(0, 50)}..."`);
        }
    }
    
    cleaned = uniqueLines.join('\n');
    
    // 4. Remove consecutive duplicate words (sometimes Gemini stutters)
    // Example: "◊ê◊†◊ô ◊û◊ë◊ô◊ü ◊û◊ë◊ô◊ü ◊ê◊™ ◊î◊©◊ê◊ú◊î" -> "◊ê◊†◊ô ◊û◊ë◊ô◊ü ◊ê◊™ ◊î◊©◊ê◊ú◊î"
    cleaned = cleaned.replace(/\b(\w+)\s+\1\b/g, '$1');
    
    // 5. Detect and handle mixed languages - remove English paragraphs if main content is Hebrew
    // Count Hebrew vs English characters to determine primary language
    const hebrewChars = (cleaned.match(/[\u0590-\u05FF]/g) || []).length;
    const englishChars = (cleaned.match(/[a-zA-Z]/g) || []).length;
    
    // If primary language is Hebrew (Hebrew chars > English chars), remove English-only paragraphs
    if (hebrewChars > englishChars && hebrewChars > 10) {
        console.log(`üåê Detected Hebrew as primary language (${hebrewChars} Hebrew vs ${englishChars} English chars)`);
        
        // Split by double newlines (paragraphs)
        const paragraphs = cleaned.split(/\n\n+/);
        const filteredParagraphs = [];
        
        for (const para of paragraphs) {
            const paraHebrew = (para.match(/[\u0590-\u05FF]/g) || []).length;
            const paraEnglish = (para.match(/[a-zA-Z]/g) || []).length;
            
            // Keep paragraph if it has Hebrew OR if it's very short (like a single word/emoji)
            if (paraHebrew > 0 || para.trim().length < 20) {
                filteredParagraphs.push(para);
            } else if (paraEnglish > paraHebrew * 2) {
                // This paragraph is mostly English - likely meta-text
                console.log(`üßπ Removed English-only paragraph: "${para.substring(0, 60)}..."`);
            } else {
                // Keep it if unclear
                filteredParagraphs.push(para);
            }
        }
        
        cleaned = filteredParagraphs.join('\n\n');
    }
    
    // 6. Trim extra whitespace
    cleaned = cleaned.replace(/\n{3,}/g, '\n\n'); // Max 2 consecutive newlines
    cleaned = cleaned.trim();
    
    // Log if significant cleaning happened
    if (cleaned.length < originalLength * 0.8) {
        console.log(`üßπ Cleaned thinking patterns: ${originalLength} -> ${cleaned.length} chars (removed ${originalLength - cleaned.length})`);
    }
    
    return cleaned;
}

/**
 * Generate text response using Gemini with conversation history support
 * @param {string} prompt - User input text
 * @param {Array} conversationHistory - Previous messages in conversation
 * @param {Object} options - Additional options (model, useGoogleSearch)
 * @returns {Object} - Response with generated text
 */
async function generateTextResponse(prompt, conversationHistory = [], options = {}) {
    try {
        console.log('üí¨ Gemini text generation');
        
        // Sanitize prompt
        const cleanPrompt = sanitizeText(prompt);
        
        // Check if Google Search should be enabled
        const useGoogleSearch = options.useGoogleSearch === true;
        if (useGoogleSearch) {
            console.log('üîç Google Search enabled for this request');
        }
        
        const model = genAI.getGenerativeModel({ 
            model: options.model || "gemini-2.5-flash" 
        });

        // Build conversation contents for Gemini
        const contents = [];

        // Build system prompt - add Google Search instructions if enabled
        let systemPrompt = `◊ê◊™◊î ◊¢◊ï◊ñ◊® AI ◊ô◊ì◊ô◊ì◊ï◊™◊ô, ◊ê◊ì◊ô◊ë ◊ï◊†◊¢◊ô◊ù. ◊™◊ü ◊™◊©◊ï◊ë◊ï◊™ ◊ò◊ë◊¢◊ô◊ï◊™ ◊ï◊†◊¢◊ô◊û◊ï◊™.

◊ó◊©◊ï◊ë ◊û◊ê◊ï◊ì - ◊õ◊ú◊ú◊ô ◊™◊©◊ï◊ë◊î:
1. ◊™◊©◊ô◊ë ◊ô◊©◊ô◊®◊ï◊™ ◊¢◊ù ◊î◊™◊©◊ï◊ë◊î ◊î◊°◊ï◊§◊ô◊™ ◊ë◊ú◊ë◊ì - ◊ú◊ú◊ê ◊î◊°◊ë◊®◊ô◊ù ◊¢◊ú ◊™◊î◊ú◊ô◊ö ◊î◊ó◊©◊ô◊ë◊î ◊©◊ú◊ö
2. ◊ê◊°◊ï◊® ◊ú◊õ◊™◊ï◊ë: "As an AI, I should:", "My response should:", "Let's break down", "translates to", "refers to", "In the context of", ◊ê◊ï ◊õ◊ú ◊†◊ô◊™◊ï◊ó ◊û◊ò◊ê ◊ê◊ó◊®
3. ◊ê◊°◊ï◊® ◊ú◊î◊°◊ë◊ô◊® ◊ê◊™ ◊î◊û◊ô◊ú◊ô◊ù ◊ê◊ï ◊ú◊™◊®◊í◊ù ◊ê◊ï◊™◊ü - ◊î◊û◊©◊™◊û◊© ◊õ◊ë◊® ◊ô◊ï◊ì◊¢ ◊¢◊ë◊®◊ô◊™
4. ◊ê◊°◊ï◊® ◊ú◊õ◊™◊ï◊ë ◊®◊©◊ô◊û◊ï◊™ ◊©◊ú "what I should do" - ◊§◊©◊ï◊ò ◊™◊¢◊©◊î ◊ê◊™ ◊ñ◊î
5. ◊™◊û◊ô◊ì ◊™◊©◊ô◊ë ◊ë◊ê◊ï◊™◊î ◊©◊§◊î ◊©◊ë◊î ◊î◊û◊©◊™◊û◊© ◊©◊ï◊ê◊ú`;

        // Add Google Search specific instructions if enabled
        if (useGoogleSearch) {
            systemPrompt += `

üîç ◊ó◊©◊ï◊ë ◊ë◊ô◊ï◊™◊® - ◊©◊ô◊û◊ï◊© ◊ë-Google Search (◊ó◊ï◊ë◊î ◊û◊ï◊ó◊ú◊ò◊™!):
6. **◊ê◊™◊î ◊ú◊ê ◊ô◊õ◊ï◊ú ◊ú◊¢◊†◊ï◊™ ◊ú◊ú◊ê Google Search!** - ◊õ◊ú ◊ë◊ß◊©◊™ ◊ß◊ô◊©◊ï◊® ◊ì◊ï◊®◊©◊™ ◊ó◊ô◊§◊ï◊© ◊ê◊û◊ô◊™◊ô
7. **◊ê◊°◊ï◊® ◊ë◊î◊ó◊ú◊ò** ◊ú◊©◊ú◊ï◊ó ◊ß◊ô◊©◊ï◊® ◊©◊ú◊ê ◊û◊¶◊ê◊™ ◊ë-Google Search **◊ë◊®◊í◊¢ ◊ñ◊î**
8. **◊ê◊°◊ï◊® ◊ú◊ó◊ú◊ï◊ò◊ô◊ü** ◊ú◊î◊©◊™◊û◊© ◊ë◊ô◊ì◊¢ ◊û◊î◊ê◊ô◊û◊ï◊ü ◊©◊ú◊ö - ◊®◊ß ◊û◊î ◊©◊û◊¶◊ê◊™ ◊ë-Google Search **◊¢◊õ◊©◊ô◊ï**
9. ◊ê◊ù Google Search ◊ú◊ê ◊î◊ó◊ñ◊ô◊® ◊™◊ï◊¶◊ê◊ï◊™: "◊ú◊ê ◊û◊¶◊ê◊™◊ô ◊ß◊ô◊©◊ï◊® ◊ñ◊û◊ô◊ü ◊õ◊®◊í◊¢" - **◊ê◊°◊ï◊® ◊ú◊î◊û◊¶◊ô◊ê!**
10. **◊ó◊©◊ï◊ë ◊ë◊ô◊ï◊™◊®**: ◊î◊ñ◊ô◊õ◊®◊ï◊ü ◊©◊ú◊ö ◊û-2023 - ◊î◊ß◊ô◊©◊ï◊®◊ô◊ù ◊ô◊©◊†◊ô◊ù! ◊ó◊§◊© ◊û◊ó◊ì◊© **◊™◊û◊ô◊ì**!

‚ö†Ô∏è **◊ì◊ï◊í◊û◊î ◊ú◊û◊î ◊©◊ê◊°◊ï◊® ◊ú◊¢◊©◊ï◊™:**
◊û◊©◊™◊û◊©: "◊©◊ú◊ó ◊ß◊ô◊©◊ï◊® ◊ú-Love Story ◊©◊ú ◊ò◊ô◊ô◊ú◊ï◊®"
◊ê◊™◊î: "◊î◊†◊î: https://youtube.com/watch?v=eK6F13e0n5Y" ‚Üê **◊ê◊°◊ï◊®!** ◊ñ◊î ◊û◊î◊ñ◊ô◊õ◊®◊ï◊ü!
‚úÖ ◊†◊õ◊ï◊ü: ◊™◊ó◊§◊© ◊ë-Google Search ‚Üí ◊™◊û◊¶◊ê ◊ß◊ô◊©◊ï◊® ◊¢◊ì◊õ◊†◊ô ‚Üí ◊™◊©◊ú◊ó

‚ùå **◊ì◊ï◊í◊û◊ê◊ï◊™ ◊ú◊ß◊ô◊©◊ï◊®◊ô◊ù ◊ê◊°◊ï◊®◊ô◊ù (◊û◊ï◊û◊¶◊ê◊ô◊ù):**
- https://youtube.com/watch?v=xxx123 ‚Üê ◊†◊®◊ê◊î ◊û◊ï◊û◊¶◊ê
- https://youtube.com/watch?v=abc123 ‚Üê ◊†◊®◊ê◊î ◊û◊ï◊û◊¶◊ê
- https://youtube.com/watch?v=example ‚Üê ◊õ◊ú◊ú◊ô ◊û◊ì◊ô
- ◊õ◊ú ◊ß◊ô◊©◊ï◊® ◊©◊ú◊ê ◊î◊ï◊§◊ô◊¢ ◊ë◊§◊ï◊¢◊ú ◊ë-Google Search ◊©◊ú◊ö ◊ë◊®◊í◊¢ ◊ñ◊î

‚úÖ **◊î◊™◊î◊ú◊ô◊ö ◊î◊†◊õ◊ï◊ü - ◊ó◊ï◊ë◊î ◊ú◊¢◊ß◊ï◊ë:**
◊û◊©◊™◊û◊©: "◊©◊ú◊ó ◊ú◊ô◊†◊ß ◊ú◊©◊ô◊® Love Story ◊©◊ú ◊ò◊ô◊ô◊ú◊ï◊® ◊°◊ï◊ï◊ô◊§◊ò"
1. **◊ó◊§◊© ◊û◊û◊© ◊ë-Google Search** (◊ú◊ê ◊û◊î◊ñ◊ô◊õ◊®◊ï◊ü ◊©◊ú◊ö!)
2. ◊ê◊ù ◊û◊¶◊ê◊™ ◊™◊ï◊¶◊ê◊î: ◊©◊ú◊ó ◊ê◊™ ◊î◊ß◊ô◊©◊ï◊® ◊î◊û◊ì◊ï◊ô◊ß ◊û◊î◊ó◊ô◊§◊ï◊©
3. ◊ê◊ù ◊ú◊ê ◊û◊¶◊ê◊™: "◊ú◊ê ◊î◊¶◊ú◊ó◊™◊ô ◊ú◊û◊¶◊ï◊ê ◊ß◊ô◊©◊ï◊®, ◊†◊°◊î ◊ú◊ó◊§◊© ◊ë◊ô◊ï◊ò◊ô◊ï◊ë" - **◊ê◊ú ◊™◊û◊¶◊ô◊ê ◊ß◊ô◊©◊ï◊®!**

‚ùå **◊ê◊°◊ï◊® ◊ú◊ó◊ú◊ï◊ò◊ô◊ü ◊ú◊¢◊©◊ï◊™:**
◊û◊©◊™◊û◊©: "◊©◊ú◊ó ◊ú◊ô◊†◊ß ◊ú◊©◊ô◊® X"
◊ê◊™◊î: "◊î◊†◊î ◊î◊ß◊ô◊©◊ï◊®: https://youtube.com/watch?v=eK6F13e0n5Y" ‚Üê ◊ê◊°◊ï◊®! ◊ê◊ù ◊ú◊ê ◊ó◊ô◊§◊©◊™ ◊¢◊õ◊©◊ô◊ï ◊ë-Google Search`;
        }

        systemPrompt += `

◊ì◊ï◊í◊û◊î ◊ú◊™◊©◊ï◊ë◊î ◊†◊õ◊ï◊†◊î:
◊û◊©◊™◊û◊©: "◊ë◊ó◊® ◊ë◊ô◊ü A ◊ú-B"
◊ê◊™◊î: "◊ê◊†◊ô ◊û◊¢◊ì◊ô◊£ ◊ê◊™ A ◊õ◊ô..."  ‚Üê ◊ô◊©◊ô◊®, ◊ú◊ú◊ê ◊†◊ô◊™◊ï◊ó

◊ì◊ï◊í◊û◊î ◊ú◊™◊©◊ï◊ë◊î ◊©◊í◊ï◊ô◊î:
◊û◊©◊™◊û◊©: "◊ë◊ó◊® ◊ë◊ô◊ü A ◊ú-B"
◊ê◊™◊î: "A translates to... B refers to... As an AI, I should: 1. Acknowledge... 2. Avoid..."  ‚Üê ◊ê◊°◊ï◊®!`;

        // Add system prompt as first user message (Gemini format)
        contents.push({
            role: 'user',
            parts: [{ text: systemPrompt }]
        });
        
        // Add system prompt response
        let modelResponse = '◊î◊ë◊†◊™◊ô ◊ú◊ó◊ú◊ï◊ò◊ô◊ü. ◊ê◊©◊ô◊ë ◊ô◊©◊ô◊®◊ï◊™ ◊ú◊ú◊ê ◊™◊î◊ú◊ô◊ö ◊ó◊©◊ô◊ë◊î, ◊†◊ô◊™◊ï◊ó, ◊™◊®◊í◊ï◊û◊ô◊ù ◊ê◊ï ◊®◊©◊ô◊û◊ï◊™ ◊©◊ú "◊û◊î ◊ê◊†◊ô ◊¶◊®◊ô◊ö ◊ú◊¢◊©◊ï◊™". ◊®◊ß ◊î◊™◊©◊ï◊ë◊î ◊î◊°◊ï◊§◊ô◊™, ◊ë◊ê◊ï◊™◊î ◊©◊§◊î ◊©◊ë◊î ◊†◊©◊ê◊ú◊™ ◊î◊©◊ê◊ú◊î.';
        
        if (useGoogleSearch) {
            modelResponse += ' ◊õ◊ê◊©◊® ◊†◊ì◊®◊© ◊ß◊ô◊©◊ï◊® - ◊ê◊ó◊§◊© **◊®◊ß** ◊ë-Google Search **◊¢◊õ◊©◊ô◊ï** (◊ú◊ê ◊û◊î◊ñ◊ô◊õ◊®◊ï◊ü). ◊ê◊ù Google Search ◊ú◊ê ◊û◊ó◊ñ◊ô◊® ◊™◊ï◊¶◊ê◊ï◊™ - ◊ê◊ï◊ì◊ô◊¢ "◊ú◊ê ◊û◊¶◊ê◊™◊ô". ◊ê◊°◊ï◊® ◊ú◊î◊©◊™◊û◊© ◊ë◊ß◊ô◊©◊ï◊®◊ô◊ù ◊û◊î◊ê◊ô◊û◊ï◊ü ◊©◊ú◊ô ◊û-2023.';
        }
        
        contents.push({
            role: 'model',
            parts: [{ text: modelResponse }]
        });

        // Normalize conversation history to an array to avoid undefined lengths
        if (!Array.isArray(conversationHistory)) {
            conversationHistory = [];
        }

        // Add conversation history if exists
        if (conversationHistory.length > 0) {
            console.log(`üß† Using conversation history: ${conversationHistory.length} previous messages`);
            
            for (const msg of conversationHistory) {
                // Convert OpenAI format to Gemini format
                const role = msg.role === 'assistant' ? 'model' : 'user';
                contents.push({
                    role: role,
                    parts: [{ text: msg.content }]
                });
            }
        }

        // Add current user message
        contents.push({
            role: 'user',
            parts: [{ text: cleanPrompt }]
        });

        console.log(`üîÆ Gemini processing (${Array.isArray(conversationHistory) ? conversationHistory.length : 0} context messages)`);

        // Build generation config
        const generateConfig = {
            contents
        };
        
        // Add Google Search tool if requested
        // Note: Using 'googleSearch' (not 'googleSearchRetrieval') for Gemini 2.5 models
        if (useGoogleSearch) {
            generateConfig.tools = [{
                googleSearch: {}
            }];
            // Force Gemini to use the Google Search tool (not optional)
            generateConfig.toolConfig = {
                functionCallingConfig: {
                    mode: 'ANY'  // Force tool usage
                }
            };
            console.log('üîç Adding Google Search tool to Gemini API call (FORCED MODE)');
        }
        
        // Generate response with history (and optionally Google Search)
        const result = await model.generateContent(generateConfig);
        const response = result.response;
        
        // Log if Google Search was actually used
        if (useGoogleSearch) {
            const groundingMetadata = response.candidates?.[0]?.groundingMetadata;
            if (groundingMetadata) {
                console.log('‚úÖ Google Search was USED by Gemini:', JSON.stringify(groundingMetadata, null, 2));
            } else {
                console.warn('‚ö†Ô∏è Google Search was enabled but NOT used by Gemini (it may have answered from memory)');
            }
        }
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini: No candidates returned');
            const errorMsg = getGeminiErrorMessage(null, response.promptFeedback);
            return { error: errorMsg };
        }
        
        let text = response.text();
        
        if (!text || text.trim().length === 0) {
            console.log('‚ùå Gemini: Empty text response');
            return { error: 'Empty response from Gemini' };
        }
        
        // Clean up verbose thinking patterns that sometimes appear
        text = text.trim();
        
        // Remove meta-linguistic reasoning and English thinking patterns
        // Sometimes Gemini ignores the system prompt and adds reasoning anyway
        text = cleanThinkingPatterns(text);
        
        // Fix URLs with parentheses - Gemini sometimes wraps URLs in parentheses
        // or uses Markdown link syntax [text](url)
        // Example: "◊î◊†◊î ◊î◊©◊ô◊® (https://youtube.com/...)" becomes broken in WhatsApp
        
        // 1. Convert Markdown links [text](url) to plain text with URL
        text = text.replace(/\[([^\]]+)\]\((https?:\/\/[^\)]+)\)/g, '$1: $2');
        
        // 2. Add space between URL and closing parenthesis to prevent WhatsApp from including ) in URL
        text = text.replace(/(\bhttps?:\/\/[^\s)]+)\)/g, '$1 )');
        
        // 3. Add space between opening parenthesis and URL
        text = text.replace(/\((\bhttps?:\/\/[^\s)]+)/g, '( $1');
        
        // 4. Detect suspicious YouTube URLs (likely hallucinated)
        // YouTube video IDs are exactly 11 characters (alphanumeric, -, _)
        // If we find a YouTube URL with a suspicious ID, log a warning
        if (useGoogleSearch) {
            const youtubeUrls = text.match(/https?:\/\/(www\.)?(youtube\.com\/watch\?v=|youtu\.be\/)([^\s&)]+)/g);
            if (youtubeUrls) {
                youtubeUrls.forEach(url => {
                    const videoIdMatch = url.match(/(?:watch\?v=|youtu\.be\/)([^\s&)]+)/);
                    if (videoIdMatch && videoIdMatch[1]) {
                        const videoId = videoIdMatch[1];
                        // YouTube video IDs should be 11 characters
                        if (videoId.length < 10 || videoId.length > 12) {
                            console.warn(`‚ö†Ô∏è Suspicious YouTube URL detected (ID length: ${videoId.length}): ${url}`);
                            console.warn(`   This URL might be hallucinated by Gemini!`);
                        }
                        // Check for obvious hallucination patterns (e.g., "abc123", "example", "xxx")
                        if (/^(abc|test|example|xxx|demo|sample)/i.test(videoId)) {
                            console.warn(`‚ö†Ô∏è Likely hallucinated YouTube URL detected: ${url}`);
                            console.warn(`   Video ID "${videoId}" looks fake!`);
                        }
                    }
                });
            }
        }
        
        // Detect various thinking/reasoning patterns that should be removed
        const hasThinkingPattern = 
            text.includes('SPECIAL INSTRUCTION:') || 
            text.includes('Think step-by-step') ||
            text.startsWith('THOUGHT') ||
            /^THOUGHT\s/m.test(text) || // THOUGHT at start of a line
            text.includes('*Drafting the response:*') ||
            text.includes('This response:') ||
            text.includes('As an AI, I should:') ||
            text.includes('My response should:') ||
            text.includes('Let\'s break down') ||
            text.includes('The user is essentially asking') ||
            (text.includes('translates to') && text.includes('In the context of')) ||
            text.startsWith('If I were to') || // Chain of thought reasoning
            (text.includes('However, as an AI') || text.includes('However, from a technical perspective')) ||
            text.includes('Let\'s consider the implications') ||
            text.includes('Given the instructions to be');
        
        if (hasThinkingPattern) {
            console.log('üßπ Detected verbose thinking pattern, extracting final answer...');
            
            // Split by common delimiters that separate thinking from final answer
            let finalAnswer = '';
            
            // Try to find the actual answer after thinking patterns
            // Often the final answer comes after patterns like:
            // - "This response:" followed by bullet points, then the actual text
            // - Just after markdown formatting like "*text*" or numbered lists
            
            const lines = text.split('\n');
            let inThinkingSection = false;
            let answerLines = [];
            let foundAnswerStart = false;
            
            for (let i = 0; i < lines.length; i++) {
                const line = lines[i].trim();
                
                // Skip empty lines at the start
                if (!foundAnswerStart && !line) continue;
                
                // Detect thinking section markers
                if (line.startsWith('THOUGHT') || 
                    line.includes('SPECIAL INSTRUCTION') ||
                    line.includes('Think step-by-step') ||
                    line.includes('I need to:') ||
                    line.includes('*Drafting the response:*') ||
                    line.includes('This response:') ||
                    line.includes('As an AI, I should:') ||
                    line.includes('My response should:') ||
                    line.includes('The user is essentially asking') ||
                    line.includes('translates to') ||
                    line.includes('Let\'s break down') ||
                    line.includes('In the context of') ||
                    line.startsWith('If I were to') ||
                    line.includes('However, as an AI') ||
                    line.includes('However, from a technical perspective') ||
                    line.includes('Let\'s consider the implications') ||
                    line.includes('Given the instructions')) {
                    inThinkingSection = true;
                    continue;
                }
                
                // Skip lines that look like internal reasoning
                if (inThinkingSection && (
                    line.startsWith('*') && line.endsWith('*') || // Markdown emphasis for meta-comments
                    line.match(/^\d+\.\s+\*.*\*:/) || // Numbered list with emphasized headers
                    line.match(/^\d+\.\s+/) || // Any numbered list during thinking
                    line.startsWith('-   ') || // Bullet points with extra spacing (markdown)
                    line.includes('The user is') ||
                    line.includes('My current instruction') ||
                    line.includes('Let\'s consider') ||
                    line.includes('I should') ||
                    line.includes('I cannot') ||
                    line.includes('I must') ||
                    line.includes('refers to') ||
                    line.includes('meaning is'))) {
                    continue;
                }
                
                // If we find a line that looks like actual content (Hebrew/English text, reasonable length)
                // and doesn't have meta-markers, consider it the start of the answer
                // Additional check: line should start with actual content, not analysis/meta-discussion
                const looksLikeMetaDiscussion = 
                    line.includes('translates to') ||
                    line.includes('refers to') ||
                    line.includes('means') ||
                    line.includes('can mean') ||
                    line.includes('evokes') ||
                    line.includes('Together, it') ||
                    line.includes('In the context') ||
                    line.includes('Given') ||
                    line.startsWith('The contrast is') ||
                    line.match(/^-\s+["'].*["']:/) || // Definition list format
                    line.match(/^".*".*:$/); // Quoted term with colon (definition)
                
                if (line.length > 0 && 
                    !line.startsWith('*') && 
                    !line.match(/^\d+\.\s+\*/) &&
                    !line.match(/^\d+\.\s+/) && // Skip numbered lists
                    !line.startsWith('-   ') && // Skip markdown bullets
                    !looksLikeMetaDiscussion &&
                    !line.includes('THOUGHT')) {
                    foundAnswerStart = true;
                    inThinkingSection = false;
                    answerLines.push(lines[i]); // Keep original formatting
                } else if (foundAnswerStart && !inThinkingSection) {
                    answerLines.push(lines[i]); // Keep building the answer
                }
            }
            
            if (answerLines.length > 0) {
                finalAnswer = answerLines.join('\n').trim();
                
                // Additional cleanup: remove any remaining markdown meta-comments at the start
                finalAnswer = finalAnswer.replace(/^\*.*?\*\s*\n/gm, '');
                
                // If the answer is still wrapped in quotes (from drafting), extract it
                // e.g., "◊ñ◊ï ◊©◊ê◊ú◊î ◊û◊¢◊†◊ô◊ô◊†◊™..." -> ◊ñ◊ï ◊©◊ê◊ú◊î ◊û◊¢◊†◊ô◊ô◊†◊™...
                const quotedMatch = finalAnswer.match(/^"(.+)"$/s);
                if (quotedMatch) {
                    finalAnswer = quotedMatch[1].trim();
                    console.log('üßπ Removed surrounding quotes from answer');
                }
                
                if (finalAnswer && finalAnswer.length > 10) {
                    text = finalAnswer;
                    console.log(`üéØ Extracted final answer (${finalAnswer.length} chars)`);
                    console.log(`   Preview: ${finalAnswer.substring(0, 100)}...`);
                }
            } else {
                // Fallback: If mostly English text with Hebrew ending, extract Hebrew part
                const allLines = text.split('\n');
                const hebrewLines = [];
                let foundHebrewSection = false;
                
                // Hebrew character detection
                const hasHebrew = (str) => /[\u0590-\u05FF]/.test(str);
                
                // Scan from bottom up for Hebrew content
                for (let i = allLines.length - 1; i >= 0; i--) {
                    const line = allLines[i].trim();
                    if (!line) continue;
                    
                    if (hasHebrew(line)) {
                        hebrewLines.unshift(allLines[i]); // Keep original formatting
                        foundHebrewSection = true;
                    } else if (foundHebrewSection) {
                        // Stop when we hit English after finding Hebrew
                        break;
                    }
                }
                
                if (hebrewLines.length > 0 && hebrewLines.join('').length > 20) {
                    const hebrewAnswer = hebrewLines.join('\n').trim();
                    text = hebrewAnswer;
                    console.log(`üéØ Extracted Hebrew final answer from mixed response (${hebrewAnswer.length} chars)`);
                    console.log(`   Preview: ${hebrewAnswer.substring(0, 100)}...`);
                } else {
                    // Fallback: Try to find the last substantial paragraph that looks like a real answer
                    // Split by double newlines to get paragraphs
                    const paragraphs = text.split(/\n\n+/).filter(p => p.trim().length > 0);
                    
                    // Look for the last paragraph that doesn't contain meta-discussion markers
                    for (let i = paragraphs.length - 1; i >= 0; i--) {
                        const para = paragraphs[i].trim();
                        
                        // Check if this paragraph looks like a real answer (not meta-discussion)
                        const isMetaParagraph = 
                            para.includes('As an AI') ||
                            para.includes('translates to') ||
                            para.includes('refers to') ||
                            para.includes('Let\'s break down') ||
                            para.includes('My response should') ||
                            para.match(/^\d+\.\s+\*/) || // Numbered list with emphasis
                            para.match(/^-\s+["'].*["']:/) || // Definition list
                            para.startsWith('THOUGHT');
                        
                        if (!isMetaParagraph && para.length > 20) {
                            finalAnswer = para;
                            console.log('üéØ Found final answer paragraph (fallback method)');
                            console.log(`   Preview: ${finalAnswer.substring(0, 100)}...`);
                            text = finalAnswer;
                            break;
                        }
                    }
                }
            }
        }
        
        console.log(`‚úÖ Gemini text generated: ${text.substring(0, 100)}...`);
        
        return {
            text: text,
            originalPrompt: cleanPrompt,
            metadata: {
                service: 'Gemini',
                model: options.model || "gemini-2.5-flash",
                type: 'text_generation',
                characterCount: text.length,
                created_at: new Date().toISOString()
            }
        };
        
    } catch (err) {
        console.error('‚ùå Gemini text generation error:', err);
        
        // Emergency response
        return { 
            text: '◊û◊¶◊ò◊¢◊®, ◊ß◊®◊™◊î ◊©◊í◊ô◊ê◊î ◊ë◊¢◊ô◊ë◊ï◊ì ◊î◊ë◊ß◊©◊î ◊©◊ú◊ö ◊¢◊ù Gemini. ◊†◊°◊î ◊©◊ï◊ë ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊®.',
            error: err.message || 'Text generation failed' 
        };
    }
}

/**
 * Generate chat summary using Gemini
 */
async function generateChatSummary(messages) {
    try {
        console.log(`üìù Generating chat summary for ${messages.length} messages`);
        
        // Format messages for Gemini
        let formattedMessages = '';
        messages.forEach((msg, index) => {
            const timestamp = new Date(msg.timestamp * 1000).toLocaleString('he-IL');
            
            // Use WhatsApp display name only (chatName), fallback to phone number
            let sender = '◊û◊©◊™◊û◊©';
            if (msg.chatName) {
                sender = msg.chatName;
            } else if (msg.sender) {
                // Extract phone number from sender ID (e.g., "972543995202@c.us" -> "972543995202")
                const phoneMatch = msg.sender.match(/^(\d+)@/);
                sender = phoneMatch ? phoneMatch[1] : msg.sender;
            }
            
            const messageText = msg.textMessage || msg.caption || '[◊û◊ì◊ô◊î]';
            
            formattedMessages += `${index + 1}. ${timestamp} - ${sender}: ${messageText}\n`;
        });
        
        const summaryPrompt = `◊ê◊†◊ê ◊¶◊ï◊® ◊°◊ô◊õ◊ï◊ù ◊ß◊¶◊® ◊ï◊ë◊®◊ï◊® ◊©◊ú ◊î◊©◊ô◊ó◊î ◊î◊ë◊ê◊î. ◊î◊™◊û◊ß◊ì ◊ë◊†◊ï◊©◊ê◊ô◊ù ◊î◊¢◊ô◊ß◊®◊ô◊ô◊ù, ◊î◊ó◊ú◊ò◊ï◊™ ◊©◊î◊™◊ß◊ë◊ú◊ï, ◊ï◊†◊ß◊ï◊ì◊ï◊™ ◊ó◊©◊ï◊ë◊ï◊™.

◊ó◊©◊ï◊ë: ◊î◊°◊ô◊õ◊ï◊ù ◊ó◊ô◊ô◊ë ◊ú◊î◊ô◊ï◊™ ◊ë◊¢◊ë◊®◊ô◊™.

◊î◊ï◊ì◊¢◊ï◊™ ◊î◊©◊ô◊ó◊î:
${formattedMessages}

◊°◊ô◊õ◊ï◊ù ◊î◊©◊ô◊ó◊î:`;

        const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
        const result = await model.generateContent(summaryPrompt);
        
        if (!result.response) {
            throw new Error('No response from Gemini');
        }
        
        const summaryText = result.response.text();
        console.log(`‚úÖ Chat summary generated: ${summaryText.length} characters`);
        
        return {
            success: true,
            text: summaryText
        };
        
    } catch (err) {
        console.error('‚ùå Chat summary generation error:', err);
        return {
            success: false,
            error: err.message || 'Chat summary generation failed'
        };
    }
}

/**
 * Parse music generation request to detect if video is requested
 * @param {string} prompt - User's music request
 * @returns {Object} - { wantsVideo: boolean, cleanPrompt: string }
 */
async function parseMusicRequest(prompt) {
    try {
        // First, try simple regex detection for common patterns (fast and reliable)
        // Hebrew patterns: ◊õ◊ï◊ú◊ú ◊ï◊ô◊ì◊ê◊ï, ◊¢◊ù ◊ï◊ô◊ì◊ê◊ï, ◊í◊ù ◊ï◊ô◊ì◊ê◊ï, ◊õ◊ï◊ú◊ú ◊ß◊ú◊ô◊§, ◊¢◊ù ◊ß◊ú◊ô◊§, ◊ï◊ô◊ì◊ê◊ï, ◊ß◊ú◊ô◊§
        // English patterns: with video, and video, plus video, with clip, and clip, video, clip
        const videoPatterns = /\b(with|and|plus|including|include)\s+(video|clip)\b|◊õ◊ï◊ú◊ú\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)|◊¢◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)|◊í◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)|◊ï◊¢◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)|\bvideo\s*clip\b|\bmusic\s*video\b/i;
        
        const regexMatch = videoPatterns.test(prompt);
        
        if (regexMatch) {
            console.log('üé¨ Video requested with music');
            // Clean the prompt by removing video/clip mentions
            const cleanPrompt = prompt
                .replace(/\s*(with|and|plus|including|include)\s+(video|clip)\s*/gi, ' ')
                .replace(/\s*◊õ◊ï◊ú◊ú\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)\s*/g, ' ')
                .replace(/\s*◊¢◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)\s*/g, ' ')
                .replace(/\s*◊í◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)\s*/g, ' ')
                .replace(/\s*◊ï◊¢◊ù\s+(◊ï◊ô◊ì◊ê◊ï|◊ß◊ú◊ô◊§)\s*/g, ' ')
                .replace(/\s*video\s*clip\s*/gi, ' ')
                .replace(/\s*music\s*video\s*/gi, ' ')
                .trim()
                .replace(/\s+/g, ' '); // normalize spaces
            
            return {
                wantsVideo: true,
                cleanPrompt: cleanPrompt || prompt
            };
        }
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        const analysisPrompt = `Analyze this music generation request and determine if the user wants a video along with the song.

User request: "${prompt}"

Return ONLY a JSON object (no markdown, no extra text) with this exact structure:
{
  "wantsVideo": true/false,
  "cleanPrompt": "the music description without video request"
}

Rules:
1. If user explicitly requests video or clip (e.g., "with video", "◊õ◊ï◊ú◊ú ◊ï◊ô◊ì◊ê◊ï", "◊¢◊ù ◊ï◊ô◊ì◊ê◊ï", "◊í◊ù ◊ï◊ô◊ì◊ê◊ï", "plus video", "and video", "◊ï◊¢◊ù ◊ï◊ô◊ì◊ê◊ï", "◊ß◊ú◊ô◊§", "◊õ◊ï◊ú◊ú ◊ß◊ú◊ô◊§", "◊¢◊ù ◊ß◊ú◊ô◊§", "clip", "with clip", "video clip", "music video"), set wantsVideo=true
2. Extract the actual music description (without the video/clip instruction)
3. Keep the cleanPrompt focused on music style, theme, mood, lyrics topic
4. If no video/clip is mentioned, set wantsVideo=false and keep original prompt
5. IMPORTANT: The presence of other words (like "Suno", "◊ë◊¢◊ñ◊®◊™", "◊ë◊ê◊û◊¶◊¢◊ï◊™") should NOT affect video detection - focus ONLY on video/clip keywords

Examples:
Input: "◊¶◊ï◊® ◊©◊ô◊® ◊ë◊°◊í◊†◊ï◊ü ◊®◊ï◊ß ◊¢◊ú ◊ê◊î◊ë◊î ◊õ◊ï◊ú◊ú ◊ï◊ô◊ì◊ê◊ï"
Output: {"wantsVideo":true,"cleanPrompt":"◊¶◊ï◊® ◊©◊ô◊® ◊ë◊°◊í◊†◊ï◊ü ◊®◊ï◊ß ◊¢◊ú ◊ê◊î◊ë◊î"}

Input: "◊¶◊ï◊® ◊©◊ô◊® ◊¢◊ú ◊î◊õ◊ú◊ë ◊ì◊ï◊ë◊ô ◊ë◊¢◊ñ◊®◊™ Suno, ◊õ◊ï◊ú◊ú ◊ï◊ô◊ì◊ê◊ï"
Output: {"wantsVideo":true,"cleanPrompt":"◊¶◊ï◊® ◊©◊ô◊® ◊¢◊ú ◊î◊õ◊ú◊ë ◊ì◊ï◊ë◊ô ◊ë◊¢◊ñ◊®◊™ Suno"}

Input: "create a pop song about summer with video"
Output: {"wantsVideo":true,"cleanPrompt":"create a pop song about summer"}

Input: "◊©◊ô◊® ◊¢◊¶◊ï◊ë ◊¢◊ú ◊§◊®◊ô◊ì◊î ◊¢◊ù ◊ß◊ú◊ô◊§"
Output: {"wantsVideo":true,"cleanPrompt":"◊©◊ô◊® ◊¢◊¶◊ï◊ë ◊¢◊ú ◊§◊®◊ô◊ì◊î"}

Input: "◊©◊ô◊® ◊®◊ï◊û◊†◊ò◊ô ◊õ◊ï◊ú◊ú ◊ß◊ú◊ô◊§"
Output: {"wantsVideo":true,"cleanPrompt":"◊©◊ô◊® ◊®◊ï◊û◊†◊ò◊ô"}

Input: "make a rock song with clip"
Output: {"wantsVideo":true,"cleanPrompt":"make a rock song"}

Input: "make a song with Suno and video"
Output: {"wantsVideo":true,"cleanPrompt":"make a song with Suno"}

Input: "◊¶◊ï◊® ◊©◊ô◊® ◊í'◊ê◊ñ"
Output: {"wantsVideo":false,"cleanPrompt":"◊¶◊ï◊® ◊©◊ô◊® ◊í'◊ê◊ñ"}

Input: "make a happy song"
Output: {"wantsVideo":false,"cleanPrompt":"make a happy song"}`;

        const result = await model.generateContent(analysisPrompt);
        const response = result.response;
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini music parsing: No candidates returned');
            return { wantsVideo: false, cleanPrompt: prompt };
        }
        
        let rawText = response.text().trim();
        
        // Remove markdown code fences if present
        rawText = rawText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
        
        const parsed = JSON.parse(rawText);
        
        if (parsed.wantsVideo) {
            console.log('üé¨ Video requested with music (LLM detected)');
        }
        return parsed;
        
    } catch (err) {
        console.error('‚ùå Error parsing music request:', err);
        // Fallback: no video
        return { wantsVideo: false, cleanPrompt: prompt };
    }
}

/**
 * Parse text-to-speech request to detect if translation is needed
 * @param {string} prompt - User's TTS request
 * @returns {Object} - { needsTranslation: boolean, text: string, targetLanguage?: string, languageCode?: string }
 */
async function parseTextToSpeechRequest(prompt) {
    try {
        console.log('üîç Parsing TTS request for translation needs');
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        const analysisPrompt = `Analyze this text-to-speech request and determine if the user wants the output in a specific language.

User request: "${prompt}"

Return ONLY a JSON object (no markdown, no extra text) with this exact structure:
{
  "needsTranslation": true/false,
  "text": "the text to speak",
  "targetLanguage": "language name in English (e.g., Japanese, French, Spanish)",
  "languageCode": "ISO 639-1 code (e.g., ja, fr, es, he, en, ar)"
}

Rules:
1. If user explicitly requests a language (e.g., "say X in Japanese", "◊ê◊û◊ï◊® X ◊ë◊ô◊§◊†◊ô◊™", "read X in French"), set needsTranslation=true
2. Extract the actual text to speak (without the language instruction)
3. Map the target language to its ISO code
4. If no specific language is requested, set needsTranslation=false, use the original text, and omit targetLanguage/languageCode

Examples:
Input: "◊ê◊û◊ï◊® ◊î◊ô◊ô ◊û◊î ◊†◊©◊û◊¢ ◊ë◊ô◊§◊†◊ô◊™"
Output: {"needsTranslation":true,"text":"◊î◊ô◊ô ◊û◊î ◊†◊©◊û◊¢","targetLanguage":"Japanese","languageCode":"ja"}

Input: "say hello world in French"
Output: {"needsTranslation":true,"text":"hello world","targetLanguage":"French","languageCode":"fr"}

Input: "◊ß◊®◊ê ◊ê◊™ ◊î◊ò◊ß◊°◊ò ◊î◊ñ◊î ◊ë◊¢◊®◊ë◊ô◊™: ◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù"
Output: {"needsTranslation":true,"text":"◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù","targetLanguage":"Arabic","languageCode":"ar"}

Input: "◊ê◊û◊ï◊® ◊©◊ú◊ï◊ù"
Output: {"needsTranslation":false,"text":"◊ê◊û◊ï◊® ◊©◊ú◊ï◊ù"}

Input: "read this text"
Output: {"needsTranslation":false,"text":"read this text"}`;

        const result = await model.generateContent(analysisPrompt);
        const response = result.response;
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini TTS parsing: No candidates returned');
            return { needsTranslation: false, text: prompt };
        }
        
        let rawText = response.text().trim();
        
        // Remove markdown code fences if present
        rawText = rawText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
        
        const parsed = JSON.parse(rawText);
        
        console.log('‚úÖ TTS request parsed:', parsed);
        return parsed;
        
    } catch (err) {
        console.error('‚ùå Error parsing TTS request:', err);
        // Fallback: no translation
        return { needsTranslation: false, text: prompt };
    }
}

/**
 * Translate text to target language using Gemini
 * @param {string} text - Text to translate
 * @param {string} targetLanguage - Target language name
 * @returns {Object} - { success: boolean, translatedText?: string, error?: string }
 */
async function translateText(text, targetLanguage) {
    try {
        console.log(`üåê Translating "${text}" to ${targetLanguage}`);
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        const translationPrompt = `Translate the following text to ${targetLanguage}. Return ONLY the translated text, nothing else.

Text to translate: "${text}"

Important: Return only the translation, no explanations, no quotes, no extra text.`;

        const result = await model.generateContent(translationPrompt);
        const response = result.response;
        
        if (!response.candidates || response.candidates.length === 0) {
            console.log('‚ùå Gemini translation: No candidates returned');
            return { 
                success: false, 
                error: 'Translation failed: No response from Gemini' 
            };
        }
        
        const translatedText = response.text().trim();
        
        console.log(`‚úÖ Translation complete: "${translatedText}"`);
        
        return {
            success: true,
            translatedText: translatedText
        };
        
    } catch (err) {
        console.error('‚ùå Translation error:', err);
        return { 
            success: false, 
            error: err.message || 'Translation failed' 
        };
    }
}

/**
 * Generate a creative poll with optional rhyming options
 * @param {string} topic - Poll topic (e.g., "◊ó◊™◊ï◊ú◊ô◊ù", "◊õ◊ú◊ë◊ô◊ù", "◊§◊ô◊¶◊î")
 * @param {boolean} withRhyme - Whether options should rhyme (default: true)
 * @returns {Object} - Poll data with question and options
 */
async function generateCreativePoll(topic, withRhyme = true) {
    try {
        console.log(`üìä Generating creative poll about: ${topic} ${withRhyme ? '(with rhyme)' : '(without rhyme)'}`);
        
        const cleanTopic = sanitizeText(topic);
        
        // Randomly choose number of options (2-4)
        const crypto = require('crypto');
        const numOptions = crypto.randomInt(2, 5); // 2, 3, or 4
        console.log(`üé≤ Randomly selected ${numOptions} poll options`);
        
        // Create prompt based on rhyming preference
        let pollPrompt;
        
        if (withRhyme) {
            pollPrompt = `◊ê◊™◊î ◊ô◊ï◊¶◊® ◊°◊ß◊®◊ô◊ù ◊ô◊¶◊ô◊®◊™◊ô◊ô◊ù ◊ï◊û◊©◊¢◊©◊¢◊ô◊ù ◊ë◊¢◊ë◊®◊ô◊™ ◊¢◊ù ◊ó◊®◊ô◊ñ◊î ◊û◊ï◊©◊ú◊û◊™.

◊†◊ï◊©◊ê ◊î◊°◊ß◊®: ${cleanTopic}

◊¶◊ï◊® ◊°◊ß◊® ◊¢◊ù:
1. ◊©◊ê◊ú◊î ◊û◊¢◊†◊ô◊ô◊†◊™ ◊ï◊ô◊¶◊ô◊®◊™◊ô◊™ (◊ô◊õ◊ï◊ú◊î ◊ú◊î◊ô◊ï◊™ "◊û◊î ◊î◊ô◊ô◊™ ◊û◊¢◊ì◊ô◊§/◊î?" ◊ê◊ï ◊õ◊ú ◊©◊ê◊ú◊î ◊ê◊ó◊®◊™)
2. ◊ë◊ì◊ô◊ï◊ß ${numOptions} ◊™◊©◊ï◊ë◊ï◊™ ◊ê◊§◊©◊®◊ô◊ï◊™
3. ‚≠ê ◊ó◊©◊ï◊ë ◊ë◊ô◊ï◊™◊®: ◊õ◊ú ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊ó◊®◊ï◊ñ ◊ñ◊ï ◊¢◊ù ◊ñ◊ï ◊ë◊ó◊®◊ô◊ñ◊î ◊û◊ï◊©◊ú◊û◊™! ‚≠ê
4. ◊î◊ó◊®◊ô◊ñ◊î ◊ó◊ô◊ô◊ë◊™ ◊ú◊î◊ô◊ï◊™ ◊ë◊°◊ï◊£ ◊õ◊ú ◊™◊©◊ï◊ë◊î (◊î◊û◊ô◊ú◊î ◊î◊ê◊ó◊®◊ï◊†◊î)
5. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊ß◊¶◊®◊ï◊™ (◊¢◊ì 100 ◊™◊ï◊ï◊ô◊ù ◊õ◊ú ◊ê◊ó◊™)
6. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊ß◊©◊ï◊®◊ï◊™ ◊ú◊†◊ï◊©◊ê
7. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊û◊©◊¢◊©◊¢◊ï◊™ ◊ï◊ô◊¶◊ô◊®◊™◊ô◊ï◊™

◊ì◊ï◊í◊û◊ê◊ï◊™ ◊ú◊ó◊®◊ï◊ñ◊ô◊ù ◊û◊ï◊©◊ú◊û◊ô◊ù:
- ◊†◊ï◊©◊ê: ◊ó◊™◊ï◊ú◊ô◊ù (2 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊û◊î ◊î◊ô◊ô◊™ ◊û◊¢◊ì◊ô◊§/◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊ó◊™◊ï◊ú ◊õ◊ï◊¢◊°"
  ◊™◊©◊ï◊ë◊î 2: "◊†◊û◊® ◊ú◊ï◊¢◊°"
  (◊ó◊®◊ï◊ñ: ◊õ◊ï◊¢◊° / ◊ú◊ï◊¢◊°)

- ◊†◊ï◊©◊ê: ◊õ◊ú◊ë◊ô◊ù (3 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ñ◊î ◊õ◊ú◊ë ◊î◊õ◊ô ◊ò◊ï◊ë?"
  ◊™◊©◊ï◊ë◊î 1: "◊í◊ï◊ú◊ì◊ü ◊®◊ò◊®◊ô◊ë◊® ◊†◊î◊ì◊®"
  ◊™◊©◊ï◊ë◊î 2: "◊ë◊ô◊í◊ú ◊ß◊ò◊ü ◊ï◊ô◊§◊î ◊ë◊ó◊ì◊®"
  ◊™◊©◊ï◊ë◊î 3: "◊§◊ï◊ì◊ú ◊ú◊ë◊ü ◊©◊û◊™◊í◊ë◊®"
  (◊ó◊®◊ï◊ñ: ◊†◊î◊ì◊® / ◊ë◊ó◊ì◊® / ◊û◊™◊í◊ë◊®)

- ◊†◊ï◊©◊ê: ◊§◊ô◊¶◊î (4 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ñ◊ï ◊§◊ô◊¶◊î ◊î◊õ◊ô ◊ò◊¢◊ô◊û◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊§◊ô◊¶◊î ◊¢◊ù ◊ñ◊ô◊™◊ô◊ù"
  ◊™◊©◊ï◊ë◊î 2: "◊§◊ú◊ê◊§◊ú ◊¢◊ù ◊ó◊ï◊û◊ï◊° ◊©◊ú◊û◊ô◊ù"
  ◊™◊©◊ï◊ë◊î 3: "◊ë◊ï◊®◊ß◊° ◊ë◊û◊ô◊ú◊ï◊ô ◊¢◊©◊ô◊® ◊ï◊©◊û◊†◊ô◊ù"
  ◊™◊©◊ï◊ë◊î 4: "◊©◊ï◊ï◊ê◊®◊û◊î ◊¢◊ù ◊ë◊¶◊ú ◊ï◊ó◊¶◊ô◊ú◊ô◊ù"
  (◊ó◊®◊ï◊ñ: ◊ñ◊ô◊™◊ô◊ù / ◊©◊ú◊û◊ô◊ù / ◊©◊û◊†◊ô◊ù / ◊ó◊¶◊ô◊ú◊ô◊ù)

- ◊†◊ï◊©◊ê: ◊ß◊§◊î (2 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ö ◊ê◊™◊î ◊©◊ï◊™◊î ◊ß◊§◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊¢◊ù ◊ó◊ú◊ë ◊ï◊°◊ï◊õ◊®"
  ◊™◊©◊ï◊ë◊î 2: "◊©◊ó◊ï◊® ◊ï◊ó◊ñ◊ß ◊õ◊û◊ï ◊†◊û◊®"
  (◊ó◊®◊ï◊ñ: ◊°◊ï◊õ◊® / ◊†◊û◊®)

◊ó◊ï◊ß◊ô◊ù ◊ß◊§◊ì◊†◊ô◊ô◊ù:
‚≠ê ◊î◊ó◊®◊ï◊ñ ◊ó◊ô◊ô◊ë ◊ú◊î◊ô◊ï◊™ ◊û◊ï◊©◊ú◊ù - ◊î◊û◊ô◊ú◊î ◊î◊ê◊ó◊®◊ï◊†◊î ◊ë◊õ◊ú ◊™◊©◊ï◊ë◊î ◊ó◊ô◊ô◊ë◊™ ◊ú◊ó◊®◊ï◊ñ!
- ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊©◊ï◊†◊ï◊™ ◊ñ◊ï ◊û◊ñ◊ï ◊ë◊û◊©◊û◊¢◊ï◊™
- ◊î◊©◊ê◊ú◊î ◊û◊ß◊°◊ô◊û◊ï◊ù 255 ◊™◊ï◊ï◊ô◊ù
- ◊õ◊ú ◊™◊©◊ï◊ë◊î ◊û◊ß◊°◊ô◊û◊ï◊ù 100 ◊™◊ï◊ï◊ô◊ù
- ◊õ◊ú ◊î◊™◊©◊ï◊ë◊ï◊™ (${numOptions}) ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊ó◊®◊ï◊ñ ◊ë◊ô◊ó◊ì!

◊î◊ó◊ñ◊® JSON ◊ë◊ú◊ë◊ì ◊ë◊§◊ï◊®◊û◊ò:
{
  "question": "◊î◊©◊ê◊ú◊î ◊õ◊ê◊ü",
  "options": ["◊™◊©◊ï◊ë◊î 1", "◊™◊©◊ï◊ë◊î 2"${numOptions > 2 ? ', "◊™◊©◊ï◊ë◊î 3"' : ''}${numOptions > 3 ? ', "◊™◊©◊ï◊ë◊î 4"' : ''}]
}`;
        } else {
            pollPrompt = `◊ê◊™◊î ◊ô◊ï◊¶◊® ◊°◊ß◊®◊ô◊ù ◊ô◊¶◊ô◊®◊™◊ô◊ô◊ù ◊ï◊û◊©◊¢◊©◊¢◊ô◊ù ◊ë◊¢◊ë◊®◊ô◊™.

◊†◊ï◊©◊ê ◊î◊°◊ß◊®: ${cleanTopic}

◊¶◊ï◊® ◊°◊ß◊® ◊¢◊ù:
1. ◊©◊ê◊ú◊î ◊û◊¢◊†◊ô◊ô◊†◊™ ◊ï◊ô◊¶◊ô◊®◊™◊ô◊™ (◊ô◊õ◊ï◊ú◊î ◊ú◊î◊ô◊ï◊™ "◊û◊î ◊î◊ô◊ô◊™ ◊û◊¢◊ì◊ô◊§/◊î?" ◊ê◊ï ◊õ◊ú ◊©◊ê◊ú◊î ◊ê◊ó◊®◊™)
2. ◊ë◊ì◊ô◊ï◊ß ${numOptions} ◊™◊©◊ï◊ë◊ï◊™ ◊ê◊§◊©◊®◊ô◊ï◊™
3. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊ß◊¶◊®◊ï◊™ (◊¢◊ì 100 ◊™◊ï◊ï◊ô◊ù ◊õ◊ú ◊ê◊ó◊™)
4. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊ß◊©◊ï◊®◊ï◊™ ◊ú◊†◊ï◊©◊ê
5. ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊û◊©◊¢◊©◊¢◊ï◊™, ◊ô◊¶◊ô◊®◊™◊ô◊ï◊™, ◊ï◊û◊¢◊†◊ô◊ô◊†◊ï◊™
6. ‚≠ê ◊ó◊©◊ï◊ë: ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ú◊ê ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊ó◊®◊ï◊ñ! ‚≠ê

◊ì◊ï◊í◊û◊ê◊ï◊™ ◊ú◊ú◊ê ◊ó◊®◊ô◊ñ◊î:
- ◊†◊ï◊©◊ê: ◊ó◊™◊ï◊ú◊ô◊ù (2 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ñ◊î ◊ó◊™◊ï◊ú ◊î◊ô◊ô◊™ ◊û◊¢◊ì◊ô◊§/◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊ó◊™◊ï◊ú ◊§◊®◊°◊ô ◊®◊ö ◊ï◊†◊ó◊û◊ì"
  ◊™◊©◊ï◊ë◊î 2: "◊ó◊™◊ï◊ú ◊®◊ó◊ï◊ë ◊¢◊¶◊û◊ê◊ô ◊ï◊§◊®◊ê◊ô"

- ◊†◊ï◊©◊ê: ◊§◊ô◊¶◊î (3 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ñ◊ï ◊§◊ô◊¶◊î ◊î◊õ◊ô ◊ò◊¢◊ô◊û◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊û◊®◊í◊®◊ô◊ò◊î ◊ß◊ú◊ê◊°◊ô◊™"
  ◊™◊©◊ï◊ë◊î 2: "◊§◊§◊®◊ï◊†◊ô ◊¢◊ù ◊í◊ë◊ô◊†◊î"
  ◊™◊©◊ï◊ë◊î 3: "◊ô◊®◊ß◊ï◊™ ◊ò◊®◊ô◊ô◊ù ◊ï◊ë◊®◊ô◊ê◊ô◊ù"

- ◊†◊ï◊©◊ê: ◊ß◊§◊î (4 ◊™◊©◊ï◊ë◊ï◊™)
  ◊©◊ê◊ú◊î: "◊ê◊ô◊ö ◊ê◊™◊î ◊©◊ï◊™◊î ◊ß◊§◊î?"
  ◊™◊©◊ï◊ë◊î 1: "◊ê◊°◊§◊®◊°◊ï ◊ó◊ñ◊ß"
  ◊™◊©◊ï◊ë◊î 2: "◊ß◊§◊ï◊¶'◊ô◊†◊ï ◊û◊ï◊ß◊¶◊£"
  ◊™◊©◊ï◊ë◊î 3: "◊ú◊ê◊ò◊î ◊¢◊ù ◊ó◊ú◊ë ◊©◊ß◊ì◊ô◊ù"
  ◊™◊©◊ï◊ë◊î 4: "◊ß◊® ◊¢◊ù ◊ß◊®◊ó"

◊ó◊ï◊ß◊ô◊ù ◊ß◊§◊ì◊†◊ô◊ô◊ù:
- ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ó◊ô◊ô◊ë◊ï◊™ ◊ú◊î◊ô◊ï◊™ ◊©◊ï◊†◊ï◊™ ◊ñ◊ï ◊û◊ñ◊ï ◊ë◊û◊©◊û◊¢◊ï◊™
- ◊î◊©◊ê◊ú◊î ◊û◊ß◊°◊ô◊û◊ï◊ù 255 ◊™◊ï◊ï◊ô◊ù
- ◊õ◊ú ◊™◊©◊ï◊ë◊î ◊û◊ß◊°◊ô◊û◊ï◊ù 100 ◊™◊ï◊ï◊ô◊ù
- ◊î◊™◊©◊ï◊ë◊ï◊™ ◊ú◊ê ◊¶◊®◊ô◊õ◊ï◊™ ◊ú◊ó◊®◊ï◊ñ (◊ñ◊î ◊ó◊©◊ï◊ë!)

◊î◊ó◊ñ◊® JSON ◊ë◊ú◊ë◊ì ◊ë◊§◊ï◊®◊û◊ò:
{
  "question": "◊î◊©◊ê◊ú◊î ◊õ◊ê◊ü",
  "options": ["◊™◊©◊ï◊ë◊î 1", "◊™◊©◊ï◊ë◊î 2"${numOptions > 2 ? ', "◊™◊©◊ï◊ë◊î 3"' : ''}${numOptions > 3 ? ', "◊™◊©◊ï◊ë◊î 4"' : ''}]
}`;
        }

        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        const result = await model.generateContent(pollPrompt);
        
        if (!result.response) {
            throw new Error('No response from Gemini');
        }
        
        const responseText = result.response.text();
        
        // Try to extract JSON from response
        let jsonText = responseText.trim();
        
        // If wrapped in code fences, strip them
        const fenceMatch = jsonText.match(/```[a-zA-Z]*\n([\s\S]*?)\n```/);
        if (fenceMatch && fenceMatch[1]) {
            jsonText = fenceMatch[1].trim();
        }
        
        let parsed;
        try {
            parsed = JSON.parse(jsonText);
        } catch (parseError) {
            console.error('‚ùå Failed to parse Gemini poll response:', jsonText);
            throw new Error('Failed to parse poll data from Gemini');
        }
        
        // Validate the response
        if (!parsed.question || !parsed.options || !Array.isArray(parsed.options)) {
            throw new Error('Invalid poll data structure from Gemini');
        }
        
        // Validate number of options (must be between 2-4 and match what we requested)
        if (parsed.options.length < 2 || parsed.options.length > 4) {
            throw new Error(`Invalid number of options: ${parsed.options.length} (expected ${numOptions})`);
        }
        
        // Ensure limits
        if (parsed.question.length > 255) {
            parsed.question = parsed.question.substring(0, 252) + '...';
        }
        
        // Truncate each option if needed
        parsed.options = parsed.options.map(opt => {
            if (opt.length > 100) {
                return opt.substring(0, 97) + '...';
            }
            return opt;
        });
        
        console.log(`‚úÖ Poll generated successfully with ${parsed.options.length} ${withRhyme ? 'rhyming' : 'non-rhyming'} options:`);
        console.log(`   Question: "${parsed.question}"`);
        parsed.options.forEach((opt, idx) => {
            console.log(`   Option ${idx + 1}: "${opt}"`);
        });
        
        return {
            success: true,
            question: parsed.question,
            options: parsed.options,
            numOptions: parsed.options.length
        };
        
    } catch (err) {
        console.error('‚ùå Poll generation error:', err);
        return {
            success: false,
            error: err.message || 'Failed to generate poll'
        };
    }
}

/**
 * Get location information using Google Maps grounding
 * @param {number} latitude - Latitude
 * @param {number} longitude - Longitude
 * @returns {Object} - Location information
 */
async function getLocationInfo(latitude, longitude) {
    try {
        console.log(`üó∫Ô∏è Getting location info for: ${latitude}, ${longitude}`);
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        // HYBRID APPROACH:
        // 1. Try Google Maps Grounding first (best for populated areas)
        // 2. If it fails or returns unhelpful response, fallback to general Gemini knowledge
        
        let text = '';
        let usedMapsGrounding = false;
        
        try {
            console.log('üó∫Ô∏è Trying Google Maps Grounding first...');
            const mapsPrompt = `◊™◊ê◊® ◊ê◊™ ◊î◊û◊ô◊ß◊ï◊ù ◊ë◊ß◊ï◊ê◊ï◊®◊ì◊ô◊†◊ò◊ï◊™: ◊ß◊ï ◊®◊ï◊ó◊ë ${latitude}¬∞, ◊ß◊ï ◊ê◊ï◊®◊ö ${longitude}¬∞.
            
◊ë◊ê◊ô◊ñ◊ï ◊¢◊ô◊® ◊ê◊ï ◊ê◊ñ◊ï◊® ◊ñ◊î ◊†◊û◊¶◊ê? ◊ë◊ê◊ô◊ñ◊ï ◊û◊ì◊ô◊†◊î? ◊û◊î ◊û◊¢◊†◊ô◊ô◊ü ◊ê◊ï ◊û◊§◊ï◊®◊°◊ù ◊ë◊û◊ß◊ï◊ù ◊î◊ñ◊î?

◊™◊©◊ï◊ë◊î ◊ß◊¶◊®◊î ◊ï◊û◊¢◊†◊ô◊ô◊†◊™ ◊ë◊¢◊ë◊®◊ô◊™ (2-3 ◊©◊ï◊®◊ï◊™).`;

            const mapsResult = await model.generateContent({
                contents: [{ role: "user", parts: [{ text: mapsPrompt }] }],
                tools: [{
                    googleMaps: {}
                }],
                toolConfig: {
                    retrievalConfig: {
                        latLng: {
                            latitude: latitude,
                            longitude: longitude
                        }
                    }
                }
            });
            
            const mapsResponse = mapsResult.response;
            if (mapsResponse.candidates && mapsResponse.candidates.length > 0) {
                text = mapsResponse.text();
                
                // Check if Maps Grounding gave a useful answer
                // If it asks for more info or says it needs a specific location, it means no data
                const unhelpfulPatterns = [
                    '◊ê◊†◊ô ◊ñ◊ß◊ï◊ß ◊ú◊û◊ô◊ß◊ï◊ù',
                    '◊ê◊†◊ô ◊¶◊®◊ô◊ö ◊û◊ô◊ß◊ï◊ù',
                    '◊ê◊ô◊ñ◊î ◊û◊ô◊ß◊ï◊ù',
                    '◊ê◊ô◊ñ◊î ◊û◊ß◊ï◊ù',
                    '◊°◊§◊ß ◊ê◊™ ◊©◊ù',
                    '◊°◊§◊ß ◊©◊ù',
                    '◊°◊§◊ß◊ô ◊ê◊™',
                    '◊°◊§◊ß ◊ú◊ô ◊§◊®◊ò◊ô◊ù',
                    '◊°◊§◊ß◊ï ◊§◊®◊ò◊ô◊ù',
                    '◊õ◊ì◊ô ◊©◊ê◊ï◊õ◊ú ◊ú◊™◊ê◊®',
                    '◊õ◊ì◊ô ◊ú◊™◊ê◊®',
                    '◊ê◊†◊ê ◊°◊§◊ß',
                    '◊ú◊ê ◊¶◊ï◊ô◊ü ◊û◊ô◊ß◊ï◊ù',
                    '◊ú◊ê ◊¶◊ï◊ô◊†◊î',
                    '◊ú◊ê ◊†◊ô◊™◊ü ◊û◊ô◊ß◊ï◊ù',
                    'I need a location',
                    'I need more information',
                    'which location',
                    'which place',
                    'provide the location',
                    'provide the place',
                    'provide a location',
                    'provide more details',
                    'provide details',
                    'not specified',
                    'no location specified',
                    'location not specified',
                    '◊ê◊†◊ê ◊¶◊ô◊ô◊ü',
                    'please specify',
                    '◊ú◊ê ◊ë◊®◊ï◊®',
                    'unclear',
                    '◊ú◊ê ◊ô◊õ◊ï◊ú ◊ú◊™◊ê◊®',
                    'cannot describe'
                ];
                
                const isUnhelpful = unhelpfulPatterns.some(pattern => 
                    text.toLowerCase().includes(pattern.toLowerCase())
                );
                
                if (!isUnhelpful && text.trim().length > 20) {
                    console.log('‚úÖ Google Maps Grounding provided useful info');
                    usedMapsGrounding = true;
                } else {
                    console.log('‚ö†Ô∏è Google Maps Grounding response not useful, falling back to general knowledge...');
                    text = ''; // Reset for fallback
                }
            }
        } catch (mapsError) {
            console.log(`‚ö†Ô∏è Google Maps Grounding failed: ${mapsError.message}, falling back to general knowledge...`);
            text = ''; // Reset for fallback
        }
        
        // Fallback: Use Gemini's general geographic knowledge
        if (!text || text.trim().length === 0) {
            console.log('üåç Using Gemini general geographic knowledge...');
            const generalPrompt = `◊™◊ê◊® ◊ê◊™ ◊î◊û◊ô◊ß◊ï◊ù ◊î◊í◊ô◊ê◊ï◊í◊®◊§◊ô: ◊ß◊ï ◊®◊ï◊ó◊ë ${latitude}¬∞, ◊ß◊ï ◊ê◊ï◊®◊ö ${longitude}¬∞.

◊°◊§◊® ◊ë◊ß◊¶◊®◊î (2-3 ◊©◊ï◊®◊ï◊™):
- ◊ë◊ê◊ô◊ñ◊ï ◊û◊ì◊ô◊†◊î, ◊ê◊ñ◊ï◊® ◊ê◊ï ◊ê◊ï◊ß◊ô◊ô◊†◊ï◊° ◊ñ◊î ◊†◊û◊¶◊ê
- ◊û◊î ◊î◊ê◊ß◊ú◊ô◊ù ◊ï◊î◊ò◊ë◊¢ ◊©◊ú ◊î◊ê◊ñ◊ï◊®
- ◊ê◊ù ◊ô◊© ◊©◊ù ◊û◊©◊î◊ï ◊û◊¢◊†◊ô◊ô◊ü ◊ê◊ï ◊û◊§◊ï◊®◊°◊ù, ◊¶◊ô◊ô◊ü ◊ê◊™ ◊ñ◊î

◊™◊©◊ï◊ë◊î ◊û◊¢◊†◊ô◊ô◊†◊™ ◊ë◊¢◊ë◊®◊ô◊™.`;

            const generalResult = await model.generateContent(generalPrompt);
            const generalResponse = generalResult.response;
            
            if (!generalResponse.candidates || generalResponse.candidates.length === 0) {
                console.log('‚ùå Gemini: No candidates returned');
                return { 
                    success: false, 
                    error: 'No response from Gemini' 
                };
            }
            
            text = generalResponse.text();
        }
        
        if (!text || text.trim().length === 0) {
            console.log('‚ùå Gemini: Empty text response');
            return { 
                success: false, 
                error: 'Empty response from Gemini' 
            };
        }
        
        console.log(`‚úÖ Location info retrieved (${usedMapsGrounding ? 'Maps Grounding' : 'General Knowledge'}): ${text.substring(0, 100)}...`);
        
        return {
            success: true,
            description: text.trim(),
            latitude: latitude,
            longitude: longitude,
            usedMapsGrounding: usedMapsGrounding
        };
        
    } catch (err) {
        console.error('‚ùå Gemini error:', err);
        return { 
            success: false, 
            error: err.message || 'Failed to get location info' 
        };
    }
}

/**
 * Get bounds for a city/location name using Google Maps Geocoding
 * Optimized to get accurate bounds and handle various city sizes
 * @param {string} locationName - City or location name (e.g., "◊™◊ú ◊ê◊ë◊ô◊ë", "◊ô◊®◊ï◊©◊ú◊ô◊ù", "Barcelona")
 * @returns {Promise<Object|null>} - {minLat, maxLat, minLng, maxLng} or null if not found
 */
async function getLocationBounds(locationName) {
    try {
        console.log(`üîç Getting bounds for location: "${locationName}"`);
        
        const model = genAI.getGenerativeModel({ 
            model: "gemini-2.5-flash" 
        });
        
        // Optimized prompt: request both center coordinates AND bounds/viewport if available
        const geocodePrompt = `◊û◊¶◊ê ◊ê◊™ ◊î◊û◊ß◊ï◊ù ◊î◊ë◊ê ◊ë-Google Maps ◊ï◊ó◊ñ◊ï◊® ◊¢◊ù ◊î◊û◊ô◊ì◊¢ ◊î◊í◊ô◊ê◊ï◊í◊®◊§◊ô ◊î◊û◊ì◊ï◊ô◊ß ◊©◊ú◊ï:

◊©◊ù ◊î◊û◊ß◊ï◊ù: ${locationName}

◊î◊ó◊ñ◊® JSON ◊ë◊ú◊ë◊ì ◊ë◊§◊ï◊®◊û◊ò ◊î◊ë◊ê:
{
  "latitude": ◊û◊°◊§◊® ◊ß◊ï ◊®◊ï◊ó◊ë (◊†◊ß◊ï◊ì◊™ ◊û◊®◊õ◊ñ),
  "longitude": ◊û◊°◊§◊® ◊ß◊ï ◊ê◊ï◊®◊ö (◊†◊ß◊ï◊ì◊™ ◊û◊®◊õ◊ñ),
  "viewport": {
    "north": ◊û◊°◊§◊® (◊ß◊ï ◊®◊ï◊ó◊ë ◊û◊ß◊°◊ô◊û◊ú◊ô),
    "south": ◊û◊°◊§◊® (◊ß◊ï ◊®◊ï◊ó◊ë ◊û◊ô◊†◊ô◊û◊ú◊ô),
    "east": ◊û◊°◊§◊® (◊ß◊ï ◊ê◊ï◊®◊ö ◊û◊ß◊°◊ô◊û◊ú◊ô),
    "west": ◊û◊°◊§◊® (◊ß◊ï ◊ê◊ï◊®◊ö ◊û◊ô◊†◊ô◊û◊ú◊ô)
  },
  "found": true/false
}

◊ó◊©◊ï◊ë:
- ◊ê◊ù ◊ô◊© viewport/bounds ◊ë-Google Maps, ◊î◊©◊™◊û◊© ◊ë◊î◊ù (◊û◊ì◊ï◊ô◊ß ◊ô◊ï◊™◊®)
- ◊ê◊ù ◊ê◊ô◊ü viewport, ◊î◊©◊™◊û◊© ◊ë◊ß◊ï◊ê◊ï◊®◊ì◊ô◊†◊ò◊ï◊™ ◊î◊û◊®◊õ◊ñ ◊ë◊ú◊ë◊ì
- ◊ï◊ï◊ì◊ê ◊©◊î◊ß◊ï◊ê◊ï◊®◊ì◊ô◊†◊ò◊ï◊™ ◊ë◊™◊ï◊ö ◊î◊ò◊ï◊ï◊ó◊ô◊ù ◊î◊™◊ß◊§◊ô◊ù: ◊ß◊ï ◊®◊ï◊ó◊ë ◊ë◊ô◊ü -90 ◊ú-90, ◊ß◊ï ◊ê◊ï◊®◊ö ◊ë◊ô◊ü -180 ◊ú-180
- ◊ê◊ù ◊ú◊ê ◊û◊¶◊ê◊™ ◊ê◊™ ◊î◊û◊ß◊ï◊ù, ◊î◊ó◊ñ◊® {"found": false}`;

        const result = await model.generateContent({
            contents: [{ role: "user", parts: [{ text: geocodePrompt }] }],
            tools: [{
                googleMaps: {}
            }]
        });
        
        const response = result.response;
        if (!response.candidates || response.candidates.length === 0) {
            console.log(`‚ùå No response for location: ${locationName}`);
            return null;
        }
        
        const text = response.text();
        console.log(`üìç Geocoding response for "${locationName}": ${text.substring(0, 200)}`);
        
        // Try to parse JSON from response with improved extraction
        let locationData = null;
        try {
            // First try: Extract JSON (might have markdown code blocks like ```json ... ```)
            let jsonText = text;
            
            // Remove markdown code blocks if present
            const codeBlockMatch = text.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
            if (codeBlockMatch) {
                jsonText = codeBlockMatch[1];
            } else {
                // Extract JSON object
                const jsonMatch = text.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    jsonText = jsonMatch[0];
                }
            }
            
            locationData = JSON.parse(jsonText);
        } catch (parseErr) {
            console.warn(`‚ö†Ô∏è Could not parse JSON from geocoding response:`, parseErr.message);
            // Fallback: Try to extract coordinates and bounds from text using regex
            const latMatch = text.match(/latitude[":\s]+(-?[0-9.]+)/i);
            const lngMatch = text.match(/longitude[":\s]+(-?[0-9.]+)/i);
            
            // Try to extract viewport if available
            const northMatch = text.match(/north[":\s]+(-?[0-9.]+)/i);
            const southMatch = text.match(/south[":\s]+(-?[0-9.]+)/i);
            const eastMatch = text.match(/east[":\s]+(-?[0-9.]+)/i);
            const westMatch = text.match(/west[":\s]+(-?[0-9.]+)/i);
            
            if (latMatch && lngMatch) {
                locationData = {
                    latitude: parseFloat(latMatch[1]),
                    longitude: parseFloat(lngMatch[1]),
                    found: true
                };
                
                // If viewport found, add it
                if (northMatch && southMatch && eastMatch && westMatch) {
                    locationData.viewport = {
                        north: parseFloat(northMatch[1]),
                        south: parseFloat(southMatch[1]),
                        east: parseFloat(eastMatch[1]),
                        west: parseFloat(westMatch[1])
                    };
                }
            }
        }
        
        if (!locationData || !locationData.found) {
            console.log(`‚ùå Location not found: ${locationName}`);
            return null;
        }
        
        // Validate coordinates
        const centerLat = parseFloat(locationData.latitude);
        const centerLng = parseFloat(locationData.longitude);
        
        if (isNaN(centerLat) || isNaN(centerLng) || 
            centerLat < -90 || centerLat > 90 || 
            centerLng < -180 || centerLng > 180) {
            console.log(`‚ùå Invalid coordinates for "${locationName}": lat=${centerLat}, lng=${centerLng}`);
            return null;
        }
        
        // If viewport/bounds are available, use them (most accurate)
        if (locationData.viewport && 
            locationData.viewport.north && locationData.viewport.south &&
            locationData.viewport.east && locationData.viewport.west) {
            
            const bounds = {
                minLat: Math.min(locationData.viewport.south, locationData.viewport.north),
                maxLat: Math.max(locationData.viewport.south, locationData.viewport.north),
                minLng: Math.min(locationData.viewport.west, locationData.viewport.east),
                maxLng: Math.max(locationData.viewport.west, locationData.viewport.east)
            };
            
            // Validate bounds
            if (bounds.minLat >= -90 && bounds.maxLat <= 90 && 
                bounds.minLng >= -180 && bounds.maxLng <= 180 &&
                bounds.minLat < bounds.maxLat && bounds.minLng < bounds.maxLng) {
                console.log(`‚úÖ Found viewport bounds for "${locationName}": ${JSON.stringify(bounds)}`);
                return bounds;
            }
        }
        
        // Fallback: Calculate bounds from center point with dynamic radius based on city size
        // Use smaller radius for better precision (covers most cities well)
        // Adjust radius slightly based on latitude (longitude degrees are shorter near poles)
        const baseRadius = 0.4; // ~44km at equator, smaller for better precision
        const latAdjustment = Math.cos(centerLat * Math.PI / 180); // Adjust for longitude spacing
        
        const bounds = {
            minLat: Math.max(-90, centerLat - baseRadius),
            maxLat: Math.min(90, centerLat + baseRadius),
            minLng: Math.max(-180, centerLng - (baseRadius / latAdjustment)),
            maxLng: Math.min(180, centerLng + (baseRadius / latAdjustment))
        };
        
        console.log(`‚úÖ Found center-point bounds for "${locationName}": ${JSON.stringify(bounds)}`);
        return bounds;
        
    } catch (err) {
        console.error(`‚ùå Error getting bounds for "${locationName}":`, err.message);
        console.error(`   Stack: ${err.stack}`);
        return null;
    }
}

module.exports = {
    generateImageWithText, 
    generateImageForWhatsApp, 
    editImageWithText, 
    editImageForWhatsApp, 
    analyzeImageWithText,
    analyzeVideoWithText,
    generateVideoWithText, 
    generateVideoWithImage, 
    generateVideoForWhatsApp, 
    generateVideoFromImageForWhatsApp, 
    generateTextResponse, 
    generateChatSummary,
    parseMusicRequest,
    parseTextToSpeechRequest,
    translateText,
    generateCreativePoll,
    getLocationInfo,
    getLocationBounds
};
