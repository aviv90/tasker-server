/**
 * Agent Pilot - Direct routing to Agent (bypassing intentRouter)
 * 
 * This is a pilot implementation that sends ALL requests directly to the Agent,
 * skipping both Regex heuristics and LLM Router prompt.
 * 
 * The Agent (via Gemini Functions API) will handle ALL intent detection and routing.
 */

const { executeAgentQuery } = require('./agentService');
const conversationManager = require('./conversationManager');

/**
 * Route incoming request directly to Agent
 * @param {Object} input - Normalized input from webhook
 * @param {string} chatId - Chat ID for context
 * @returns {Promise<Object>} - Agent execution result
 */
async function routeToAgent(input, chatId) {
  console.log(' [PILOT] Routing directly to Agent (bypassing intentRouter)');
  
  // Extract the user's prompt/request
  const userText = input.userText || '';
  
  // Build context for the agent
  let contextualPrompt = userText;
  
  // Add quoted message context if present (super important for retry/edit workflows!)
  if (input.quotedContext) {
    contextualPrompt = `[注 爪转: ${input.quotedContext.type}]\n${input.quotedContext.text || ''}\n\n[拽砖 转:]\n${userText}`;
    
    // If quoted message has media, note it
    if (input.quotedContext.hasImage) {
      contextualPrompt = `[注 爪转: 转]\n${input.quotedContext.text || '(转)'}\n\n[拽砖 转:]\n${userText}`;
    } else if (input.quotedContext.hasVideo) {
      contextualPrompt = `[注 爪转: ]\n${input.quotedContext.text || '()'}\n\n[拽砖 转:]\n${userText}`;
    }
  }
  
  // Add current media context if present
  if (input.hasImage && !input.quotedContext) {
    contextualPrompt = `[砖转砖 砖 转] ${userText}`;
  } else if (input.hasVideo && !input.quotedContext) {
    contextualPrompt = `[砖转砖 砖 ] ${userText}`;
  } else if (input.hasAudio && !input.quotedContext) {
    contextualPrompt = `[砖转砖 砖 拽 拽转] ${userText}`;
  }
  
  // Add authorization context (important for agent to know what tools it can use)
  const authContext = [];
  if (input.authorizations?.media_creation) {
    authContext.push('专砖 爪专转  (转转//拽)');
  }
  if (input.authorizations?.group_creation) {
    authContext.push('专砖 爪专转 拽爪转');
  }
  if (input.authorizations?.voice_allowed) {
    authContext.push('专砖 砖砖  拽');
  }
  
  if (authContext.length > 0) {
    contextualPrompt += `\n\n[专砖转: ${authContext.join(', ')}]`;
  }
  
  console.log(` [PILOT] Sending to Agent: "${contextualPrompt.substring(0, 100)}..."`);
  
  // Execute agent query
  const agentResult = await executeAgentQuery(contextualPrompt, chatId, {
    maxIterations: 5,
    input: input // Pass full input for agent tools to access
  });
  
  // Save the last successful command for retry functionality
  if (agentResult.success && agentResult.toolsUsed && agentResult.toolsUsed.length > 0) {
    // Save the primary tool that was used (usually the first one)
    const primaryTool = agentResult.toolsUsed[0];
    
    await conversationManager.saveLastCommand(chatId, primaryTool, {
      prompt: userText,
      // Additional context can be added here
    }, {
      normalized: input
    });
    
    console.log(` [PILOT] Saved last command for retry: ${primaryTool}`);
  }
  
  return agentResult;
}

module.exports = {
  routeToAgent
};

