const { GoogleGenerativeAI } = require('@google/generative-ai');
const fs = require('fs');
const os = require('os');
const path = require('path');
const { promisify } = require('util');
const { exec } = require('child_process');
const conversationManager = require('./conversationManager');
const { cleanThinkingPatterns } = require('./geminiService');
const locationService = require('./locationService');

const execAsync = promisify(exec);

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Helper function to format provider names nicely
const formatProviderName = (provider) => {
  const providerNames = {
    'gemini': 'Gemini',
    'openai': 'OpenAI',
    'grok': 'Grok',
    'veo3': 'Veo 3',
    'veo-3': 'Veo 3',
    'veo': 'Veo 3',
    'sora': 'Sora 2',
    'sora-2': 'Sora 2',
    'sora2': 'Sora 2',
    'sora-pro': 'Sora 2 Pro',
    'sora-2-pro': 'Sora 2 Pro',
    'kling': 'Kling',
    'runway': 'Runway',
    'suno': 'Suno'
  };
  return providerNames[provider?.toLowerCase()] || provider;
};

// Lazy-loaded services to avoid circular dependencies and improve startup time
let geminiService, openaiService, grokService, greenApiService;
const getServices = () => {
  if (!geminiService) geminiService = require('./geminiService');
  if (!openaiService) openaiService = require('./openaiService');
  if (!grokService) grokService = require('./grokService');
  if (!greenApiService) greenApiService = require('./greenApiService');
// Utility: get audio duration via ffprobe (mirrors whatsappRoutes implementation)
const getAudioDuration = async (audioBuffer) => {
  try {
    const tempFilePath = path.join(os.tmpdir(), `agent_audio_check_${Date.now()}.ogg`);
    fs.writeFileSync(tempFilePath, audioBuffer);

    try {
      const { stdout } = await execAsync(
        `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${tempFilePath}"`
      );
      const duration = parseFloat(stdout.trim());
      fs.unlinkSync(tempFilePath);
      console.log(`â±ï¸ [Agent] Audio duration: ${duration.toFixed(2)} seconds`);
      return duration;
    } catch (err) {
      if (fs.existsSync(tempFilePath)) {
        fs.unlinkSync(tempFilePath);
      }
      console.error(`âŒ [Agent] Could not get audio duration: ${err.message}`);
      return 0;
    }
  } catch (err) {
    console.error(`âŒ [Agent] Error in getAudioDuration: ${err.message}`);
    return 0;
  }
};

  return { geminiService, openaiService, grokService, greenApiService };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• AGENT CONTEXT MEMORY (Persistent in DB) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Agent context is now stored persistently in PostgreSQL database
// No more in-memory cache or TTL - context persists indefinitely like ChatGPT
// Access via conversationManager.saveAgentContext/getAgentContext/clearAgentContext
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Agent Service - Autonomous AI agent that can use tools dynamically
 * 
 * This service allows Gemini to act as an autonomous agent that can:
 * - Fetch chat history when needed
 * - Analyze images/videos/audio from history
 * - Search the web
 * - And more...
 */

/**
 * Utility functions for smart retry strategies
 */

/**
 * Simplify a complex prompt by removing unnecessary details
 * @param {string} prompt - Original prompt
 * @returns {string} - Simplified prompt
 */
function simplifyPrompt(prompt) {
  if (!prompt) return prompt;
  
  // Remove excessive details, adjectives, and complex descriptions
  let simplified = prompt;
  
  // Remove multiple adjectives (keep only core nouns/verbs)
  // "beautiful, stunning, amazing cat" â†’ "cat"
  simplified = simplified.replace(/(\w+,\s*){2,}(\w+)\s+(\w+)/gi, '$3');
  
  // Remove very specific style requests
  simplified = simplified.replace(/\b(in the style of|×‘×¡×’× ×•×Ÿ|×›××•|like)\s+.+?(,|\.|$)/gi, '');
  
  // Remove detailed background descriptions
  simplified = simplified.replace(/\b(with (a |an )?background|×‘×¨×§×¢|×¢× ×¨×§×¢)\s+.+?(,|\.|$)/gi, '');
  
  // Remove complex lighting/atmosphere descriptions
  simplified = simplified.replace(/\b(lighting|×ª××•×¨×”|××•×•×™×¨×”|atmosphere):?\s+.+?(,|\.|$)/gi, '');
  
  // Trim and clean up
  simplified = simplified.trim().replace(/\s+/g, ' ');
  
  // If we removed too much, return original
  if (simplified.length < 10) return prompt;
  
  return simplified;
}

/**
 * Check if a prompt is too complex and should be split
 * @param {string} prompt - Prompt to check
 * @returns {boolean} - True if should split
 */
function shouldSplitTask(prompt) {
  if (!prompt) return false;
  
  // Check for multiple independent requests
  const hasMultipleRequests = /\b×•(×’×|××–|××—×¨ ×›×š|×œ××—×¨ ××›×Ÿ)\b/gi.test(prompt) || 
                              /\b(and then|after that|also|plus)\b/gi.test(prompt);
  
  // Check for conditional logic
  const hasConditional = /\b(××|if|when|×›×©|×‘××™×“×”)\b/gi.test(prompt);
  
  // Check for multiple steps explicitly mentioned
  const hasSteps = /\b(×§×•×“×|×¨××©×•×Ÿ|×©× ×™|×©×œ×™×©×™|××—×¨×•×Ÿ|first|second|third|last|step)\b/gi.test(prompt);
  
  // Check prompt length (very long prompts often need splitting)
  const isTooLong = prompt.length > 200;
  
  return (hasMultipleRequests || hasConditional || hasSteps) && isTooLong;
}

/**
 * Split a complex prompt into smaller subtasks
 * @param {string} prompt - Complex prompt
 * @returns {string[]} - Array of subtasks
 */
function splitTaskIntoSteps(prompt) {
  if (!prompt) return [prompt];
  
  const steps = [];
  
  // Try to split by explicit connectors
  const splitPatterns = [
    /\s+(×•××–|×•××—×¨ ×›×š|×•×œ××—×¨ ××›×Ÿ|×•×’×)\s+/gi,
    /\s+(and then|after that|afterwards|also)\s+/gi,
    /\.\s+/g  // Split by sentences
  ];
  
  let parts = [prompt];
  
  for (const pattern of splitPatterns) {
    if (pattern.test(prompt)) {
      parts = prompt.split(pattern).filter(p => p.trim().length > 10);
      break;
    }
  }
  
  // If we couldn't split intelligently, try to extract main concepts
  if (parts.length === 1 && prompt.length > 150) {
    // Extract main nouns/actions as separate steps
    const mainConcepts = prompt.match(/\b(×¦×•×¨|×ª×¦×•×¨|×¢×¨×•×š|×ª×¢×¨×•×š|× ×ª×—|×ª× ×ª×—|×”×•×¡×£|×ª×•×¡×™×£|create|edit|analyze|add)\s+[^,\.]+/gi);
    
    if (mainConcepts && mainConcepts.length > 1) {
      return mainConcepts.map(c => c.trim());
    }
  }
  
  return parts.length > 1 ? parts.map(p => p.trim()) : [prompt];
}

/**
 * Make a prompt more generic by removing specific details
 * @param {string} prompt - Original prompt
 * @returns {string} - Generic version
 */
function makePromptMoreGeneric(prompt) {
  if (!prompt) return prompt;
  
  let generic = prompt;
  
  // Remove specific names/brands
  generic = generic.replace(/\b(×©×œ|××‘×™×ª|by|from)\s+[A-Z][a-z]+\b/g, '');
  
  // Remove specific years/dates
  generic = generic.replace(/\b(×?×©× ×ª|from|in)\s+(19|20)\d{2}\b/gi, '');
  
  // Remove very specific technical terms
  generic = generic.replace(/\b(resolution|×¨×–×•×œ×•×¦×™×”|quality|××™×›×•×ª):\s*\d+[a-z]*/gi, '');
  
  // Remove specific color codes
  generic = generic.replace(/#[0-9A-Fa-f]{6}\b/g, 'color');
  
  // Simplify comparative language
  generic = generic.replace(/\b(very|extremely|super|incredibly|×××•×“|×¡×•×¤×¨|×‘××™×•×—×“)\s+/gi, '');
  
  // Trim
  generic = generic.trim().replace(/\s+/g, ' ');
  
  return generic;
}

/**
 * Define available tools for the agent
 */
const agentTools = {
  // Tool 1: Get chat history
  get_chat_history: {
    declaration: {
      name: 'get_chat_history',
      description: '×§×‘×œ ××ª ×”×™×¡×˜×•×¨×™×™×ª ×”×”×•×“×¢×•×ª ××”×©×™×—×”. ×”×©×ª××© ×‘×›×œ×™ ×”×–×” ×›×©×”××©×ª××© ××ª×™×™×—×¡ ×œ×”×•×“×¢×•×ª ×§×•×“××•×ª, ××• ×›×©××ª×” ×¦×¨×™×š ×§×•× ×˜×§×¡×˜ × ×•×¡×£ ××”×©×™×—×”.',
      parameters: {
        type: 'object',
        properties: {
          limit: {
            type: 'number',
            description: '××¡×¤×¨ ×”×”×•×“×¢×•×ª ×”××—×¨×•× ×•×ª ×œ×©×œ×•×£ (×‘×¨×™×¨×ª ××—×“×œ: 20)',
          }
        },
        required: []
      }
    },
    execute: async (args, context) => {
      const limit = args.limit || 20;
      console.log(`ğŸ”§ [Agent Tool] get_chat_history called with limit: ${limit}`);
      
      try {
        const history = await conversationManager.getConversationHistory(context.chatId);
        
        if (!history || history.length === 0) {
          return {
            success: true,
            data: '××™×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×”×•×“×¢×•×ª ×–××™× ×”',
            messages: []
          };
        }
        
        // Format history for the agent
        const formattedHistory = history.map((msg, idx) => {
          let content = `${msg.role === 'user' ? '××©×ª××©' : '×‘×•×˜'}: ${msg.content}`;
          
          // Add media indicators with URLs
          if (msg.metadata) {
            if (msg.metadata.hasImage && msg.metadata.imageUrl) {
              content += ` [×ª××•× ×”: image_id=${idx}, url=${msg.metadata.imageUrl}]`;
            } else if (msg.metadata.hasImage) {
              content += ' [×ª××•× ×” ××¦×•×¨×¤×ª]';
            }
            
            if (msg.metadata.hasVideo && msg.metadata.videoUrl) {
              content += ` [×•×™×“××•: video_id=${idx}, url=${msg.metadata.videoUrl}]`;
            } else if (msg.metadata.hasVideo) {
              content += ' [×•×™×“××• ××¦×•×¨×£]';
            }
            
            if (msg.metadata.hasAudio && msg.metadata.audioUrl) {
              content += ` [××•×“×™×•: audio_id=${idx}, url=${msg.metadata.audioUrl}]`;
              if (msg.metadata.transcribedText) {
                content += ` [×ª××œ×•×œ: "${msg.metadata.transcribedText}"]`;
              }
            } else if (msg.metadata.hasAudio) {
              content += ' [×”×§×œ×˜×” ×§×•×œ×™×ª]';
            }
          }
          
          return content;
        }).join('\n');
        
        return {
          success: true,
          data: `×”×™×¡×˜×•×¨×™×” ×©×œ ${history.length} ×”×•×“×¢×•×ª ××—×¨×•× ×•×ª:\n\n${formattedHistory}`,
          messages: history  // Keep full history for follow-up tools
        };
      } catch (error) {
        console.error('âŒ Error in get_chat_history tool:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×©×œ×™×¤×ª ×”×™×¡×˜×•×¨×™×”: ${error.message}`
        };
      }
    }
  },

  // Tool 2: Analyze image from history
  analyze_image_from_history: {
    declaration: {
      name: 'analyze_image_from_history',
      description: '× ×ª×— ×ª××•× ×” ××”×™×¡×˜×•×¨×™×™×ª ×”×”×•×“×¢×•×ª. ×”×©×ª××© ×‘×›×œ×™ ×”×–×” ××—×¨×™ ×©×©×œ×¤×ª ××ª ×”×™×¡×˜×•×¨×™×™×ª ×”×”×•×“×¢×•×ª ×•×¨××™×ª ×©×™×© ×ª××•× ×” ×¨×œ×•×•× ×˜×™×ª.',
      parameters: {
        type: 'object',
        properties: {
          image_id: {
            type: 'number',
            description: '××–×”×” ×”×ª××•× ×” ××”×”×™×¡×˜×•×¨×™×” (×”××¡×¤×¨ ×©××•×¤×™×¢ ×‘-[image_id: X])',
          },
          question: {
            type: 'string',
            description: '×”×©××œ×” ××• ×”×‘×§×©×” ×œ×’×‘×™ ×”×ª××•× ×”',
          }
        },
        required: ['image_id', 'question']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] analyze_image_from_history called with image_id: ${args.image_id}`);
      
      let imageBuffer = null;
      try {
        // Get the message with the image
        const history = context.previousToolResults?.get_chat_history?.messages;
        if (!history || !history[args.image_id]) {
          return {
            success: false,
            error: `×œ× × ××¦××” ×ª××•× ×” ×¢× ×”××–×”×” ${args.image_id}`
          };
        }
        
        const message = history[args.image_id];
        const imageUrl = message.metadata?.imageUrl;
        
        if (!imageUrl) {
          return {
            success: false,
            error: `×”×”×•×“×¢×” ${args.image_id} ×œ× ××›×™×œ×” ×ª××•× ×”`
          };
        }
        
        // Download and analyze the image
        const { geminiService, greenApiService } = getServices();
        imageBuffer = await greenApiService.downloadFile(imageUrl);
        
        const result = await geminiService.analyzeImageWithText(args.question, imageBuffer);
        
        // Free memory
        imageBuffer = null;
        
        if (result.success) {
          return {
            success: true,
            data: result.text
          };
        } else {
          return {
            success: false,
            error: result.error || '×©×’×™××” ×‘× ×™×ª×•×— ×”×ª××•× ×”'
          };
        }
      } catch (error) {
        console.error('âŒ Error in analyze_image_from_history tool:', error);
        // Free memory on error
        imageBuffer = null;
        return {
          success: false,
          error: `×©×’×™××” ×‘× ×™×ª×•×— ×ª××•× ×”: ${error.message}`
        };
      }
    }
  },

  // Tool 3: Search web
  search_web: {
    declaration: {
      name: 'search_web',
      description: '×—×¤×© ××™×“×¢ ×‘××™× ×˜×¨× ×˜. ×”×©×ª××© ×‘×›×œ×™ ×”×–×” ×›×©××ª×” ×¦×¨×™×š ××™×“×¢ ×¢×“×›× ×™ ××• ××™×“×¢ ×©××™× ×• ×–××™×Ÿ ×‘×™×“×¢ ×©×œ×š.',
      parameters: {
        type: 'object',
        properties: {
          query: {
            type: 'string',
            description: '×©××™×œ×ª×ª ×”×—×™×¤×•×©',
          }
        },
        required: ['query']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] search_web called with query: ${args.query}`);
      
      try {
        // Use Gemini with Google Search
        const { geminiService } = getServices();
        const result = await geminiService.generateTextResponse(args.query, [], {
          useGoogleSearch: true
        });
        
        if (result.error) {
          return {
            success: false,
            error: result.error
          };
        }
        
        return {
          success: true,
          data: result.text
        };
      } catch (error) {
        console.error('âŒ Error in search_web tool:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×—×™×¤×•×©: ${error.message}`
        };
      }
    }
  },

  // Tool 4: Access long-term memory (summaries & preferences)
  save_user_preference: {
    declaration: {
      name: 'save_user_preference',
      description: '×©××•×¨ ×”×¢×“×¤×ª ××©×ª××© ×œ×˜×•×•×— ××¨×•×š. ×”×©×ª××© ×›×©××©×ª××© ××•××¨ "×ª××™×“...", "×× ×™ ××¢×“×™×£...", "×‘×¤×¢× ×”×‘××”...", "×–×›×•×¨ ×©...". ×“×•×’×××•×ª: "×ª××™×“ ×¦×•×¨ ×ª××•× ×•×ª ×¢× OpenAI", "×× ×™ ××¢×“×™×£ ×•×™×“××• ×§×¦×¨×™×", "×–×›×•×¨ ×©×× ×™ ×œ× ××•×”×‘ ×—×ª×•×œ×™×".',
      parameters: {
        type: 'object',
        properties: {
          preference_key: {
            type: 'string',
            description: '××¤×ª×— ×”×”×¢×“×¤×” (×œ××©×œ: "preferred_image_provider", "video_style", "dislikes")'
          },
          preference_value: {
            type: 'string',
            description: '×¢×¨×š ×”×”×¢×“×¤×”'
          },
          description: {
            type: 'string',
            description: '×ª×™××•×¨ ×§×¦×¨ ×©×œ ×”×”×¢×“×¤×” (××•×¤×¦×™×•× ×œ×™)'
          }
        },
        required: ['preference_key', 'preference_value']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] save_user_preference called: ${args.preference_key} = ${args.preference_value}`);
      
      try {
        await conversationManager.saveUserPreference(
          context.chatId, 
          args.preference_key, 
          args.preference_value
        );
        
        return {
          success: true,
          data: `âœ… ×©××¨×ª×™ ××ª ×”×”×¢×“×¤×”: ${args.preference_key} = ${args.preference_value}`
        };
      } catch (error) {
        console.error('âŒ Error in save_user_preference tool:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×©××™×¨×ª ×”×¢×“×¤×”: ${error.message}`
        };
      }
    }
  },
  
  get_long_term_memory: {
    declaration: {
      name: 'get_long_term_memory',
      description: '×§×¨× ×–×™×›×¨×•×Ÿ ××¨×•×š ×˜×•×•×— - ×¡×™×›×•××™ ×©×™×—×•×ª ×§×•×“××•×ª ×•×”×¢×“×¤×•×ª ××©×ª××©. ×”×©×ª××© ×›×©×¦×¨×™×š ×œ×”×‘×™×Ÿ ×”×§×©×¨ ×¨×—×‘ ×™×•×ª×¨ ××• ×œ×‘×“×•×§ ××” ×”××©×ª××© ××•×”×‘/×œ× ××•×”×‘.',
      parameters: {
        type: 'object',
        properties: {
          include_summaries: {
            type: 'boolean',
            description: '×”×× ×œ×›×œ×•×œ ×¡×™×›×•××™ ×©×™×—×•×ª ×§×•×“××•×ª (×‘×¨×™×¨×ª ××—×“×œ: true)',
          },
          include_preferences: {
            type: 'boolean',
            description: '×”×× ×œ×›×œ×•×œ ×”×¢×“×¤×•×ª ××©×ª××© (×‘×¨×™×¨×ª ××—×“×œ: true)',
          }
        },
        required: []
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] get_long_term_memory called`);
      
      try {
        const includeSummaries = args.include_summaries !== false;
        const includePreferences = args.include_preferences !== false;
        
        let result = {
          success: true,
          data: ''
        };
        
        // Get summaries
        if (includeSummaries) {
          const summaries = await conversationManager.getConversationSummaries(context.chatId, 5);
          
          if (summaries.length > 0) {
            result.data += 'ğŸ“š ×¡×™×›×•××™ ×©×™×—×•×ª ×§×•×“××•×ª:\n\n';
            summaries.forEach((summary, idx) => {
              result.data += `${idx + 1}. ${summary.summary}\n`;
              if (summary.keyTopics && summary.keyTopics.length > 0) {
                result.data += `   × ×•×©××™×: ${summary.keyTopics.join(', ')}\n`;
              }
              result.data += '\n';
            });
            result.summaries = summaries;
          } else {
            result.data += 'ğŸ“š ××™×Ÿ ×¡×™×›×•××™ ×©×™×—×•×ª ×§×•×“××•×ª\n\n';
          }
        }
        
        // Get preferences
        if (includePreferences) {
          const preferences = await conversationManager.getUserPreferences(context.chatId);
          
          if (Object.keys(preferences).length > 0) {
            result.data += 'âš™ï¸ ×”×¢×“×¤×•×ª ××©×ª××©:\n';
            for (const [key, value] of Object.entries(preferences)) {
              result.data += `   â€¢ ${key}: ${value}\n`;
            }
            result.preferences = preferences;
          } else {
            result.data += 'âš™ï¸ ××™×Ÿ ×”×¢×“×¤×•×ª ××©×ª××© ×©××•×¨×•×ª';
          }
        }
        
        return result;
      } catch (error) {
        console.error('âŒ Error in get_long_term_memory tool:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×’×™×©×” ×œ×–×™×›×¨×•×Ÿ ××¨×•×š ×˜×•×•×—: ${error.message}`
        };
      }
    }
  },

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CREATION TOOLS (Basic) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // Tool 5: Create image (basic tool)
  create_image: {
    declaration: {
      name: 'create_image',
      description: '×¦×•×¨ ×ª××•× ×” ×—×“×©×”. ×‘×¨×™×¨×ª ××—×“×œ: Gemini. ×× ×ª×¨×¦×” ×¡×¤×§ ××—×¨, ×¦×™×™×Ÿ ×‘×¤×¨××˜×¨ provider.',
      parameters: {
        type: 'object',
        properties: {
          prompt: {
            type: 'string',
            description: '×ª×™××•×¨ ×”×ª××•× ×” ×œ×™×¦×™×¨×”',
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×”: gemini (×‘×¨×™×¨×ª ××—×“×œ), openai, ××• grok',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['prompt']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_image called`);
      
      try {
        if (context?.expectedMediaType === 'video') {
          return {
            success: false,
            error: '×”×ª×‘×§×©×ª ×œ×™×¦×•×¨ ×•×™×“××•, ×œ× ×ª××•× ×”. ×‘×—×¨ ×¡×¤×§ ×•×™×“××• ××ª××™× ××• × ×¡×” ×©×•×‘.'
          };
        }

        const provider = args.provider || 'gemini';
        const { geminiService, openaiService, grokService } = getServices();
        
        let imageResult;
        if (provider === 'openai') {
          imageResult = await openaiService.generateImageForWhatsApp(args.prompt);
        } else if (provider === 'grok') {
          imageResult = await grokService.generateImageForWhatsApp(args.prompt);
        } else {
          imageResult = await geminiService.generateImageForWhatsApp(args.prompt);
        }
        
        if (imageResult.error) {
          return {
            success: false,
            error: `×©×’×™××” ×‘×™×¦×™×¨×ª ×ª××•× ×” ×¢× ${provider}: ${imageResult.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×ª××•× ×” × ×•×¦×¨×” ×‘×”×¦×œ×—×”!`,
          imageUrl: imageResult.imageUrl,
          imageCaption: imageResult.description || imageResult.revisedPrompt || '',
          provider: provider
        };
      } catch (error) {
        console.error('âŒ Error in create_image tool:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• META TOOLS (Stage 2) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // Tool 5: Create and analyze (meta-tool)
  create_and_analyze: {
    declaration: {
      name: 'create_and_analyze',
      description: '×¦×•×¨ ×ª××•× ×” ×•××™×“ × ×ª×— ××•×ª×”. ×©×™××•×©×™ ×›×©××ª×” ×¨×•×¦×” ×œ×•×•×“× ×©×”×ª××•× ×” ×¢×•××“×ª ×‘×“×¨×™×©×•×ª ××¡×•×™××•×ª.',
      parameters: {
        type: 'object',
        properties: {
          prompt: {
            type: 'string',
            description: '×ª×™××•×¨ ×”×ª××•× ×” ×œ×™×¦×™×¨×”',
          },
          analysis_question: {
            type: 'string',
            description: '××” ×œ×‘×“×•×§ ×‘×ª××•× ×” (×œ×“×•×’××”: "×”×× ×™×© ×›×œ×‘ ×‘×ª××•× ×”?")',
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×”: gemini, openai, ××• grok (×‘×¨×™×¨×ª ××—×“×œ: gemini)',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['prompt', 'analysis_question']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_and_analyze called`);
      
      let imageBuffer = null;
      try {
        const provider = args.provider || 'gemini';
        const { geminiService, openaiService, grokService, fileDownloader } = getServices();
        
        // Step 1: Create image
        let imageResult;
        if (provider === 'openai') {
          imageResult = await openaiService.generateImageForWhatsApp(args.prompt);
        } else if (provider === 'grok') {
          imageResult = await grokService.generateImageForWhatsApp(args.prompt);
        } else {
          imageResult = await geminiService.generateImageForWhatsApp(args.prompt);
        }
        
        if (imageResult.error) {
          return {
            success: false,
            error: `×©×’×™××” ×‘×™×¦×™×¨×ª ×ª××•× ×”: ${imageResult.error}`
          };
        }
        
        console.log(`âœ… Image created with ${provider}, analyzing...`);
        
        // Step 2: Download and analyze
        const { greenApiService: greenApi2 } = getServices();
        imageBuffer = await greenApi2.downloadFile(imageResult.imageUrl);
        const analysisResult = await geminiService.analyzeImageWithText(args.analysis_question, imageBuffer);
        
        // Free memory
        imageBuffer = null;
        
        if (analysisResult.error) {
          return {
            success: false,
            error: `×”×ª××•× ×” × ×•×¦×¨×” ××‘×œ ×”× ×™×ª×•×— × ×›×©×œ: ${analysisResult.error}`
          };
        }
        
        return {
          success: true,
          data: `×”×ª××•× ×” × ×•×¦×¨×” ×‘×”×¦×œ×—×”! × ×™×ª×•×—: ${analysisResult.text}`,
          imageUrl: imageResult.imageUrl,
          caption: imageResult.description || ''
        };
      } catch (error) {
        console.error('âŒ Error in create_and_analyze tool:', error);
        // Free memory on error
        imageBuffer = null;
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool 5: Analyze and edit (meta-tool)
  analyze_and_edit: {
    declaration: {
      name: 'analyze_and_edit',
      description: '× ×ª×— ×ª××•× ×” ××”×”×™×¡×˜×•×¨×™×” ×•××– ×¢×¨×•×š ××•×ª×” ×‘×”×ª×× ×œ×××¦××™×. ×©×™××•×©×™ ×œ×©×™×¤×•×¨ ×ª××•× ×•×ª ××•×˜×•××˜×™.',
      parameters: {
        type: 'object',
        properties: {
          image_id: {
            type: 'number',
            description: '××–×”×” ×”×ª××•× ×” ××”×”×™×¡×˜×•×¨×™×”',
          },
          analysis_goal: {
            type: 'string',
            description: '××” ×œ×‘×“×•×§ ×‘×ª××•× ×” (×œ×“×•×’××”: "××” ×—×¡×¨ ×‘×ª××•× ×”?")',
          },
          edit_instruction: {
            type: 'string',
            description: '×”×•×¨××•×ª ×œ×¢×¨×™×›×” (×œ×“×•×’××”: "×”×•×¡×£ ××ª ××” ×©×—×¡×¨")',
          }
        },
        required: ['image_id', 'analysis_goal', 'edit_instruction']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] analyze_and_edit called`);
      
      let imageBuffer = null;
      try {
        // Step 1: Get image from history
        const history = context.previousToolResults?.get_chat_history?.messages;
        if (!history || !history[args.image_id]) {
          return {
            success: false,
            error: `×œ× × ××¦××” ×ª××•× ×” ×¢× ×”××–×”×” ${args.image_id}`
          };
        }
        
        const message = history[args.image_id];
        const imageUrl = message.metadata?.imageUrl;
        
        if (!imageUrl) {
          return {
            success: false,
            error: `×”×”×•×“×¢×” ${args.image_id} ×œ× ××›×™×œ×” ×ª××•× ×”`
          };
        }
        
        // Step 2: Analyze
        const { geminiService, greenApiService } = getServices();
        imageBuffer = await greenApiService.downloadFile(imageUrl);
        
        const analysisResult = await geminiService.analyzeImageWithText(args.analysis_goal, imageBuffer);
        
        if (analysisResult.error) {
          imageBuffer = null;
          return {
            success: false,
            error: `×©×’×™××” ×‘× ×™×ª×•×—: ${analysisResult.error}`
          };
        }
        
        console.log(`âœ… Analysis complete: ${analysisResult.text.substring(0, 50)}...`);
        
        // Step 3: Edit based on analysis
        const editPrompt = `${args.edit_instruction}. ×‘×”×ª×‘×¡×¡ ×¢×œ ×”× ×™×ª×•×—: ${analysisResult.text}`;
        const editResult = await geminiService.editImageWithText(editPrompt, imageBuffer);
        
        // Free memory
        imageBuffer = null;
        
        if (editResult.error) {
          return {
            success: false,
            error: `×”× ×™×ª×•×— ×”×¦×œ×™×— ××‘×œ ×”×¢×¨×™×›×” × ×›×©×œ×”: ${editResult.error}`
          };
        }
        
        return {
          success: true,
          data: `× ×™×ª×—×ª×™ ××ª ×”×ª××•× ×” ×•×¢×¨×™×›×ª×™ ××•×ª×”! ×××¦××™×: ${analysisResult.text}`,
          imageUrl: editResult.url
        };
      } catch (error) {
        console.error('âŒ Error in analyze_and_edit tool:', error);
        // Free memory on error
        imageBuffer = null;
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool 6: Smart Execute with Fallback (meta-tool - Stage 3)
  smart_execute_with_fallback: {
    declaration: {
      name: 'smart_execute_with_fallback',
      description: '×‘×¦×¢ ××©×™××” ×¢× ××¡×˜×¨×˜×’×™×•×ª fallback ×—×›××•×ª. ×× × ×™×¡×™×•×Ÿ ×¨××©×•×Ÿ × ×›×©×œ, × × ×¡×” ××•×˜×•××˜×™×ª: ×œ×¤×©×˜ ××ª ×”×¤×¨×•××¤×˜, ×œ× ×¡×•×ª ×¡×¤×§ ××—×¨, ××• ×œ×¤×¦×œ ×œ××©×™××•×ª ×§×˜× ×•×ª ×™×•×ª×¨. ×”×©×ª××© ×‘×›×œ×™ ×”×–×” ×¨×§ ×œ××—×¨ ×©× ×™×¡×™×•×Ÿ ×¨×’×™×œ ×›×‘×¨ × ×›×©×œ!',
      parameters: {
        type: 'object',
        properties: {
          task_type: {
            type: 'string',
            description: '×¡×•×’ ×”××©×™××”: image_creation, video_creation, audio_creation',
            enum: ['image_creation', 'video_creation', 'audio_creation']
          },
          original_prompt: {
            type: 'string',
            description: '×”×¤×¨×•××¤×˜ ×”××§×•×¨×™ ×©× ×›×©×œ'
          },
          failure_reason: {
            type: 'string',
            description: '×œ××” ×”× ×™×¡×™×•×Ÿ ×”×¨××©×•×Ÿ × ×›×©×œ'
          },
          provider_tried: {
            type: 'string',
            description: '××™×–×” ×¡×¤×§ ×›×‘×¨ × ×•×¡×” (gemini/openai/grok)',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['task_type', 'original_prompt', 'failure_reason']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ§  [Agent Tool] smart_execute_with_fallback called for ${args.task_type}`);
      
      try {
        const { geminiService, openaiService, grokService } = getServices();
        if (args.task_type === 'video_creation') {
          context.expectedMediaType = 'video';
        }
        
        // Strategy 1: Try different provider
        console.log(`ğŸ“Š Strategy 1: Trying different provider...`);
        const providersTriedRaw = [];
        if (Array.isArray(args.providers_tried)) {
          providersTriedRaw.push(...args.providers_tried);
        }
        if (args.provider_tried) {
          providersTriedRaw.push(args.provider_tried);
        }
        const providersTried = providersTriedRaw.map(normalizeProviderKey).filter(Boolean);
        const providerOrder = VIDEO_PROVIDER_FALLBACK_ORDER;
        const lastTried = providersTried.length > 0 ? providersTried[providersTried.length - 1] : null;
        let startIndex = providerOrder.indexOf(lastTried);
        if (startIndex === -1) {
          startIndex = null;
        }
        const providers = [];
        for (let i = 0; i < providerOrder.length; i++) {
          const index = startIndex === null ? i : (startIndex + 1 + i) % providerOrder.length;
          const candidate = providerOrder[index];
          if (!providersTried.includes(candidate) && !providers.includes(candidate)) {
            providers.push(candidate);
          }
        }
        
        for (const provider of providers) {
          console.log(`   â†’ Attempting with ${provider}...`);
          
          try {
            let result;
            
            if (args.task_type === 'image_creation') {
              // Image generation with different providers
              if (provider === 'openai') {
                result = await openaiService.generateImageForWhatsApp(args.original_prompt);
              } else if (provider === 'grok') {
                result = await grokService.generateImageForWhatsApp(args.original_prompt);
              } else {
                result = await geminiService.generateImageForWhatsApp(args.original_prompt);
              }
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×¢× ${formatProviderName(provider)}!`,
                  imageUrl: result.imageUrl,
                  imageCaption: result.description || result.revisedPrompt || '',
                  strategy_used: 'different_provider',
                  provider: provider
                };
              }
            } else if (args.task_type === 'video_creation') {
              // Video generation with different providers
              const replicateService = require('./replicateService');
              const videoProviderLabelMap = {
                gemini: 'veo3',
                openai: 'sora',
                grok: 'kling'
              };
              
              if (provider === 'gemini') {
                result = await geminiService.generateVideoForWhatsApp(args.original_prompt);
              } else if (provider === 'openai') {
                // Try Sora (OpenAI)
                result = await openaiService.generateVideoWithSoraForWhatsApp(args.original_prompt, null, { model: 'sora-2' });
              } else if (provider === 'grok') {
                // Fallback to Kling via Replicate
                result = await replicateService.generateVideoWithTextForWhatsApp(args.original_prompt);
              } else {
                result = await replicateService.generateVideoWithTextForWhatsApp(args.original_prompt);
              }
              
              if (!result.error) {
                if (args.task_type === 'video_creation') {
                  context.expectedMediaType = null;
                }
                const providerLabel = videoProviderLabelMap[provider] || provider;
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××• ×¢× ${formatProviderName(providerLabel)}! (××¡×˜×¨×˜×’×™×”: ××•×“×œ ×—×œ×•×¤×™)`,
                  videoUrl: result.videoUrl || result.url,
                  strategy_used: 'different_provider',
                  provider: providerLabel
                };
              }
            } else if (args.task_type === 'audio_creation') {
              // Audio/TTS - only one main provider (ElevenLabs)
              // Strategy: Try with different voices or settings
              const voiceService = require('./voiceService');
              result = await voiceService.textToSpeechForBot(args.original_prompt);
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ××•×“×™×•! (××¡×˜×¨×˜×’×™×”: ×”×’×“×¨×•×ª ××©×•×¤×¨×•×ª)`,
                  audioUrl: result.url,
                  strategy_used: 'improved_settings',
                  provider: 'elevenlabs'
                };
              }
            }
          } catch (e) {
            console.log(`   âœ— ${provider} failed: ${e.message}`);
          }
        }
        
        // Strategy 2: Simplify prompt
        console.log(`ğŸ“Š Strategy 2: Simplifying prompt...`);
        const simplifiedPrompt = simplifyPrompt(args.original_prompt);
        
        if (simplifiedPrompt !== args.original_prompt) {
          console.log(`   â†’ Original: "${args.original_prompt}"`);
          console.log(`   â†’ Simplified: "${simplifiedPrompt}"`);
          
          try {
            let result;
            
            if (args.task_type === 'image_creation') {
              result = await geminiService.generateImageForWhatsApp(simplifiedPrompt);
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×¢× ×¤×¨×•××¤×˜ ×¤×©×•×˜ ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×¤×™×©×•×˜)`,
                  imageUrl: result.imageUrl,
                  caption: result.description || '',
                  strategy_used: 'simplified_prompt',
                  original_prompt: args.original_prompt,
                  simplified_prompt: simplifiedPrompt
                };
              }
            } else if (args.task_type === 'video_creation') {
              const replicateService = require('./replicateService');
              result = await replicateService.generateVideoWithTextForWhatsApp(simplifiedPrompt);
              
              if (!result.error) {
                if (args.task_type === 'video_creation') {
                  context.expectedMediaType = null;
                }
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××• ×¢× ×¤×¨×•××¤×˜ ×¤×©×•×˜ ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×¤×™×©×•×˜)`,
                  videoUrl: result.videoUrl || result.url,
                  strategy_used: 'simplified_prompt',
                  original_prompt: args.original_prompt,
                  simplified_prompt: simplifiedPrompt
                };
              }
            } else if (args.task_type === 'audio_creation') {
              const voiceService = require('./voiceService');
              result = await voiceService.textToSpeechForBot(simplifiedPrompt);
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ××•×“×™×• ×¢× ×˜×§×¡×˜ ×¤×©×•×˜ ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×¤×™×©×•×˜)`,
                  audioUrl: result.url,
                  strategy_used: 'simplified_prompt',
                  original_prompt: args.original_prompt,
                  simplified_prompt: simplifiedPrompt
                };
              }
            }
          } catch (e) {
            console.log(`   âœ— Simplified prompt failed: ${e.message}`);
          }
        }
        
        // Strategy 3: Split into smaller tasks (for complex prompts)
        console.log(`ğŸ“Š Strategy 3: Checking if task should be split...`);
        if (shouldSplitTask(args.original_prompt)) {
          const subtasks = splitTaskIntoSteps(args.original_prompt);
          console.log(`   â†’ Split into ${subtasks.length} subtasks`);
          
          return {
            success: false,
            data: `×”×¤×¨×•××¤×˜ ××•×¨×›×‘ ××“×™. ×× ×™ ××¦×™×¢ ×œ×¤×¦×œ ×œ××©×™××•×ª ×§×˜× ×•×ª ×™×•×ª×¨:\n${subtasks.map((t, i) => `${i+1}. ${t}`).join('\n')}`,
            strategy_used: 'suggest_split',
            subtasks: subtasks
          };
        }
        
        // Strategy 4: Try with relaxed parameters (less strict)
        console.log(`ğŸ“Š Strategy 4: Trying with relaxed parameters...`);
        try {
          // For images, try with a more generic/simplified version
          const genericPrompt = makePromptMoreGeneric(args.original_prompt);
          
          if (genericPrompt !== args.original_prompt) {
            console.log(`   â†’ Generic version: "${genericPrompt}"`);
            
            let result;
            
            if (args.task_type === 'image_creation') {
              result = await openaiService.generateImageForWhatsApp(genericPrompt);
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×¢× ×’×¨×¡×” ×›×œ×œ×™×ª ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×”×›×œ×œ×”)`,
                  imageUrl: result.imageUrl,
                  caption: result.description || '',
                  strategy_used: 'generic_prompt',
                  original_prompt: args.original_prompt,
                  generic_prompt: genericPrompt
                };
              }
            } else if (args.task_type === 'video_creation') {
              const replicateService = require('./replicateService');
              result = await replicateService.generateVideoWithTextForWhatsApp(genericPrompt);
              
              if (!result.error) {
                if (args.task_type === 'video_creation') {
                  context.expectedMediaType = null;
                }
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ×•×™×“××• ×¢× ×’×¨×¡×” ×›×œ×œ×™×ª ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×”×›×œ×œ×”)`,
                  videoUrl: result.videoUrl || result.url,
                  strategy_used: 'generic_prompt',
                  original_prompt: args.original_prompt,
                  generic_prompt: genericPrompt
                };
              }
            } else if (args.task_type === 'audio_creation') {
              const voiceService = require('./voiceService');
              result = await voiceService.textToSpeechForBot(genericPrompt);
              
              if (!result.error) {
                return {
                  success: true,
                  data: `âœ… ×”×¦×œ×—×ª×™ ×œ×™×¦×•×¨ ××•×“×™×• ×¢× ×˜×§×¡×˜ ×›×œ×œ×™ ×™×•×ª×¨! (××¡×˜×¨×˜×’×™×”: ×”×›×œ×œ×”)`,
                  audioUrl: result.url,
                  strategy_used: 'generic_prompt',
                  original_prompt: args.original_prompt,
                  generic_prompt: genericPrompt
                };
              }
            }
          }
        } catch (e) {
          console.log(`   âœ— Generic prompt failed: ${e.message}`);
        }
        
        // All strategies failed
        const failureBase = `×›×œ ×”××¡×˜×¨×˜×’×™×•×ª × ×›×©×œ×•:\n1. ×¡×¤×§×™× ×©×•× ×™× âœ—\n2. ×¤×™×©×•×˜ ×¤×¨×•××¤×˜ âœ—\n3. ×¤×¨××˜×¨×™× ×›×œ×œ×™×™× âœ—`;
        const additionalHint = args.task_type === 'video_creation'
          ? '\n\n×”×‘×§×©×” ×”××§×•×¨×™×ª ×“×•×¨×©×ª ×•×™×“××•, ×œ× ×ª××•× ×”. × ×¡×” ×œ× ×¡×— ××—×“×© ××• ×œ×¦×™×™×Ÿ ×¡×’× ×•×Ÿ ××—×¨ ×œ×•×™×“××•.'
          : '\n\n××•×œ×™ ×ª× ×¡×” ×œ× ×¡×— ××ª ×”×‘×§×©×” ××—×¨×ª?';
        return {
          success: false,
          error: `${failureBase}${additionalHint}`
        };
        
      } catch (error) {
        console.error('âŒ Error in smart_execute_with_fallback:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×× ×’× ×•×Ÿ ×”×—×›×: ${error.message}`
        };
      }
    }
  },

  // Tool 7: Retry with different provider (meta-tool)
  retry_with_different_provider: {
    declaration: {
      name: 'retry_with_different_provider',
      description: '× ×¡×” ×œ×™×¦×•×¨ ×ª××•× ×” ××• ×•×™×“××• ×¢× ×¡×¤×§ ××—×¨ ×× ×”×¨××©×•×Ÿ × ×›×©×œ ××• ×œ× ×˜×•×‘. ××œ ×ª×©×ª××© ×‘×›×œ×™ ×”×–×” ×œ×¤× ×™ ×©× ×™×¡×™×ª ×œ×™×¦×•×¨!',
      parameters: {
        type: 'object',
        properties: {
          original_prompt: {
            type: 'string',
            description: '×”×¤×¨×•××¤×˜ ×”××§×•×¨×™ ×œ×™×¦×™×¨×”',
          },
          reason: {
            type: 'string',
            description: '×œ××” ×œ× ×¡×•×ª ×¡×¤×§ ××—×¨ (×œ×“×•×’××”: "×”×ª××•× ×” ×œ× ×˜×•×‘×”")',
          },
          task_type: {
            type: 'string',
            description: '×¡×•×’ ×”××©×™××”: image ××• video',
            enum: ['image', 'video']
          },
          avoid_provider: {
            type: 'string',
            description: '××™×–×” ×¡×¤×§ ×œ× ×œ× ×¡×•×ª (×œ××©×œ: kling, veo3, sora, gemini, openai, grok)',
          }
        },
        required: ['original_prompt', 'reason']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] retry_with_different_provider called for ${args.task_type || 'image'}`);
      
      try {
        const taskType = args.task_type || 'image';
        const avoidProviderRaw = args.avoid_provider;
        const avoidProvider = normalizeProviderKey(avoidProviderRaw);
        
        const { geminiService, openaiService, grokService } = getServices();
        const replicateService = require('./replicateService');
        
        let providers, displayProviders;
        
        if (taskType === 'video') {
          // Video: kling (grok) â†’ veo3 (gemini) â†’ sora (openai)
          context.expectedMediaType = 'video';
          providers = VIDEO_PROVIDER_FALLBACK_ORDER.filter(p => p !== avoidProvider);
          displayProviders = providers.map(p => VIDEO_PROVIDER_DISPLAY_MAP[p] || p);
          
          const errors = [];
          
          for (let i = 0; i < providers.length; i++) {
            const provider = providers[i];
            const displayProvider = displayProviders[i];
            console.log(`ğŸ”„ Trying video provider: ${displayProvider} (${provider})`);
            
            try {
              let result;
              if (provider === 'grok') {
                result = await replicateService.generateVideoWithTextForWhatsApp(args.original_prompt);
              } else if (provider === 'gemini') {
                result = await geminiService.generateVideoForWhatsApp(args.original_prompt);
              } else if (provider === 'openai') {
                result = await openaiService.generateVideoWithSoraForWhatsApp(args.original_prompt);
              }
              
              if (result && !result.error) {
                return {
                  success: true,
                  data: `âœ… × ×™×¡×™×ª×™ ×¢× ${formatProviderName(displayProvider)} ×•×”×¦×œ×—×ª×™!`,
                  videoUrl: result.videoUrl || result.url,
                  caption: result.description || '',
                  provider: displayProvider
                };
              }
              
              errors.push(`${displayProvider}: ${result?.error || 'Unknown error'}`);
              console.log(`âŒ ${displayProvider} failed: ${result?.error}`);
            } catch (providerError) {
              errors.push(`${displayProvider}: ${providerError.message}`);
              console.error(`âŒ ${displayProvider} threw error:`, providerError);
            }
          }
          
          return {
            success: false,
            error: `×›×œ ×”×¡×¤×§×™× × ×›×©×œ×•:\n${errors.join('\n')}`
          };
          
        } else {
          // Image: try providers in order, skipping the one that failed
          const providers = ['gemini', 'openai', 'grok'].filter(p => p !== avoidProvider);
          const errors = [];
          
          for (const provider of providers) {
            console.log(`ğŸ”„ Trying image provider: ${provider}`);
            
            try {
              let imageResult;
              if (provider === 'openai') {
                imageResult = await openaiService.generateImageForWhatsApp(args.original_prompt);
              } else if (provider === 'grok') {
                imageResult = await grokService.generateImageForWhatsApp(args.original_prompt);
              } else {
                imageResult = await geminiService.generateImageForWhatsApp(args.original_prompt);
              }
              
              if (!imageResult.error) {
                return {
                  success: true,
                  data: `âœ… × ×™×¡×™×ª×™ ×¢× ${formatProviderName(provider)} ×•×”×¦×œ×—×ª×™!`,
                  imageUrl: imageResult.imageUrl,
                  caption: imageResult.description || '',
                  provider: provider
                };
              }
              
              errors.push(`${provider}: ${imageResult.error}`);
              console.log(`âŒ ${provider} failed: ${imageResult.error}`);
            } catch (providerError) {
              errors.push(`${provider}: ${providerError.message}`);
              console.error(`âŒ ${provider} threw error:`, providerError);
            }
          }
          
          return {
            success: false,
            error: `×›×œ ×”×¡×¤×§×™× × ×›×©×œ×•:\n${errors.join('\n')}`
          };
        }
      } catch (error) {
        console.error('âŒ Error in retry_with_different_provider tool:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• OPTIMIZED META-TOOLS (Tool Chaining) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // Tool 8: History-aware creation (creates based on chat history context)
  history_aware_create: {
    declaration: {
      name: 'history_aware_create',
      description: '×¦×•×¨ ×ª××•× ×” ××‘×•×¡×¡×ª ×¢×œ ×”×§×©×¨ ××”×”×™×¡×˜×•×¨×™×”. ×××—×“ 2 ×¤×¢×•×œ×•×ª: ×©×œ×™×¤×ª ×”×™×¡×˜×•×¨×™×” + ×™×¦×™×¨×” ×—×›××” ××‘×•×¡×¡×ª context.',
      parameters: {
        type: 'object',
        properties: {
          user_request: {
            type: 'string',
            description: '×”×‘×§×©×” ×©×œ ×”××©×ª××© (×œ×“×•×’××”: "×¦×•×¨ ×ª××•× ×” ×›××• ×‘×¤×¢× ×”×§×•×“××ª")',
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×” (gemini/openai/grok)',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['user_request']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] history_aware_create called`);
      
      try {
        // Step 1: Get chat history
        const history = await conversationManager.getChatHistory(context.chatId, 20);
        
        if (!history || history.length === 0) {
          return {
            success: false,
            error: '××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×–××™× ×” ×œ×™×¦×™×¨×” ××‘×•×¡×¡×ª context'
          };
        }
        
        // Step 2: Build context-aware prompt
        const recentMessages = history.slice(-10).map(msg => 
          `${msg.role}: ${msg.content}`
        ).join('\n');
        
        const enrichedPrompt = `×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×§×©×¨ ×”×‘×:\n${recentMessages}\n\n×‘×§×©×”: ${args.user_request}`;
        
        console.log(`ğŸ¨ Creating with enriched prompt based on history...`);
        
        // Step 3: Create with the enriched prompt
        const provider = args.provider || 'gemini';
        const { geminiService, openaiService, grokService } = getServices();
        
        let result;
        if (provider === 'openai') {
          result = await openaiService.generateImageForWhatsApp(enrichedPrompt);
        } else if (provider === 'grok') {
          result = await grokService.generateImageForWhatsApp(enrichedPrompt);
        } else {
          result = await geminiService.generateImageForWhatsApp(enrichedPrompt);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×” × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×™×¦×¨×ª×™ ×ª××•× ×” ××‘×•×¡×¡×ª ×¢×œ ×”×”×§×©×¨ ××”×”×™×¡×˜×•×¨×™×”!`,
          imageUrl: result.imageUrl,
          caption: result.description || '',
          provider: provider,
          usedHistory: true
        };
      } catch (error) {
        console.error('âŒ Error in history_aware_create:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool 9: Create with long-term memory (uses preferences and summaries)
  create_with_memory: {
    declaration: {
      name: 'create_with_memory',
      description: '×¦×•×¨ ×ª××•× ×”/×ª×•×›×Ÿ ××‘×•×¡×¡ ×¢×œ ×”×¢×“×¤×•×ª ×”××©×ª××© ×•×–×™×›×¨×•×Ÿ ××¨×•×š ×˜×•×•×—. ×××—×“ 2 ×¤×¢×•×œ×•×ª: ×§×¨×™××ª ×”×¢×“×¤×•×ª + ×™×¦×™×¨×” ××•×ª×××ª ××™×©×™×ª.',
      parameters: {
        type: 'object',
        properties: {
          base_prompt: {
            type: 'string',
            description: '×”×¤×¨×•××¤×˜ ×”×‘×¡×™×¡×™ ×œ×™×¦×™×¨×”',
          },
          use_style_preferences: {
            type: 'boolean',
            description: '×”×× ×œ×”×©×ª××© ×‘×”×¢×“×¤×•×ª ×¡×’× ×•×Ÿ ××”×–×™×›×¨×•×Ÿ (×‘×¨×™×¨×ª ××—×“×œ: true)',
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×”',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['base_prompt']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_with_memory called`);
      
      try {
        const usePreferences = args.use_style_preferences !== false;
        
        let finalPrompt = args.base_prompt;
        
        // Step 1: Get user preferences if enabled
        if (usePreferences) {
          const preferences = await conversationManager.getUserPreferences(context.chatId);
          
          if (Object.keys(preferences).length > 0) {
            console.log(`ğŸ§  Applying user preferences:`, preferences);
            
            // Build preference string
            const prefString = Object.entries(preferences)
              .map(([key, value]) => `${key}: ${value}`)
              .join(', ');
            
            finalPrompt = `${args.base_prompt}\n×”×¢×“×¤×•×ª ×¡×’× ×•×Ÿ: ${prefString}`;
          }
        }
        
        // Step 2: Create with personalized prompt
        const provider = args.provider || 'gemini';
        const { geminiService, openaiService, grokService } = getServices();
        
        let result;
        if (provider === 'openai') {
          result = await openaiService.generateImageForWhatsApp(finalPrompt);
        } else if (provider === 'grok') {
          result = await grokService.generateImageForWhatsApp(finalPrompt);
        } else {
          result = await geminiService.generateImageForWhatsApp(finalPrompt);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×” × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×™×¦×¨×ª×™ ×ª××•× ×” ××•×ª×××ª ××™×©×™×ª ×¢×œ ×‘×¡×™×¡ ×”×”×¢×“×¤×•×ª ×©×œ×š!`,
          imageUrl: result.imageUrl,
          caption: result.description || '',
          provider: provider,
          usedPreferences: usePreferences
        };
      } catch (error) {
        console.error('âŒ Error in create_with_memory:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool 10: Search and create (combines web search with image creation)
  search_and_create: {
    declaration: {
      name: 'search_and_create',
      description: '×—×¤×© ××™×“×¢ ×‘××™× ×˜×¨× ×˜ ×•××– ×¦×•×¨ ×ª××•× ×” ××‘×•×¡×¡×ª ×¢×œ ×”××™×“×¢. ×××—×“ 2 ×¤×¢×•×œ×•×ª: ×—×™×¤×•×© + ×™×¦×™×¨×” ××•×©×›×œ×ª.',
      parameters: {
        type: 'object',
        properties: {
          search_query: {
            type: 'string',
            description: '××” ×œ×—×¤×© ×‘××™× ×˜×¨× ×˜',
          },
          creation_goal: {
            type: 'string',
            description: '××” ×œ×™×¦×•×¨ ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×•×¦××•×ª ×”×—×™×¤×•×©',
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×”',
            enum: ['gemini', 'openai', 'grok']
          }
        },
        required: ['search_query', 'creation_goal']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] search_and_create called`);
      
      try {
        // Step 1: Search web
        console.log(`ğŸ” Searching for: ${args.search_query}`);
        const { geminiService } = getServices();
        
        const searchResult = await geminiService.searchWeb(args.search_query);
        
        if (!searchResult || searchResult.error) {
          return {
            success: false,
            error: `×—×™×¤×•×© × ×›×©×œ: ${searchResult?.error || 'Unknown error'}`
          };
        }
        
        // Step 2: Create image based on search results
        const enrichedPrompt = `${args.creation_goal}\n\n××™×“×¢ ×¨×œ×•×•× ×˜×™ ××”××™× ×˜×¨× ×˜: ${searchResult.text?.substring(0, 500) || 'N/A'}`;
        
        console.log(`ğŸ¨ Creating based on search results...`);
        
        const provider = args.provider || 'gemini';
        const { openaiService, grokService } = getServices();
        
        let result;
        if (provider === 'openai') {
          result = await openaiService.generateImageForWhatsApp(enrichedPrompt);
        } else if (provider === 'grok') {
          result = await grokService.generateImageForWhatsApp(enrichedPrompt);
        } else {
          result = await geminiService.generateImageForWhatsApp(enrichedPrompt);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×” × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×—×™×¤×©×ª×™ ×‘××™× ×˜×¨× ×˜ ×•×™×¦×¨×ª×™ ×ª××•× ×” ××‘×•×¡×¡×ª ×¢×œ ×”××™×“×¢ ×©××¦××ª×™!`,
          imageUrl: result.imageUrl,
          caption: result.description || '',
          provider: provider,
          searchUsed: true
        };
      } catch (error) {
        console.error('âŒ Error in search_and_create:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• NEW TOOLS: Video, Music, Audio, Utilities â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // Tool: Create video from text
  create_video: {
    declaration: {
      name: 'create_video',
      description: '×¦×•×¨ ×¡×¨×˜×•×Ÿ ×•×™×“××• ××˜×§×¡×˜. ×ª×•××š ×‘-Veo3 (Google), Sora (OpenAI), Kling (×‘×¨×™×¨×ª ××—×“×œ).',
      parameters: {
        type: 'object',
        properties: {
          prompt: {
            type: 'string',
            description: '×ª×™××•×¨ ×”×¡×¨×˜×•×Ÿ ×”××‘×•×§×©'
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×™×¦×™×¨×ª ×”×•×™×“××•',
            enum: ['veo3', 'sora', 'sora-pro', 'kling']
          }
        },
        required: ['prompt']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_video called with provider: ${args.provider || 'kling'}`);
      
      try {
        const { geminiService, openaiService } = getServices();
        const replicateService = require('./replicateService');
        const provider = args.provider || 'kling';
        context.expectedMediaType = 'video';
        
        let result;
        if (provider === 'veo3') {
          result = await geminiService.generateVideoForWhatsApp(args.prompt);
        } else if (provider === 'sora' || provider === 'sora-pro') {
          const model = provider === 'sora-pro' ? 'sora-2-pro' : 'sora-2';
          result = await openaiService.generateVideoWithSoraForWhatsApp(args.prompt, null, { model });
        } else {
          result = await replicateService.generateVideoWithTextForWhatsApp(args.prompt);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×ª ×•×™×“××• × ×›×©×œ×”: ${result.error}`
          };
        }
        
        const payload = {
          success: true,
          data: `âœ… ×”×•×™×“××• × ×•×¦×¨ ×‘×”×¦×œ×—×” ×¢× ${formatProviderName(provider)}!`,
          videoUrl: result.videoUrl || result.url,
          provider: provider
        };
        context.expectedMediaType = null;
        return payload;
      } catch (error) {
        console.error('âŒ Error in create_video:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Convert image to video
  image_to_video: {
    declaration: {
      name: 'image_to_video',
      description: '×”××¨ ×ª××•× ×” ××”×”×™×¡×˜×•×¨×™×” ×œ×¡×¨×˜×•×Ÿ ×•×™×“××• ××•× ×¤×©. ×¦×¨×™×š ×œ×§×¨×•× ×§×•×“× ×œ-get_chat_history ×œ×§×‘×œ URL ×©×œ ×ª××•× ×”.',
      parameters: {
        type: 'object',
        properties: {
          image_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×ª××•× ×” ×œ×”××¨×”'
          },
          prompt: {
            type: 'string',
            description: '×”× ×—×™×•×ª ×œ×× ×™××¦×™×”'
          },
          provider: {
            type: 'string',
            description: '×¡×¤×§ ×œ×”××¨×”',
            enum: ['veo3', 'sora', 'sora-pro', 'kling']
          }
        },
        required: ['image_url', 'prompt']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] image_to_video called`);
      
      try {
        const { geminiService, openaiService } = getServices();
        const replicateService = require('./replicateService');
        const provider = args.provider || 'kling';
        
        let result;
        if (provider === 'veo3') {
          result = await geminiService.generateVideoFromImageForWhatsApp(args.image_url, args.prompt);
        } else if (provider === 'sora' || provider === 'sora-pro') {
          const model = provider === 'sora-pro' ? 'sora-2-pro' : 'sora-2';
          result = await openaiService.generateVideoWithSoraFromImageForWhatsApp(args.image_url, args.prompt, model);
        } else {
          result = await replicateService.generateVideoFromImageForWhatsApp(args.image_url, args.prompt);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×”××¨×” ×œ×•×™×“××• × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×ª××•× ×” ×”×•××¨×” ×œ×•×™×“××• ×‘×”×¦×œ×—×” ×¢× ${formatProviderName(provider)}!`,
          videoUrl: result.videoUrl || result.url,
          provider: provider
        };
      } catch (error) {
        console.error('âŒ Error in image_to_video:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Analyze video
  analyze_video: {
    declaration: {
      name: 'analyze_video',
      description: '× ×ª×— ×¡×¨×˜×•×Ÿ ×•×™×“××• ××”×”×™×¡×˜×•×¨×™×”. ×¦×¨×™×š ×œ×§×¨×•× ×§×•×“× ×œ-get_chat_history ×œ×§×‘×œ URL ×©×œ ×•×™×“××•.',
      parameters: {
        type: 'object',
        properties: {
          video_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×•×™×“××• ×œ× ×™×ª×•×—'
          },
          question: {
            type: 'string',
            description: '××” ×œ× ×ª×—/×œ×©××•×œ ×¢×œ ×”×•×™×“××•'
          }
        },
        required: ['video_url', 'question']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] analyze_video called`);
      
      try {
        const { geminiService } = getServices();
        
        const result = await geminiService.analyzeVideoWithText(args.video_url, args.question);
        
        if (result.error) {
          return {
            success: false,
            error: `× ×™×ª×•×— ×•×™×“××• × ×›×©×œ: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: result.text || '× ×™×ª×•×— ×”×•×©×œ×',
          analysis: result.text
        };
      } catch (error) {
        console.error('âŒ Error in analyze_video:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Create music
  create_music: {
    declaration: {
      name: 'create_music',
      description: '×¦×•×¨ ×©×™×¨/××•×–×™×§×” ×¢× ××™×œ×™×. ××©×ª××© ×‘-Suno AI.',
      parameters: {
        type: 'object',
        properties: {
          prompt: {
            type: 'string',
            description: '×ª×™××•×¨ ×”×©×™×¨, ×¡×’× ×•×Ÿ, × ×•×©×, ××• ××™×œ×™×'
          },
          make_video: {
            type: 'boolean',
            description: '×”×× ×œ×™×¦×•×¨ ×’× ×•×™×“××•/×§×œ×™×¤ ×œ×©×™×¨ (×× ×”××©×ª××© ×‘×™×§×©)'
          }
        },
        required: ['prompt']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_music called`);
      
      try {
        const { generateMusicWithLyrics } = require('./musicService');
        const { parseMusicRequest } = require('./geminiService');
        
        const originalUserText = context.originalInput?.userText || args.prompt;
        const cleanedOriginal = originalUserText ? String(originalUserText).replace(/^#\s*/, '').trim() : args.prompt;
        
        let cleanPrompt = args.prompt;
        let wantsVideo = Boolean(args.make_video);
        
        try {
          const parsingResult = await parseMusicRequest(cleanedOriginal || args.prompt);
          if (parsingResult?.cleanPrompt) {
            cleanPrompt = parsingResult.cleanPrompt.trim() || cleanPrompt;
          }
          if (parsingResult?.wantsVideo) {
            wantsVideo = true;
          }
        } catch (parseError) {
          console.warn('âš ï¸ create_music: Failed to parse music request for video detection:', parseError.message);
        }
        
        const senderData = context.originalInput?.senderData || {};
        const whatsappContext = context.chatId ? {
          chatId: context.chatId,
          senderId: senderData.senderId || senderData.sender || null,
          senderName: senderData.senderName || senderData.senderContactName || '',
          senderContactName: senderData.senderContactName || '',
          chatName: senderData.chatName || ''
        } : null;
        
        const result = await generateMusicWithLyrics(cleanPrompt, {
          whatsappContext,
          makeVideo: wantsVideo
        });
        
        if (result.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×ª ××•×–×™×§×” × ×›×©×œ×”: ${result.error}`
          };
        }
        
        if (result.status === 'pending') {
          return {
            success: true,
            data: result.message || 'ğŸµ ×™×¦×™×¨×ª ×”×©×™×¨ ×‘×¢×™×¦×•××”! ××©×œ×— ××•×ª×• ××™×“ ×›×©×”×•× ×™×”×™×” ××•×›×Ÿ.',
            status: 'pending',
            taskId: result.taskId || null,
            makeVideo: wantsVideo
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×©×™×¨ × ×•×¦×¨ ×‘×”×¦×œ×—×”!`,
          audioUrl: result.result || result.url,
          lyrics: result.lyrics
        };
      } catch (error) {
        console.error('âŒ Error in create_music:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Transcribe audio
  transcribe_audio: {
    declaration: {
      name: 'transcribe_audio',
      description: '×ª××œ×œ ×”×§×œ×˜×” ×§×•×œ×™×ª ×œ×˜×§×¡×˜ (STT). ×”×©×ª××© ×›×©×”××©×ª××© ××‘×§×© "××” × ×××¨ ×‘×”×§×œ×˜×”?", "×ª××œ×œ ××ª ×–×”", "××” ×›×ª×•×‘?" ×•×›×•\'. × ×“×¨×© audioUrl ×‘×”×•×“×¢×” ×”××¦×•×˜×˜×ª.',
      parameters: {
        type: 'object',
        properties: {
          audio_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×”×§×œ×˜×” ×œ×ª××œ×•×œ. ×—×œ×¥ ××”××‘× ×” "[audioUrl: URL]" ×‘-prompt.'
          }
        },
        required: ['audio_url']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] transcribe_audio called`);
      
      try {
        const axios = require('axios');
        const speechService = require('./speechService');
        const { voiceService } = require('./voiceService');
        
        if (!args.audio_url) {
          return {
            success: false,
            error: '×œ× × ××¦× URL ×©×œ ×”×§×œ×˜×”. ×¦×˜×˜ ×”×•×“×¢×” ×§×•×œ×™×ª ×•× ×¡×” ×©×•×‘.'
          };
        }
        
        // Download audio file
        console.log(`ğŸ“¥ Downloading audio: ${args.audio_url}`);
        const audioResponse = await axios.get(args.audio_url, { responseType: 'arraybuffer' });
        const audioBuffer = Buffer.from(audioResponse.data);
        
        // Transcribe
        console.log(`ğŸ¤ Transcribing audio...`);
        const transcriptionResult = await speechService.speechToText(audioBuffer, {
          response_format: 'verbose_json',
          timestamp_granularities: ['word']
        });
        
        if (transcriptionResult.error) {
          return {
            success: false,
            error: `×ª××œ×•×œ × ×›×©×œ: ${transcriptionResult.error}`
          };
        }
        
        const transcribedText = transcriptionResult.text || '';
        const detectedLanguage = transcriptionResult.detectedLanguage || voiceService.detectLanguage(transcribedText);
        
        console.log(`âœ… Transcribed: "${transcribedText}" (${detectedLanguage})`);
        
        return {
          success: true,
          data: `ğŸ“ ×ª××œ×•×œ:\n\n"${transcribedText}"`,
          transcription: transcribedText,
          language: detectedLanguage
        };
      } catch (error) {
        console.error('âŒ Error in transcribe_audio:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Text to speech
  text_to_speech: {
    declaration: {
      name: 'text_to_speech',
      description: '×”××¨ ×˜×§×¡×˜ ×œ×“×™×‘×•×¨. ××©×ª××© ×‘-ElevenLabs.',
      parameters: {
        type: 'object',
        properties: {
          text: {
            type: 'string',
            description: '×”×˜×§×¡×˜ ×œ×”×§×¨××”'
          },
          language: {
            type: 'string',
            description: '×©×¤×” ×œ×”×§×¨××” (en, he, es, fr, etc.)'
          }
        },
        required: ['text']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] text_to_speech called`);
      
      try {
        const { voiceService } = require('./voiceService');
        
        const language = args.language || 'he';
        const voiceResult = await voiceService.getVoiceForLanguage(language);
        
        if (voiceResult.error) {
          return {
            success: false,
            error: `×œ× × ××¦× ×§×•×œ ×œ×©×¤×”: ${voiceResult.error}`
          };
        }
        
        const ttsResult = await voiceService.textToSpeech(voiceResult.voiceId, args.text, {
          model_id: 'eleven_v3',
          optimize_streaming_latency: 0,
          output_format: 'mp3_44100_128'
        });
        
        if (ttsResult.error) {
          return {
            success: false,
            error: `TTS × ×›×©×œ: ${ttsResult.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×˜×§×¡×˜ ×”×•××¨ ×œ×“×™×‘×•×¨!`,
          audioUrl: ttsResult.audioUrl
        };
      } catch (error) {
        console.error('âŒ Error in text_to_speech:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Chat summary
  chat_summary: {
    declaration: {
      name: 'chat_summary',
      description: '×¦×•×¨ ×¡×™×›×•× ×©×œ ×”×©×™×—×” ×”× ×•×›×—×™×ª. ×©×™××•×©×™ ×œ××©×ª××© ×©×¨×•×¦×” ×¡×™×›×•× ××”×™×¨.',
      parameters: {
        type: 'object',
        properties: {},
        required: []
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] chat_summary called`);
      
      try {
        const { geminiService } = getServices();
        
        const history = await conversationManager.getConversationHistory(context.chatId);
        
        if (!history || history.length === 0) {
          return {
            success: false,
            error: '××™×Ÿ ××¡×¤×™×§ ×”×•×“×¢×•×ª ×œ×¡×™×›×•×'
          };
        }
        
        const summary = await geminiService.generateChatSummary(history);
        
        if (summary.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×ª ×¡×™×›×•× × ×›×©×œ×”: ${summary.error}`
          };
        }
        
        return {
          success: true,
          data: summary.text || summary,
          summary: summary.text || summary
        };
      } catch (error) {
        console.error('âŒ Error in chat_summary:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Create poll
  create_poll: {
    declaration: {
      name: 'create_poll',
      description: '×¦×•×¨ ×¡×§×¨ ×¢× ×©××œ×” ×•×ª×©×•×‘×•×ª ×™×¦×™×¨×ª×™×•×ª.',
      parameters: {
        type: 'object',
        properties: {
          topic: {
            type: 'string',
            description: '× ×•×©× ×”×¡×§×¨'
          }
        },
        required: ['topic']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_poll called`);
      
      try {
        const { geminiService } = getServices();
        
        const pollData = await geminiService.generateCreativePoll(args.topic);
        
        if (pollData.error) {
          return {
            success: false,
            error: `×™×¦×™×¨×ª ×¡×§×¨ × ×›×©×œ×”: ${pollData.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×¡×§×¨ × ×•×¦×¨!`,
          poll: pollData
        };
      } catch (error) {
        console.error('âŒ Error in create_poll:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Send random location
  send_location: {
    declaration: {
      name: 'send_location',
      description: '×©×œ×— ××™×§×•× ××§×¨××™ ××”×¢×•×œ× ×¢× ××™×“×¢ ×¢×œ ×”××§×•×. ××¤×©×¨ ×œ×¦×™×™×Ÿ ××–×•×¨ ×¡×¤×¦×™×¤×™ (×¢×™×¨, ××“×™× ×”, ×™×‘×©×ª).',
      parameters: {
        type: 'object',
        properties: {
          region: {
            type: 'string',
            description: '××–×•×¨ ××•×¤×¦×™×•× ×œ×™ ×œ×‘×—×™×¨×ª ××™×§×•× (×œ××©×œ: "×ª×œ ××‘×™×‘", "× ×™×• ×™×•×¨×§", "×™×¤×Ÿ", "××™×¨×•×¤×”", "××¡×™×”", ×•×›×•\'). ×× ×œ× ××¦×•×™×Ÿ - ××™×§×•× ××§×¨××™ ××”×¢×•×œ×.'
          }
        },
        required: []
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] send_location called with region: ${args.region || 'none'}`);
      const { greenApiService } = getServices();

      try {
        // Use region from args if provided, otherwise try to extract from user prompt
        const regionToSearch = args.region || context?.originalInput?.userText || context?.normalized?.text || '';
        const requestedRegion = await locationService.extractRequestedRegion(regionToSearch);
        const regionAckMessage = locationService.buildLocationAckMessage(requestedRegion);

        if (regionAckMessage && context?.chatId) {
          await greenApiService.sendTextMessage(context.chatId, regionAckMessage);
        }

        const locationResult = await locationService.findRandomLocation({ requestedRegion });
        if (!locationResult.success) {
          const errorMessage = locationResult.error || '×œ× ×”×¦×œ×—×ª×™ ×œ××¦×•× ××™×§×•× ×ª×§×™×Ÿ';
          if (context?.chatId) {
            await greenApiService.sendTextMessage(context.chatId, `âŒ ${errorMessage}`);
          }
          return {
            success: false,
            error: errorMessage
          };
        }

        const latitude = parseFloat(locationResult.latitude);
        const longitude = parseFloat(locationResult.longitude);

        if (Number.isNaN(latitude) || Number.isNaN(longitude)) {
          throw new Error('Invalid coordinates returned from location service');
        }

        return {
          success: true,
          latitude,
          longitude,
          locationInfo: locationResult.description || '',
          data: locationResult.description || '',
          suppressFinalResponse: true
        };
      } catch (error) {
        console.error('âŒ Error in send_location:', error);
        const errorMessage = error?.message || '×©×’×™××” ×œ× ×™×“×•×¢×” ×‘×©×œ×™×—×ª ×”××™×§×•×';
        if (context?.chatId) {
          await greenApiService.sendTextMessage(context.chatId, `âŒ ${errorMessage}`);
        }
        return {
          success: false,
          error: errorMessage
        };
      }
    }
  },

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ADVANCED TOOLS: Editing, Audio, Translation â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // Tool: Edit image
  edit_image: {
    declaration: {
      name: 'edit_image',
      description: '×¢×¨×•×š ×ª××•× ×” ×§×™×™××ª ××”×”×™×¡×˜×•×¨×™×”. ×¦×¨×™×š ×œ×§×¨×•× ×§×•×“× ×œ-get_chat_history ×œ×§×‘×œ URL ×©×œ ×ª××•× ×”.',
      parameters: {
        type: 'object',
        properties: {
          image_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×ª××•× ×” ×œ×¢×¨×™×›×”'
          },
          edit_instruction: {
            type: 'string',
            description: '××” ×œ×¢×¨×•×š ×‘×ª××•× ×” (×”×•×¡×£, ×”×¡×¨, ×©× ×”, etc.)'
          },
          service: {
            type: 'string',
            description: '×¡×¤×§ ×œ×¢×¨×™×›×”',
            enum: ['openai', 'gemini']
          }
        },
        required: ['image_url', 'edit_instruction']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] edit_image called`);
      
      try {
        const { openaiService, geminiService } = getServices();
        const service = args.service || 'openai'; // OpenAI is better for editing
        
        let result;
        if (service === 'openai') {
          result = await openaiService.editImageForWhatsApp(args.image_url, args.edit_instruction);
        } else {
          result = await geminiService.editImageForWhatsApp(args.image_url, args.edit_instruction);
        }
        
        if (result.error) {
          return {
            success: false,
            error: `×¢×¨×™×›×ª ×ª××•× ×” × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×ª××•× ×” × ×¢×¨×›×” ×‘×”×¦×œ×—×” ×¢× ${formatProviderName(service)}!`,
          imageUrl: result.imageUrl,
          caption: result.description || '',
          service: service
        };
      } catch (error) {
        console.error('âŒ Error in edit_image:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Edit video
  edit_video: {
    declaration: {
      name: 'edit_video',
      description: '×¢×¨×•×š ×¡×¨×˜×•×Ÿ ×•×™×“××• ×§×™×™× ××”×”×™×¡×˜×•×¨×™×”. ×¦×¨×™×š ×œ×§×¨×•× ×§×•×“× ×œ-get_chat_history ×œ×§×‘×œ URL ×©×œ ×•×™×“××•.',
      parameters: {
        type: 'object',
        properties: {
          video_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×•×™×“××• ×œ×¢×¨×™×›×”'
          },
          edit_instruction: {
            type: 'string',
            description: '××” ×œ×¢×¨×•×š ×‘×•×•×™×“××•'
          }
        },
        required: ['video_url', 'edit_instruction']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] edit_video called`);
      
      try {
        const replicateService = require('./replicateService');
        
        const result = await replicateService.generateVideoFromVideoForWhatsApp(args.video_url, args.edit_instruction);
        
        if (result.error) {
          return {
            success: false,
            error: `×¢×¨×™×›×ª ×•×™×“××• × ×›×©×œ×”: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”×•×™×“××• × ×¢×¨×š ×‘×”×¦×œ×—×”!`,
          videoUrl: result.videoUrl
        };
      } catch (error) {
        console.error('âŒ Error in edit_video:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Voice clone and speak
  voice_clone_and_speak: {
    declaration: {
      name: 'voice_clone_and_speak',
      description: '×©×‘×˜ ×§×•×œ ××”×§×œ×˜×” ×§×™×™××ª ×•×”×©×ª××© ×‘×• ×›×“×™ ×œ×“×‘×¨ ×˜×§×¡×˜ ×—×“×©. ×¦×¨×™×š URL ×©×œ ×”×§×œ×˜×” (×-get_chat_history).',
      parameters: {
        type: 'object',
        properties: {
          audio_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×”×§×œ×˜×” ×œ×©×™×‘×•×˜ ×”×§×•×œ'
          },
          text_to_speak: {
            type: 'string',
            description: '×”×˜×§×¡×˜ ×©×”×§×•×œ ×”××©×•×‘×˜ ×™×“×‘×¨'
          },
          language: {
            type: 'string',
            description: '×©×¤×ª ×”×“×™×‘×•×¨ (he, en, es, etc.)'
          }
        },
        required: ['audio_url', 'text_to_speak']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] voice_clone_and_speak called`);
      
      try {
        const { voiceService } = require('./voiceService');
        const { greenApiService } = getServices();
        
        // Download audio for cloning
        const audioBuffer = await greenApiService.downloadFile(args.audio_url);
        
        // Clone voice
        const voiceCloneOptions = {
          name: `Agent Voice Clone ${Date.now()}`,
          description: `Voice clone from agent tool`,
          removeBackgroundNoise: true,
          labels: JSON.stringify({
            accent: 'natural',
            use_case: 'conversational',
            quality: 'high',
            language: args.language || 'he'
          })
        };
        
        const cloneResult = await voiceService.createInstantVoiceClone(audioBuffer, voiceCloneOptions);
        
        if (cloneResult.error) {
          return {
            success: false,
            error: `×©×™×‘×•×˜ ×§×•×œ × ×›×©×œ: ${cloneResult.error}`
          };
        }
        
        // Use cloned voice to speak text
        const ttsResult = await voiceService.textToSpeech(cloneResult.voiceId, args.text_to_speak, {
          model_id: 'eleven_v3',
          optimize_streaming_latency: 0,
          output_format: 'mp3_44100_128'
        });
        
        if (ttsResult.error) {
          return {
            success: false,
            error: `×“×™×‘×•×¨ ×¢× ×§×•×œ ××©×•×‘×˜ × ×›×©×œ: ${ttsResult.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×©×™×‘×˜×ª×™ ××ª ×”×§×•×œ ×•×”×•× ××“×‘×¨ ××ª ×”×˜×§×¡×˜ ×©×‘×™×§×©×ª!`,
          audioUrl: ttsResult.audioUrl,
          voiceId: cloneResult.voiceId
        };
      } catch (error) {
        console.error('âŒ Error in voice_clone_and_speak:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Creative audio mix
  creative_audio_mix: {
    declaration: {
      name: 'creative_audio_mix',
      description: '×¦×•×¨ ××™×§×¡ ××•×“×™×• ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™× ×•××•×–×™×§×” ××”×§×œ×˜×” ×§×™×™××ª. ×¦×¨×™×š URL ×©×œ ×”×§×œ×˜×”.',
      parameters: {
        type: 'object',
        properties: {
          audio_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×”×§×œ×˜×” ×œ××™×§×¡'
          },
          style: {
            type: 'string',
            description: '×¡×’× ×•×Ÿ ×”××™×§×¡ (××¤×©×¨×•×™×•×ª: creative, remix, enhance)'
          }
        },
        required: ['audio_url']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] creative_audio_mix called`);
      
      try {
        const { creativeAudioService } = require('./creativeAudioService');
        const { greenApiService } = getServices();
        
        // Download audio
        const audioBuffer = await greenApiService.downloadFile(args.audio_url);
        
        // Create creative mix
        const result = await creativeAudioService.createCreativeMix(audioBuffer, {
          style: args.style || 'creative',
          addMusic: true,
          addEffects: true
        });
        
        if (result.error) {
          return {
            success: false,
            error: `××™×§×¡ ×™×¦×™×¨×ª×™ × ×›×©×œ: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×”××™×§×¡ ×”×™×¦×™×¨×ª×™ × ×•×¦×¨ ×‘×”×¦×œ×—×”!`,
          audioUrl: result.url
        };
      } catch (error) {
        console.error('âŒ Error in creative_audio_mix:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Translate text
  translate_text: {
    declaration: {
      name: 'translate_text',
      description: '×ª×¨×’× ×˜×§×¡×˜ ×œ×©×¤×” ××—×¨×ª (××—×–×™×¨ ×˜×§×¡×˜ ×‘×œ×‘×“). ×× ×”××©×ª××© ××•××¨ "×××•×¨ ×‘×™×¤× ×™×ª" ××• "×ª×¨×’× ×•×××•×¨" - ×”×©×ª××© ×‘-translate_and_speak ×‘××§×•×! ×ª×•××š ×‘-20+ ×©×¤×•×ª.',
      parameters: {
        type: 'object',
        properties: {
          text: {
            type: 'string',
            description: '×”×˜×§×¡×˜ ×œ×ª×¨×’×•×'
          },
          target_language: {
            type: 'string',
            description: '×©×¤×ª ×™×¢×“ (English, Hebrew, Spanish, French, German, Italian, Portuguese, Russian, Chinese, Japanese, Korean, Arabic, Hindi, Turkish, Polish, Dutch, Swedish, Finnish, Norwegian, Danish, Czech)'
          }
        },
        required: ['text', 'target_language']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] translate_text called`);
      
      try {
        const { geminiService } = getServices();
        
        const result = await geminiService.translateText(args.text, args.target_language);
        
        if (result.error) {
          return {
            success: false,
            error: `×ª×¨×’×•× × ×›×©×œ: ${result.error}`
          };
        }
        
        return {
          success: true,
          data: result.translatedText,
          translation: result.translatedText,
          translatedText: result.translatedText,
          provider: result.provider || 'gemini'
        };
      } catch (error) {
        console.error('âŒ Error in translate_text:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Translate and speak
  translate_and_speak: {
    declaration: {
      name: 'translate_and_speak',
      description: '×ª×¨×’× ×˜×§×¡×˜ ×œ×©×¤×” ××—×¨×ª ×•×”××¨ ××•×ª×• ×œ×“×™×‘×•×¨ (××—×–×™×¨ ×”×•×“×¢×” ×§×•×œ×™×ª). ×× ×™×© ×”×§×œ×˜×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª ×‘××‘× ×” ×”-prompt (audioUrl), ×™×© ×œ×—×œ×¥ ××•×ª×” ×•×œ×”×¢×‘×™×¨! ×”×©×ª××© ×›×©×”××©×ª××© ××•××¨ "×××•×¨ X ×‘×™×¤× ×™×ª", "×ª×¨×’× ×œ-Y ×•×××•×¨", "×§×¨× ×‘×¦×¨×¤×ª×™×ª" ×•×›×“\'.',
      parameters: {
        type: 'object',
        properties: {
          text: {
            type: 'string',
            description: '×”×˜×§×¡×˜ ×œ×ª×¨×’×•×'
          },
          target_language: {
            type: 'string',
            description: '×©×¤×ª ×™×¢×“ (English, Hebrew, Spanish, French, German, Italian, Portuguese, Russian, Chinese, Japanese, Korean, Arabic, Hindi, Turkish, Polish, Dutch, Swedish, Finnish, Norwegian, Danish, Czech)'
          },
          quoted_audio_url: {
            type: 'string',
            description: 'URL ×©×œ ×”×§×œ×˜×” ×§×•×œ×™×ª ××¦×•×˜×˜×ª (×× ×§×™×™××ª ×‘-prompt). ×—×œ×¥ ××•×ª×• ××”××‘× ×” "[audioUrl: URL]" ×‘××™×“×” ×•×§×™×™×.'
          }
        },
        required: ['text', 'target_language']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] translate_and_speak called: "${args.text}" -> ${args.target_language}`);
      
      try {
        const { geminiService } = getServices();
        const { voiceService } = require('./voiceService');
        const axios = require('axios');
        
        const MIN_DURATION_FOR_CLONING = 4.6; // seconds
        
        // Step 1: Translate the text
        console.log(`ğŸŒ Translating to ${args.target_language}...`);
        const translationResult = await geminiService.translateText(args.text, args.target_language);
        
        if (translationResult.error || !translationResult.success) {
          return {
            success: false,
            error: `×ª×¨×’×•× × ×›×©×œ: ${translationResult.error || 'Unknown error'}`
          };
        }
        
        const translatedText = translationResult.translatedText;
        console.log(`âœ… Translated: "${translatedText}"`);
        
        // Validate that translated text is not empty
        if (!translatedText || translatedText.trim().length === 0) {
          return {
            success: false,
            error: '×”×ª×¨×’×•× ×”×—×–×™×¨ ×˜×§×¡×˜ ×¨×™×§. ×× × ×¡×¤×§ ×˜×§×¡×˜ ×ª×§×™×Ÿ ×œ×ª×¨×’×•×.'
          };
        }
        
        // Step 2: Get language code for voice selection
        const languageCodeMap = {
          'english': 'en',
          'hebrew': 'he',
          'spanish': 'es',
          'french': 'fr',
          'german': 'de',
          'italian': 'it',
          'portuguese': 'pt',
          'russian': 'ru',
          'chinese': 'zh',
          'japanese': 'ja',
          'korean': 'ko',
          'arabic': 'ar',
          'hindi': 'hi',
          'turkish': 'tr',
          'polish': 'pl',
          'dutch': 'nl',
          'swedish': 'sv',
          'finnish': 'fi',
          'norwegian': 'no',
          'danish': 'da',
          'czech': 'cs'
        };
        
        const targetLanguageCode = languageCodeMap[args.target_language.toLowerCase()] || 'en';
        
        // Step 3: Handle voice selection (clone or random)
        let voiceId = null;
        
        // Check if there's a quoted audio for voice cloning
        if (args.quoted_audio_url) {
          console.log(`ğŸ¤ Quoted audio detected: ${args.quoted_audio_url}`);
          
          try {
            // Download audio file
            const audioResponse = await axios.get(args.quoted_audio_url, { responseType: 'arraybuffer' });
            const audioBuffer = Buffer.from(audioResponse.data);
            
            // Get audio duration
            const audioDuration = await getAudioDuration(audioBuffer);
            
            console.log(`ğŸµ Audio duration: ${audioDuration.toFixed(2)}s (minimum for cloning: ${MIN_DURATION_FOR_CLONING}s)`);
            
            if (audioDuration >= MIN_DURATION_FOR_CLONING) {
              console.log(`ğŸ¤ Attempting voice clone...`);
              
              const voiceCloneResult = await voiceService.cloneVoice({
                name: `Agent Voice Clone ${Date.now()}`,
                description: `Voice clone for translate_and_speak`,
                removeBackgroundNoise: true,
                labels: JSON.stringify({
                  accent: 'natural',
                  use_case: 'conversational',
                  quality: 'high',
                  language: targetLanguageCode
                })
              }, audioBuffer);
              
              if (voiceCloneResult.error) {
                console.log(`âš ï¸ Voice cloning failed: ${voiceCloneResult.error}, using random voice`);
              } else {
                voiceId = voiceCloneResult.voiceId;
                console.log(`âœ… Voice cloned successfully: ${voiceId}`);
              }
            } else {
              console.log(`â­ï¸ Audio too short for cloning (${audioDuration.toFixed(2)}s < ${MIN_DURATION_FOR_CLONING}s), using random voice`);
            }
          } catch (cloneError) {
            console.log(`âš ï¸ Error during voice cloning process: ${cloneError.message}, using random voice`);
          }
        }
        
        // If voice wasn't cloned, get random voice for target language
        if (!voiceId) {
          console.log(`ğŸ¤ Getting random voice for language: ${targetLanguageCode}...`);
          const voiceResult = await voiceService.getVoiceForLanguage(targetLanguageCode);
          
          if (voiceResult.error) {
            return {
              success: false,
              error: `×œ× × ××¦× ×§×•×œ ×œ×©×¤×”: ${voiceResult.error}`
            };
          }
          
          voiceId = voiceResult.voiceId;
        }
        
        // Step 4: Convert to speech
        console.log(`ğŸ—£ï¸ Converting to speech with voice ${voiceId}...`);
        const ttsResult = await voiceService.textToSpeech(voiceId, translatedText, {
          model_id: 'eleven_v3',
          optimize_streaming_latency: 0,
          output_format: 'mp3_44100_128',
          language_code: targetLanguageCode
        });
        
        if (ttsResult.error) {
          return {
            success: false,
            error: `TTS × ×›×©×œ: ${ttsResult.error}`
          };
        }
        
        return {
          success: true,
          data: `âœ… ×ª×•×¨×’× ×œ-${args.target_language} ×•×”×•××¨ ×œ×“×™×‘×•×¨!`,
          audioUrl: ttsResult.audioUrl,
          translatedText: translatedText
        };
      } catch (error) {
        console.error('âŒ Error in translate_and_speak:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },

  // Tool: Create group
  create_group: {
    declaration: {
      name: 'create_group',
      description: '×¦×•×¨ ×§×‘×•×¦×ª WhatsApp ×—×“×©×” ×¢× ××©×ª×ª×¤×™×. ×–××™×Ÿ ×¨×§ ×œ××©×ª××©×™× ××•×¨×©×™×.',
      parameters: {
        type: 'object',
        properties: {
          group_name: {
            type: 'string',
            description: '×©× ×”×§×‘×•×¦×”'
          },
          participants_description: {
            type: 'string',
            description: '×ª×™××•×¨ ×”××©×ª×ª×¤×™× (×œ××©×œ: "×›×œ ×—×‘×¨×™ ×”××©×¤×—×”", "×¦×•×•×ª ×”×¢×‘×•×“×”", ×•×›×•\')'
          }
        },
        required: ['group_name']
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] create_group called`);
      
      try {
        const chatId = context.chatId;
        if (!chatId) {
          return {
            success: false,
            error: '×œ× × ××¦× chatId ×¢×‘×•×¨ ×™×¦×™×¨×ª ×”×§×‘×•×¦×”'
          };
        }
        
        const senderData = context.originalInput?.senderData || {};
        const senderId = senderData.senderId || senderData.sender;
        const senderName = senderData.senderName || senderData.senderContactName || senderId || '×”××©×ª××©';
        
        const { parseGroupCreationPrompt, resolveParticipants } = require('./groupService');
        const { createGroup, setGroupPicture, sendTextMessage } = require('./greenApiService');
        const { generateImageForWhatsApp } = require('./geminiService');
        const fs = require('fs');
        const path = require('path');
        
        // Use the original user request to extract group details (falls back to args.group_name)
        const rawPrompt = (context.originalInput?.userText || args.group_name || '').replace(/^#\s*/, '').trim();
        const promptForParsing = rawPrompt || args.participants_description || args.group_name;
        
        console.log(`ğŸ“‹ Parsing group creation request from: "${promptForParsing}"`);
        
        await sendTextMessage(chatId, 'ğŸ‘¥ ××ª×—×™×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”...');
        await sendTextMessage(chatId, 'ğŸ” ×× ×ª×— ××ª ×”×‘×§×©×”...');
        
        const parsed = await parseGroupCreationPrompt(promptForParsing);
        
        let statusMsg = `ğŸ“‹ ×©× ×”×§×‘×•×¦×”: "${parsed.groupName}"\nğŸ‘¥ ××—×¤×© ${parsed.participants.length} ××©×ª×ª×¤×™×...`;
        if (parsed.groupPicture) {
          statusMsg += `\nğŸ¨ ×ª××•× ×”: ${parsed.groupPicture}`;
        }
        await sendTextMessage(chatId, statusMsg);
        
        const resolution = await resolveParticipants(parsed.participants);
        
        if (resolution.notFound.length > 0) {
          let errorMsg = `âš ï¸ ×œ× ××¦××ª×™ ××ª ×”××©×ª×ª×¤×™× ×”×‘××™×:\n`;
          resolution.notFound.forEach(name => {
            errorMsg += `â€¢ ${name}\n`;
          });
          errorMsg += `\nğŸ’¡ ×˜×™×¤: ×•×•×“× ×©×”×©××•×ª × ×›×•× ×™× ××• ×”×¨×¥ "×¢×“×›×Ÿ ×× ×©×™ ×§×©×¨" ×œ×¡× ×›×¨×•×Ÿ ×× ×©×™ ×§×©×¨`;
          
          if (resolution.resolved.length === 0) {
            await sendTextMessage(chatId, errorMsg + '\n\nâŒ ×œ× × ××¦××• ××©×ª×ª×¤×™× - ×‘×™×˜×•×œ ×™×¦×™×¨×ª ×§×‘×•×¦×”');
            return {
              success: false,
              error: '×œ× × ××¦××• ××©×ª×ª×¤×™× ×ª×•×××™× ×œ×™×¦×™×¨×ª ×”×§×‘×•×¦×”'
            };
          }
          
          await sendTextMessage(chatId, errorMsg);
        }
        
        if (resolution.resolved.length > 0) {
          let foundMsg = `âœ… × ××¦××• ${resolution.resolved.length} ××©×ª×ª×¤×™×:\n`;
          resolution.resolved.forEach(p => {
            foundMsg += `â€¢ ${p.searchName} â†’ ${p.contactName}\n`;
          });
          await sendTextMessage(chatId, foundMsg);
        }
        
        await sendTextMessage(chatId, 'ğŸ”¨ ×™×•×¦×¨ ××ª ×”×§×‘×•×¦×”...');
        
        const participantIds = resolution.resolved
          .map(p => p.contactId)
          .filter(id => id && id !== senderId);
        
        if (participantIds.length === 0) {
          await sendTextMessage(chatId, 'âš ï¸ ×œ× × ××¦××• ××©×ª×ª×¤×™× × ×•×¡×¤×™× (×—×•×¥ ×××š). ×¦×¨×™×š ×œ×¤×—×•×ª ××©×ª×ª×£ ××—×“ × ×•×¡×£ ×œ×™×¦×™×¨×ª ×§×‘×•×¦×”.');
          return {
            success: false,
            error: '×œ× × ××¦××• ××©×ª×ª×¤×™× × ×•×¡×¤×™× ×œ×™×¦×™×¨×ª ×”×§×‘×•×¦×”'
          };
        }
        
        const groupResult = await createGroup(parsed.groupName, participantIds);
        await sendTextMessage(chatId, `âœ… ×”×§×‘×•×¦×” "${parsed.groupName}" × ×•×¦×¨×” ×‘×”×¦×œ×—×”!`);
        
        if (parsed.groupPicture && groupResult.chatId) {
          try {
            await sendTextMessage(chatId, `ğŸ¨ ×™×•×¦×¨ ×ª××•× ×ª ×¤×¨×•×¤×™×œ ×œ×§×‘×•×¦×”...\n"${parsed.groupPicture}"`);
            
            const imageResult = await generateImageForWhatsApp(parsed.groupPicture);
            
            if (imageResult.success && imageResult.fileName) {
              const imagePath = path.join(__dirname, '..', 'public', 'tmp', imageResult.fileName);
              
              if (fs.existsSync(imagePath)) {
                const imageBuffer = fs.readFileSync(imagePath);
                await sendTextMessage(chatId, 'ğŸ–¼ï¸ ××¢×œ×” ×ª××•× ×” ×œ×§×‘×•×¦×”...');
                await setGroupPicture(groupResult.chatId, imageBuffer);
                await sendTextMessage(chatId, 'âœ… ×ª××•× ×ª ×”×§×‘×•×¦×” ×¢×•×“×›× ×” ×‘×”×¦×œ×—×”!');
              } else {
                console.warn(`âš ï¸ Generated group image not found at ${imagePath}`);
              }
            } else if (imageResult.error) {
              await sendTextMessage(chatId, `âš ï¸ ×”×§×‘×•×¦×” × ×•×¦×¨×”, ××‘×œ ×”×™×™×ª×” ×‘×¢×™×” ×‘×™×¦×™×¨×ª ×”×ª××•× ×”: ${imageResult.error}`);
            }
          } catch (pictureError) {
            console.error('âŒ Failed to set group picture:', pictureError);
            await sendTextMessage(chatId, `âš ï¸ ×”×§×‘×•×¦×” × ×•×¦×¨×”, ××‘×œ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×¢×œ×•×ª ×ª××•× ×”: ${pictureError.message}`);
          }
        }
        
        const summaryLines = [
          `âœ… ×”×§×‘×•×¦×” "${parsed.groupName}" ××•×›× ×”!`,
          `ğŸ‘¤ ×™×•×¦×¨: ${senderName}`,
          `ğŸ‘¥ ××©×ª×ª×¤×™×: ${resolution.resolved.length}`,
          groupResult.chatId ? `ğŸ†” ××–×”×” ×§×‘×•×¦×”: ${groupResult.chatId}` : null,
          groupResult.groupInviteLink ? `ğŸ”— ×œ×™× ×§ ×”×–×× ×”: ${groupResult.groupInviteLink}` : null
        ].filter(Boolean);
        
        return {
          success: true,
          data: '',
          groupId: groupResult.chatId || null,
          groupInviteLink: groupResult.groupInviteLink || null,
          participantsAdded: resolution.resolved.length,
          suppressFinalResponse: true
        };
      } catch (error) {
        console.error('âŒ Error in create_group:', error);
        return {
          success: false,
          error: `×©×’×™××”: ${error.message}`
        };
      }
    }
  },
  
  // Tool 27: Retry last command
  retry_last_command: {
    declaration: {
      name: 'retry_last_command',
      description: '×—×–×•×¨ ×¢×œ ×”×¤×§×•×“×” ×”××—×¨×•× ×” ×©×œ ×”××©×ª××©, ×¢× ××¤×©×¨×•×ª ×œ×©× ×•×ª ×¡×¤×§ ××• ×¤×¨××˜×¨×™×. ×”×©×ª××© ×›×©×”××©×ª××© ××•××¨ "× ×¡×” ×©×•×‘", "×©×•×‘", "×¢× OpenAI", "×¢× Gemini", "×ª×§×Ÿ", ×•×›×•\'.',
      parameters: {
        type: 'object',
        properties: {
          provider_override: {
            type: 'string',
            enum: ['gemini', 'openai', 'grok', 'sora', 'veo3', 'kling', 'runway', 'none'],
            description: '×¡×¤×§ ×—×œ×•×¤×™ ×œ×”×©×ª××© (×× ×”××©×ª××© ×‘×™×§×©). none = ××™×Ÿ ×©×™× ×•×™'
          },
          modifications: {
            type: 'string',
            description: '×©×™× ×•×™×™× ××• ×”×•×¨××•×ª × ×•×¡×¤×•×ª ××”××©×ª××© (×œ××©×œ: "×¢× ×©×™×¢×¨ ××¨×•×š", "×‘×œ×™ ××©×§×¤×™×™×")'
          }
        },
        required: []
      }
    },
    execute: async (args, context) => {
      console.log(`ğŸ”§ [Agent Tool] retry_last_command called with provider: ${args.provider_override || 'none'}`);
      
      try {
        // Get last command from DB
        const lastCommand = await conversationManager.getLastCommand(context.chatId);
        
        if (!lastCommand) {
          return {
            success: false,
            error: '××™×Ÿ ×¤×§×•×“×” ×§×•×“××ª ×œ×—×–×•×¨ ×¢×œ×™×”. ×–×• ×”×¤×¢× ×”×¨××©×•× ×” ×©××ª×” ××‘×§×© ××©×”×•.'
          };
        }
        
        console.log(`ğŸ”„ Last command: ${lastCommand.tool} with args:`, lastCommand.args);
        
        // Map tool names to appropriate retry function
        const tool = lastCommand.tool;
        const storedWrapper = lastCommand.args || {};
        const originalArgs = (storedWrapper && storedWrapper.toolArgs)
          ? storedWrapper.toolArgs
          : storedWrapper || {};
        const storedResult = (storedWrapper && storedWrapper.result) ? storedWrapper.result : {};
        
        // Build modified prompt if needed
        let modifiedPrompt = originalArgs.prompt || originalArgs.text || storedResult.translation || storedResult.translatedText || '';
        if (args.modifications && args.modifications.trim()) {
          modifiedPrompt = modifiedPrompt
            ? `${modifiedPrompt} ${args.modifications}`
            : args.modifications;
        }
        modifiedPrompt = (modifiedPrompt || '').toString().trim();
        
        // Determine provider override
        let provider = args.provider_override;
        if (provider === 'none' || !provider) {
          // Keep original provider if exists
          provider = originalArgs.provider || originalArgs.service;
        }
        
        // Route to appropriate tool based on last command
        if (tool === 'gemini_image' || tool === 'openai_image' || tool === 'grok_image' || tool === 'create_image') {
          // Image generation retry
          const promptToUse = modifiedPrompt || originalArgs.prompt || originalArgs.text || storedResult.prompt || '';
          if (!promptToUse) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ×©×—×–×¨ ××ª ×”×¤×¨×•××¤×˜ ×©×œ ×”×¤×§×•×“×” ×”×§×•×“××ª.'
            };
          }
          
          const imageArgs = {
            prompt: promptToUse,
            provider: provider || 'gemini'
          };
          
          console.log(`ğŸ¨ Retrying image generation with:`, imageArgs);
          return await agentTools.create_image.execute(imageArgs, context);
          
        } else if (tool === 'veo3_video' || tool === 'sora_video' || tool === 'kling_text_to_video' || tool === 'create_video') {
          // Video generation retry
          const promptToUse = modifiedPrompt || originalArgs.prompt || originalArgs.text || storedResult.prompt || '';
          if (!promptToUse) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ×©×—×–×¨ ××ª ×”×¤×¨×•××¤×˜ ×©×œ ×”×¤×§×•×“×” ×”×§×•×“××ª ×œ×•×™×“××•.'
            };
          }
          
          const videoArgs = {
            prompt: promptToUse,
            provider: provider || 'kling'
          };
          
          console.log(`ğŸ¬ Retrying video generation with:`, videoArgs);
          return await agentTools.create_video.execute(videoArgs, context);
          
        } else if (tool === 'gemini_chat' || tool === 'openai_chat' || tool === 'grok_chat') {
          // Chat retry
          const chatProvider = provider || (tool.includes('openai') ? 'openai' : tool.includes('grok') ? 'grok' : 'gemini');
          
          // For chat, we need to use the appropriate service directly
          const { geminiService, openaiService, grokService } = getServices();
          
          let result;
          if (chatProvider === 'openai') {
            result = await openaiService.generateTextResponse(modifiedPrompt, []);
          } else if (chatProvider === 'grok') {
            result = await grokService.generateTextResponse(modifiedPrompt, []);
          } else {
            result = await geminiService.generateTextResponse(modifiedPrompt, []);
          }
          
          return {
            success: !result.error,
            data: result.text || result.error,
            error: result.error
          };
          
        } else if (tool === 'text_to_speech') {
          // TTS retry
          const textToSpeak = modifiedPrompt || originalArgs.text || storedResult.translation || storedResult.translatedText;
          if (!textToSpeak) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ×©×—×–×¨ ××ª ×”×˜×§×¡×˜ ×œ×”××¨×” ×œ×“×™×‘×•×¨.'
            };
          }
          return await agentTools.text_to_speech.execute({
            text: textToSpeak,
            target_language: originalArgs.target_language || originalArgs.language || 'he'
          }, context);
          
        } else if (tool === 'music_generation' || tool === 'create_music') {
          // Music retry
          const promptToUse = modifiedPrompt || originalArgs.prompt || storedResult.prompt || originalArgs.text || '';
          if (!promptToUse) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ×©×—×–×¨ ××ª ×”×¤×¨×•××¤×˜ ×œ×™×¦×™×¨×ª ×”××•×–×™×§×”.'
            };
          }
          return await agentTools.create_music.execute({
            prompt: promptToUse
          }, context);
          
        } else if (tool === 'translate_text') {
          const translationArgs = {
            text: originalArgs.text || storedResult.originalText || originalArgs.prompt || '',
            target_language: originalArgs.target_language || originalArgs.language || storedResult.target_language || storedResult.language || 'he'
          };
          
          if (!translationArgs.text || !translationArgs.target_language) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ××—×–×¨ ××ª ×”×˜×§×¡×˜ ××• ××ª ×©×¤×ª ×”×™×¢×“ ×©×œ ×”×¤×§×•×“×” ×”×§×•×“××ª.'
            };
          }
          
          return await agentTools.translate_text.execute(translationArgs, context);
          
        } else if (tool === 'create_poll') {
          // Poll retry
          const topicToUse = modifiedPrompt || originalArgs.topic || originalArgs.prompt || '';
          if (!topicToUse) {
            return {
              success: false,
              error: '×œ× ×”×¦×œ×—×ª×™ ×œ×©×—×–×¨ ××ª × ×•×©× ×”×¡×§×¨ ×”×§×•×“×.'
            };
          }
          return await agentTools.create_poll.execute({
            topic: topicToUse
          }, context);
          
        } else {
          // Generic retry - just return info about what was done
          return {
            success: true,
            data: `×”×¤×§×•×“×” ×”××—×¨×•× ×” ×”×™×™×ª×”: ${tool}\n\n×œ× ×™×›×•×œ ×œ×—×–×•×¨ ×¢×œ×™×” ××•×˜×•××˜×™×ª, ××‘×œ ××ª×” ×™×›×•×œ ×œ×‘×§×© ××•×ª×” ×©×•×‘ ×™×©×™×¨×•×ª.`,
            lastTool: tool,
            lastArgs: originalArgs
          };
        }
        
      } catch (error) {
        console.error('âŒ Error in retry_last_command:', error);
        return {
          success: false,
          error: `×©×’×™××” ×‘×‘×™×¦×•×¢ ×—×•×–×¨: ${error.message}`
        };
      }
    }
  }
};

/**
 * Map tool names to Hebrew Ack messages
 */
const TOOL_ACK_MESSAGES = {
  // Creation tools
  'create_image': '×™×•×¦×¨ ×ª××•× ×”... ğŸ¨',
  'create_video': '×™×•×¦×¨ ×•×™×“××•... ğŸ¬',
  'image_to_video': '×××™×¨ ×ª××•× ×” ×œ×•×™×“××• ××•× ×¤×©... ğŸï¸',
  'create_music': '×™×•×¦×¨ ××•×–×™×§×”... ğŸµ',
  'text_to_speech': '×××™×¨ ×œ×“×™×‘×•×¨... ğŸ¤',
  
  // Analysis tools
  'analyze_image_from_history': '×× ×ª×— ×ª××•× ×”... ğŸ”',
  'analyze_video': '×× ×ª×— ×•×™×“××•... ğŸ¥',
  
  // Edit tools
  'edit_image': '×¢×•×¨×š ×ª××•× ×”... âœï¸',
  'edit_video': '×¢×•×¨×š ×•×™×“××•... ğŸï¸',
  
  // Info tools
  'search_web': '××—×¤×© ×‘××™× ×˜×¨× ×˜... ğŸ”',
  'get_chat_history': '×©×•×œ×£ ×”×™×¡×˜×•×¨×™×”... ğŸ“œ',
  'get_long_term_memory': '×‘×•×“×§ ×”×¢×“×¤×•×ª... ğŸ’¾',
  'translate_text': '××ª×¨×’×... ğŸŒ',
  'translate_and_speak': '××ª×¨×’× ×•×”×•×¤×š ×œ×“×™×‘×•×¨... ğŸŒğŸ—£ï¸',
  'transcribe_audio': '××ª××œ×œ ×”×§×œ×˜×”... ğŸ¤ğŸ“',
  'chat_summary': '××¡×›× ×©×™×—×”... ğŸ“',
  
  // WhatsApp tools
  'create_poll': '×™×•×¦×¨ ×¡×§×¨... ğŸ“Š',
  'send_location': '',
  'create_group': '×™×•×¦×¨ ×§×‘×•×¦×”... ğŸ‘¥',
  
  // Audio tools
  'voice_clone_and_speak': '××©×›×¤×œ ×§×•×œ... ğŸ™ï¸',
  'creative_audio_mix': '××¢×¨×‘×‘ ××•×“×™×•... ğŸ§',
  
  // Meta-tools
  'history_aware_create': '×™×•×¦×¨ ×¢× context... ğŸ§ ',
  'create_with_memory': '×™×•×¦×¨ ×œ×¤×™ ×”×¢×“×¤×•×ª... ğŸ’¡',
  'search_and_create': '××—×¤×© ×•×™×•×¦×¨... ğŸ”â¡ï¸ğŸ¨',
  'create_and_analyze': '×™×•×¦×¨ ×•×× ×ª×—... ğŸ¨â¡ï¸ğŸ”',
  'analyze_and_edit': '×× ×ª×— ×•×¢×•×¨×š... ğŸ”â¡ï¸âœï¸',
  'smart_execute_with_fallback': '×× ×¡×” ×¢× __PROVIDER__... ğŸ”„',
  'retry_with_different_provider': '×× ×¡×” ×¢× __PROVIDER__... ğŸ”',
  'retry_last_command': '×—×•×–×¨ ×¢×œ ×¤×§×•×“×” ×§×•×“××ª... â†©ï¸',
  
  // Preferences
  'save_user_preference': '×©×•××¨ ×”×¢×“×¤×”... ğŸ’¾'
};

const VIDEO_PROVIDER_FALLBACK_ORDER = ['grok', 'gemini', 'openai'];
const VIDEO_PROVIDER_DISPLAY_MAP = {
  grok: 'kling',
  gemini: 'veo3',
  openai: 'sora-2'
};

const normalizeProviderKey = (provider) => {
  if (!provider) return null;
  const key = String(provider).toLowerCase();
  const mapping = {
    kling: 'grok',
    'kling-text-to-video': 'grok',
    grok: 'grok',
    veo3: 'gemini',
    veo: 'gemini',
    gemini: 'gemini',
    google: 'gemini',
    'google-veo3': 'gemini',
    sora: 'openai',
    'sora-2': 'openai',
    'sora2': 'openai',
    'sora-2-pro': 'openai',
    'sora-pro': 'openai',
    openai: 'openai'
  };
  return mapping[key] || key;
};

const applyProviderToMessage = (message, providerName) => {
  if (message.includes('__PROVIDER__')) {
    return message.replace('__PROVIDER__', providerName || '×¡×¤×§ ××—×¨');
  }
  if (providerName) {
    if (message.includes('...')) {
      return message.replace('...', ` ×¢× ${providerName}...`).replace('  ', ' ');
    }
    return `${message} (${providerName})`;
  }
  return message;
};

/**
 * Send Ack message to user based on tools being executed
 * @param {string} chatId - Chat ID
 * @param {Array} functionCalls - Array of function calls (with name and args)
 */
async function sendToolAckMessage(chatId, functionCalls) {
  if (!chatId || !functionCalls || functionCalls.length === 0) return;
  
  try {
    let ackMessage = '';
    
    // Helper to build Ack message for a single tool
    const buildSingleAck = (call) => {
      const toolName = call.name;
      if (toolName === 'send_location') {
        return '';
      }
      let baseMessage = TOOL_ACK_MESSAGES[toolName] || `××‘×¦×¢: ${toolName}... âš™ï¸`;
      
      // Check if this tool uses a provider (direct or nested)
      const providerRaw = call.args?.provider;
      let provider = normalizeProviderKey(providerRaw);
      
      if (!provider && toolName === 'smart_execute_with_fallback') {
        const providersTriedRaw = [];
        if (Array.isArray(call.args?.providers_tried)) {
          providersTriedRaw.push(...call.args.providers_tried);
        }
        if (call.args?.provider_tried) {
          providersTriedRaw.push(call.args.provider_tried);
        }
        const providersTried = providersTriedRaw.map(normalizeProviderKey).filter(Boolean);
        const availableProviders = VIDEO_PROVIDER_FALLBACK_ORDER.filter(p => !providersTried.includes(p));
        provider = availableProviders[0] || null;
      }
      
      if (!provider && toolName === 'retry_with_different_provider') {
        const avoidRaw = call.args?.avoid_provider;
        const avoidProvider = normalizeProviderKey(avoidRaw) || 'gemini';
        const providerSequence = VIDEO_PROVIDER_FALLBACK_ORDER;
        const avoidIndex = providerSequence.indexOf(avoidProvider);
        if (avoidIndex === -1) {
          provider = providerSequence[0];
        } else {
          provider = providerSequence[(avoidIndex + 1) % providerSequence.length];
        }
      }
      
      let providerDisplayKey = providerRaw || provider;
      const isVideoTask = call.args?.task_type === 'video_creation' || toolName === 'create_video';
      if (isVideoTask) {
        const normalizedKey = normalizeProviderKey(providerDisplayKey);
        if (normalizedKey && VIDEO_PROVIDER_DISPLAY_MAP[normalizedKey]) {
          providerDisplayKey = VIDEO_PROVIDER_DISPLAY_MAP[normalizedKey];
        } else if (!providerRaw && provider && VIDEO_PROVIDER_DISPLAY_MAP[provider]) {
          providerDisplayKey = VIDEO_PROVIDER_DISPLAY_MAP[provider];
        }
      }
      
      const providerName = providerDisplayKey ? formatProviderName(providerDisplayKey) : null;
      baseMessage = applyProviderToMessage(baseMessage, providerName);
      
      return baseMessage;
    };
    
    if (functionCalls.length === 1) {
      const singleAck = buildSingleAck(functionCalls[0]);
      if (!singleAck || !singleAck.trim()) {
        return;
      }
      ackMessage = singleAck;
    } else if (functionCalls.length === 2) {
      const acks = functionCalls
        .map(buildSingleAck)
        .filter(msg => msg && msg.trim());
      if (acks.length === 0) {
        return;
      }
      ackMessage = `××‘×¦×¢:\nâ€¢ ${acks.join('\nâ€¢ ')}`;
    } else {
      // Multiple tools - generic message
      const acks = functionCalls
        .map(buildSingleAck)
        .filter(msg => msg && msg.trim());
      if (acks.length === 0) {
        return;
      }
      ackMessage = `××‘×¦×¢ ${acks.length} ×¤×¢×•×œ×•×ª... âš™ï¸`;
    }
    
    if (!ackMessage || !ackMessage.trim()) {
      return;
    }
    
    console.log(`ğŸ“¢ [ACK] Sending acknowledgment: "${ackMessage}"`);
    const { greenApiService } = getServices();
    await greenApiService.sendTextMessage(chatId, ackMessage);
  } catch (error) {
    console.error('âŒ [ACK] Failed to send acknowledgment:', error.message);
    // Don't throw - Ack failure shouldn't break the agent
  }
}

/**
 * Execute an agent query with autonomous tool usage
 * @param {string} prompt - User's question/request
 * @param {string} chatId - Chat ID for context
 * @param {Object} options - Additional options
 * @returns {Object} - Response with text and tool usage info
 */
async function executeAgentQuery(prompt, chatId, options = {}) {
  console.log(`ğŸ¤– [Agent] Starting autonomous query: "${prompt.substring(0, 100)}..."`);
  
  // âš™ï¸ Configuration: Load from env or use defaults
  const agentConfig = {
    model: process.env.AGENT_MODEL || 'gemini-2.5-flash',
    maxIterations: Number(process.env.AGENT_MAX_ITERATIONS) || 5,
    timeoutMs: Number(process.env.AGENT_TIMEOUT_MS) || 180000, // 3 minutes for complex multi-step tasks
    contextMemoryEnabled: String(process.env.AGENT_CONTEXT_MEMORY_ENABLED || 'false').toLowerCase() === 'true'
  };
  
  const maxIterations = options.maxIterations || agentConfig.maxIterations;
  const model = genAI.getGenerativeModel({ model: agentConfig.model });
  
  // Prepare tool declarations for Gemini
  const functionDeclarations = Object.values(agentTools).map(tool => tool.declaration);
  
  // System prompt for the agent (Hebrew - optimized and consistent)
  const systemInstruction = `××ª×” ×¢×•×–×¨ AI ××•×˜×•× ×•××™ ×¢× ×’×™×©×” ×œ×›×œ×™× ××ª×§×“××™×.

ğŸš« ××¡×•×¨ ×œ×—×œ×•×˜×™×Ÿ:
â€¢ ×œ×›×ª×•×‘ ××ª ×ª×”×œ×™×š ×”×—×©×™×‘×” ×©×œ×š
â€¢ ×œ×›×ª×•×‘ ×‘×× ×’×œ×™×ª ("My thoughts", "I need to", "Let me")
â€¢ ×œ×›×ª×•×‘ ×¨×©×™××•×ª ×©×œ ××” ××ª×” ×¢×•×©×”
â€¢ ×¨×§ ×ª×©×•×‘×” ×¡×•×¤×™×ª ×‘×¢×‘×¨×™×ª!

ğŸ› ï¸ ×”×›×œ×™× ×©×œ×š (30 ×›×œ×™×!):

ğŸ“š ××™×“×¢:
â€¢ get_chat_history - ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” (×—×•×‘×” ×œ×©××œ×•×ª context!)
â€¢ save_user_preference - ×©××•×¨ ×”×¢×“×¤×•×ª ××©×ª××©
â€¢ get_long_term_memory - ×§×¨× ×”×¢×“×¤×•×ª ××©×ª××©
â€¢ search_web - ××™×“×¢ ××”××™× ×˜×¨× ×˜
â€¢ chat_summary - ×¡×™×›×•× ×”×©×™×—×”
â€¢ translate_text - ×ª×¨×’×•× (22 ×©×¤×•×ª) â†’ ××—×–×™×¨ ×˜×§×¡×˜ ×‘×œ×‘×“!
â€¢ translate_and_speak - ×ª×¨×’×•× + ×“×™×‘×•×¨ â†’ ××—×–×™×¨ ×”×•×“×¢×” ×§×•×œ×™×ª!
â€¢ transcribe_audio - ×ª××œ×•×œ ××•×“×™×• ×œ×˜×§×¡×˜ (STT) â†’ ××¦×•×˜×˜ ×”×§×œ×˜×”

ğŸ¨ ×™×¦×™×¨×”:
â€¢ create_image - ×ª××•× ×•×ª (gemini/openai/grok)
â€¢ create_video - ×•×™×“××• (veo3/sora/kling)
â€¢ image_to_video - ×ª××•× ×”â†’×•×™×“××• ××•× ×¤×©
â€¢ create_music - ×©×™×¨×™×/××•×–×™×§×” (Suno)
â€¢ text_to_speech - ×˜×§×¡×˜â†’×“×™×‘×•×¨ (22 ×©×¤×•×ª)

ğŸ” × ×™×ª×•×—:
â€¢ analyze_image_from_history - × ×™×ª×•×— ×ª××•× ×•×ª
â€¢ analyze_video - × ×™×ª×•×— ×•×™×“××•

âœï¸ ×¢×¨×™×›×”:
â€¢ edit_image - ×¢×¨×™×›×ª ×ª××•× ×•×ª (openai/gemini)
â€¢ edit_video - ×¢×¨×™×›×ª ×•×™×“××• (runway)

ğŸ¤ ××•×“×™×• ××ª×§×“×:
â€¢ voice_clone_and_speak - ×©×™×‘×•×˜ ×§×•×œ + ×“×™×‘×•×¨
â€¢ creative_audio_mix - ××™×§×¡ ×™×¦×™×¨×ª×™ ×¢× ××¤×§×˜×™×

ğŸ‘¥ WhatsApp:
â€¢ create_poll - ×™×¦×™×¨×ª ×¡×§×¨×™×
â€¢ send_location - ××™×§×•× ××§×¨××™ (×ª×•××š ×‘××–×•×¨×™×: ×¢×¨×™×, ××“×™× ×•×ª, ×™×‘×©×•×ª!)
â€¢ create_group - ×™×¦×™×¨×ª ×§×‘×•×¦×•×ª (××•×¨×©×™× ×‘×œ×‘×“)

ğŸ¯ Meta-Tools:
â€¢ history_aware_create - ×™×¦×™×¨×” + ×”×™×¡×˜×•×¨×™×”
â€¢ create_with_memory - ×™×¦×™×¨×” + ×”×¢×“×¤×•×ª
â€¢ search_and_create - ×—×™×¤×•×© + ×™×¦×™×¨×”
â€¢ create_and_analyze - ×™×¦×™×¨×” + × ×™×ª×•×—
â€¢ analyze_and_edit - × ×™×ª×•×— + ×¢×¨×™×›×”
â€¢ smart_execute_with_fallback - fallback ×—×›×
â€¢ retry_with_different_provider - × ×™×¡×™×•×Ÿ ×—×•×–×¨

ğŸ”„ Retry:
â€¢ retry_last_command - ×—×–×•×¨ ×¢×œ ×¤×§×•×“×” ×§×•×“××ª (×¢× ××¤×©×¨×•×ª ×œ×©× ×•×ª ×¡×¤×§)

ğŸ’¡ ×›×œ×œ×™× ×§×¨×™×˜×™×™×:

ğŸ“œ **××ª×™ ×œ×’×©×ª ×œ×”×™×¡×˜×•×¨×™×” (×—×•×‘×”!):**
â€¢ "××” ×××¨×ª×™ ×§×•×“×" / "×¢×œ ××” ×“×™×‘×¨× ×•" â†’ get_chat_history
â€¢ "×œ×¤×™ ×”×ª××•× ×” ×©×”×¢×œ×™×ª×™" / "×›××• ×‘×”×•×“×¢×” ×”×§×•×“××ª" â†’ get_chat_history
â€¢ "×‘×”××©×š ×œ×©×™×—×”" / "×›×¤×™ ×©×›×ª×‘×ª×™" â†’ get_chat_history
â€¢ ×›×œ ×©××œ×” ×©×“×•×¨×©×ª context ×§×•×“× â†’ **×ª××™×“** ×§×¨× get_chat_history ×ª×—×™×œ×”!

ğŸ’¾ **××ª×™ ×œ×©××•×¨ ×”×¢×“×¤×•×ª:**
â€¢ "×ª××™×“ ×¦×•×¨ ×¢× X" / "×× ×™ ××¢×“×™×£ Y" â†’ save_user_preference
â€¢ "×–×›×•×¨ ×©..." / "×‘×¤×¢× ×”×‘××”" â†’ save_user_preference
â€¢ "×× ×™ ×œ× ××•×”×‘ X" / "×× ×™ ××•×”×‘ Y" â†’ save_user_preference

ğŸ—£ï¸ **××ª×™ ×œ×”×©×ª××© ×‘-translate_and_speak (CRITICAL!):**
â€¢ "×××•×¨ X ×‘×™×¤× ×™×ª" / "×××•×¨ X ×‘-Y" â†’ translate_and_speak (×œ× translate_text!)
â€¢ "×ª×¨×’× ×œ-X ×•×××•×¨" / "×§×¨× ×‘×™×¤× ×™×ª" â†’ translate_and_speak
â€¢ "×”×§×¨× ××ª ×–×” ×‘×¢×¨×‘×™×ª" / "say in English" â†’ translate_and_speak
â€¢ **×× ×”××©×ª××© ××•××¨ "×××•×¨" ×¢× ×©×¤×” - ×–×” ×ª××™×“ ×”×•×“×¢×” ×§×•×œ×™×ª!**
â€¢ **translate_text ××—×–×™×¨ ×¨×§ ×˜×§×¡×˜. translate_and_speak ××—×–×™×¨ ××•×“×™×•.**
â€¢ **××œ ×ª×¤×¦×œ translate_and_speak ×œ-translate_text + text_to_speech!** ×–×” ×›×œ×™ ××—×“ ×©×¢×•×©×” ×”×›×œ.

ğŸ” **××ª×™ ×œ×”×©×ª××© ×‘-retry ×•×‘-fallback:**
â€¢ "× ×¡×” ×©×•×‘" / "×©×•×‘" / "×¢×•×“ ×¤×¢×" â†’ retry_last_command
â€¢ "×¢× OpenAI" / "×¢× Gemini" â†’ retry_last_command (×¢× provider_override)
â€¢ "××‘×œ ×¢× X" / "×ª×§×Ÿ ×œ-Y" â†’ retry_last_command (×¢× modifications)
â€¢ **×× create_video × ×›×©×œ ×¢× Kling** â†’ retry_with_different_provider (task_type: 'video', avoid_provider: 'kling')
â€¢ **×× create_image × ×›×©×œ** â†’ retry_with_different_provider ××• smart_execute_with_fallback
â€¢ **×¡×“×¨ fallback ×œ×•×™×“××•: Kling â†’ Veo3 â†’ Sora2** (××œ ×ª×©×ª××© ×‘-Gemini ×œ×•×™×“××•!)

ğŸ§  **×¤×§×•×“×” ××—×¨×•× ×” ×–××™× ×” ×¢×‘×•×¨×š:**
â€¢ ×‘×›×œ ×¤× ×™×™×” ×—×“×©×” ××•×¦×’×ª "[×¤×§×•×“×” ×§×•×“××ª]" ×¢× ×”×¤×¨×˜×™× ×”×§×¨×™×˜×™×™× (×¤×¨×•××¤×˜, ×ª×¨×’×•×, ×¡×¤×§, ×ª×•×¦××•×ª).
â€¢ ×”×©×ª××© ×‘×–×” ×›×“×™ ×œ×¢× ×•×ª ×˜×‘×¢×™ ×œ×”××©×š ×©×™×—×” ("×•×¢×›×©×™×• ×‘×§×•×œ", "×”×¤×¢× ×‘×ª××•× ×”", "×¢× ×¡×¤×§ ××—×¨").
â€¢ ×‘×§×©×•×ª ×›××• "×ª×’×™×“ ××ª ×–×” ×‘×§×•×œ", "×•×¢×›×©×™×• ×‘×§×•×œ", "×ª×©××™×¢ ×œ×™" â†’ × ×¦×œ ××ª ×”××™×“×¢ ×”×§×•×“× ×•×”×¤×¢×œ translate_and_speak ××• text_to_speech ×‘×”×ª××.
â€¢ ××œ ×ª×©××•×¨ retry_last_command ×›×¤×§×•×“×” ×”××—×¨×•× ×” â€“ ×”×¤×§×•×“×” ×”××§×•×¨×™×ª × ×©××¨×ª ××•×˜×•××˜×™×ª.

ğŸ¯ **×‘×—×™×¨×ª ×¡×¤×§ (CRITICAL!):**
â€¢ **×ª××™×“** ×¦×™×™×Ÿ provider ×›×©×§×•×¨× ×œ-create_image/create_video/edit_image/edit_video!
â€¢ ×× ×”××©×ª××© ×œ× ×¦×™×™×Ÿ ×¡×¤×§ - ×ª×‘×—×¨ ×‘×¢×¦××š:
  - ×ª××•× ×•×ª: provider='gemini' (×‘×¨×™×¨×ª ××—×“×œ)
  - ×•×™×“××•: provider='kling' (×‘×¨×™×¨×ª ××—×“×œ)
  - ×¢×¨×™×›×ª ×ª××•× ×•×ª: provider='openai' (×‘×¨×™×¨×ª ××—×“×œ)
â€¢ ×“×•×’×××•×ª:
  âœ… create_image({prompt: "×—×ª×•×œ", provider: "gemini"})
  âœ… create_video({prompt: "× ×—×©×•×œ", provider: "kling"})
  âŒ create_image({prompt: "×—×ª×•×œ"}) â† ×—×¡×¨ provider!

âš™ï¸ **×›×œ×œ×™× ×›×œ×œ×™×™×:**
â€¢ ×ª×©×™×‘ ×‘×¢×‘×¨×™×ª, ×˜×‘×¢×™ ×•× ×¢×™×
â€¢ ×‘×©××œ×•×ª ××•×¨×›×‘×•×ª - ×¤×¦×œ ×œ××¡×¤×¨ ×©×œ×‘×™× ×§×˜× ×™×

ğŸš¨ **×˜×™×¤×•×œ ×‘×©×’×™××•×ª (CRITICAL!):**
â€¢ ×× tool × ×›×©×œ - **××œ ×ª×§×¨× ×œ××•×ª×• tool ×©×•×‘ ×‘×©×•× ××§×¨×”!**
â€¢ **××œ ×ª×¤×¦×œ tool ×›×•×©×œ ×œ××¡×¤×¨ tools ××—×¨×™×!** (×œ××©×œ: ×× translate_and_speak × ×›×©×œ â†’ ××¡×•×¨ translate_text + text_to_speech)
â€¢ **×‘××§×•× ×œ×§×¨×•× ×©×•×‘ ×œ-tool ×”×›×•×©×œ, ×¢×©×” ×›×š:**
  âœ… ×× ×–×• ×‘×¢×™×™×ª ×¡×¤×§ (create_image/create_video/edit_image × ×›×©×œ):
     â†’ ×”×©×ª××© ×‘-retry_with_different_provider(original_tool_name, new_provider, args)
  âœ… ×× ×–×• ×‘×¢×™×” ×›×œ×œ×™×ª ××• ××ª×” ×œ× ×‘×˜×•×—:
     â†’ ×”×©×ª××© ×‘-smart_execute_with_fallback(original_tool_name, args, failed_providers)
â€¢ **×“×•×’××” ×œ× × ×›×•× ×”:**
  âŒ create_image({prompt: "...", provider: "gemini"}) × ×›×©×œ
  âŒ [×§×•×¨× ×©×•×‘] create_image({prompt: "...", provider: "openai"})
â€¢ **×“×•×’××” × ×›×•× ×”:**
  âœ… create_image({prompt: "...", provider: "gemini"}) × ×›×©×œ
  âœ… [×§×•×¨×] retry_with_different_provider({original_tool_name: "create_image", new_provider: "openai", args: {...}})
â€¢ **×¡×¤×¨ ×ª××™×“ ×œ××©×ª××© ××” ×”×©×’×™××”** ×œ×¤× ×™ ×©××ª×” ×× ×¡×” fallback!
â€¢ ×“×•×’××”: "âŒ Gemini × ×›×©×œ: [×”×©×’×™××”]." â† ×ª××™×“ ×©×œ×— ××ª ×–×” ×œ××©×ª××©!
â€¢ **××œ ×ª×¡×ª×™×¨ ×©×’×™××•×ª** - ×”××©×ª××© ×¦×¨×™×š ×œ×“×¢×ª ××” ×§×¨×”!
â€¢ ×× ×›×œ ×”× ×™×¡×™×•× ×•×ª × ×›×©×œ×• - ×”×¡×‘×¨ ×œ××©×ª××© ××” × ×™×¡×™×ª ×•×œ××” ×–×” ×œ× ×¢×‘×“`;


  // ğŸ§  Context for tool execution (load previous context if enabled)
  let context = {
    chatId,
    previousToolResults: {},
    toolCalls: [],
    generatedAssets: {
      images: [],
      videos: [],
      audio: [],
      polls: []
    },
    lastCommand: options.lastCommand || null,
    originalInput: options.input || null,
    suppressFinalResponse: false,
    expectedMediaType: null
  };
  
  // Load previous context if context memory is enabled (from DB)
  if (agentConfig.contextMemoryEnabled) {
    const previousContext = await conversationManager.getAgentContext(chatId);
    if (previousContext) {
      console.log(`ğŸ§  [Agent Context] Loaded previous context from DB with ${previousContext.toolCalls.length} tool calls`);
      context = {
        ...context,
        toolCalls: previousContext.toolCalls || [],
        generatedAssets: previousContext.generatedAssets || context.generatedAssets
      };
    } else {
      console.log(`ğŸ§  [Agent Context] No previous context found in DB (starting fresh)`);
    }
  }
  
  // Conversation history for the agent
  const chat = model.startChat({
    history: [],
    tools: [{ functionDeclarations }]
  });
  
  // â±ï¸ Wrap entire agent execution with timeout
  const agentExecution = async () => {
    // Include system instruction in the first message
    const fullPrompt = `${systemInstruction}\n\n---\n\nUser Request: ${prompt}`;
    let response = await chat.sendMessage(fullPrompt);
    let iterationCount = 0;
    
    // Agent loop - continue until we get a final text response
    while (iterationCount < maxIterations) {
    iterationCount++;
    console.log(`ğŸ”„ [Agent] Iteration ${iterationCount}/${maxIterations}`);
    
    const result = response.response;
    
    // Check if Gemini wants to call a function
    const functionCalls = result.functionCalls();
    
    if (!functionCalls || functionCalls.length === 0) {
      // No more function calls - we have a final answer
      let text = result.text();
      
      // ğŸ§¹ CRITICAL: Clean thinking patterns before sending to user!
      text = cleanThinkingPatterns(text);
      
      console.log(`âœ… [Agent] Completed in ${iterationCount} iterations`);
      
      // ğŸ§  Save context for future agent calls if enabled (to DB)
      if (agentConfig.contextMemoryEnabled) {
        await conversationManager.saveAgentContext(chatId, {
          toolCalls: context.toolCalls,
          generatedAssets: context.generatedAssets
        });
        console.log(`ğŸ§  [Agent Context] Saved context to DB with ${context.toolCalls.length} tool calls`);
      }
      
      // ğŸ¨ Extract latest generated media to send to user
      console.log(`ğŸ” [Agent] context.generatedAssets:`, JSON.stringify(context.generatedAssets, null, 2));
      
      const latestImageAsset = context.generatedAssets.images.length > 0 
        ? context.generatedAssets.images[context.generatedAssets.images.length - 1]
        : null;
      const latestVideoAsset = context.generatedAssets.videos.length > 0 
        ? context.generatedAssets.videos[context.generatedAssets.videos.length - 1]
        : null;
      const latestAudioAsset = context.generatedAssets.audio && context.generatedAssets.audio.length > 0 
        ? context.generatedAssets.audio[context.generatedAssets.audio.length - 1]
        : null;
      const latestPollAsset = context.generatedAssets.polls && context.generatedAssets.polls.length > 0 
        ? context.generatedAssets.polls[context.generatedAssets.polls.length - 1]
        : null;
      
      // Check if send_location was called - extract latitude/longitude from tool result
      const locationResult = context.previousToolResults['send_location'];
      const latitude = locationResult?.latitude || null;
      const longitude = locationResult?.longitude || null;
      const locationInfo = locationResult?.locationInfo || locationResult?.data || null;
      
      console.log(`ğŸ” [Agent] Extracted assets - Image: ${latestImageAsset?.url}, Video: ${latestVideoAsset?.url}, Audio: ${latestAudioAsset?.url}, Poll: ${latestPollAsset?.question}, Location: ${latitude}, ${longitude}`);
      
      const finalText = context.suppressFinalResponse ? '' : text;
      
      return {
        success: true,
        text: finalText,
        imageUrl: latestImageAsset?.url || null,
        imageCaption: latestImageAsset?.caption || '',
        videoUrl: latestVideoAsset?.url || null,
        audioUrl: latestAudioAsset?.url || null,
        poll: latestPollAsset || null,
        latitude: latitude,
        longitude: longitude,
        locationInfo: locationInfo,
        toolsUsed: Object.keys(context.previousToolResults),
        iterations: iterationCount,
        toolCalls: context.toolCalls,
        toolResults: context.previousToolResults
      };
    }
    
    // Execute function calls (in parallel for better performance)
    console.log(`ğŸ”§ [Agent] Executing ${functionCalls.length} function call(s)`);
    
    // ğŸ“¢ Send Ack message to user before executing tools (includes provider info)
    await sendToolAckMessage(chatId, functionCalls);
    
    // Execute all tools in parallel (they're independent)
    const toolPromises = functionCalls.map(async (call) => {
      const toolName = call.name;
      const toolArgs = call.args;
      
      console.log(`   â†’ Calling tool: ${toolName} with args:`, toolArgs);
      
      const tool = agentTools[toolName];
      if (!tool) {
        console.error(`âŒ Unknown tool: ${toolName}`);
        return {
          functionResponse: {
            name: toolName,
            response: {
              success: false,
              error: `Unknown tool: ${toolName}`
            }
          }
        };
      }
      
      try {
        // Execute the tool
        const toolResult = await tool.execute(toolArgs, context);
        
        // DEBUG: Log what the tool returned
        console.log(`ğŸ” [Agent] ${toolName} returned:`, JSON.stringify(toolResult, null, 2));
        
        // Save result for future tool calls
        context.previousToolResults[toolName] = toolResult;
        
        // Immediately surface raw errors to the user (as-is), even if fallback will follow
        if (toolResult && toolResult.error && context.chatId) {
          try {
            const { greenApiService } = getServices();
            const errorMessage = toolResult.error.startsWith('âŒ')
              ? toolResult.error
              : `âŒ ${toolResult.error}`;
            await greenApiService.sendTextMessage(context.chatId, errorMessage);
          } catch (notifyError) {
            console.error(`âŒ Failed to notify user about error: ${notifyError.message}`);
          }
        }
        
        if (toolResult && toolResult.suppressFinalResponse) {
          context.suppressFinalResponse = true;
        }
        
        // ğŸ§  Track tool call for context memory
        context.toolCalls.push({
          tool: toolName,
          args: toolArgs,
          success: toolResult.success !== false,
          timestamp: Date.now()
        });
        
        // ğŸ§  Track generated assets for context memory
        if (toolResult.imageUrl) {
          console.log(`âœ… [Agent] Tracking image: ${toolResult.imageUrl}, caption: ${toolResult.caption || '(none)'}`);
          context.generatedAssets.images.push({
            url: toolResult.imageUrl,
            caption: toolResult.caption || '',
            prompt: toolArgs.prompt,
            provider: toolResult.provider || toolArgs.provider,
            timestamp: Date.now()
          });
        } else {
          console.log(`âš ï¸ [Agent] No imageUrl in toolResult for ${toolName}`);
        }
        if (toolResult.videoUrl) {
          context.generatedAssets.videos.push({
            url: toolResult.videoUrl,
            prompt: toolArgs.prompt,
            timestamp: Date.now()
          });
        }
        if (toolResult.audioUrl) {
          if (!context.generatedAssets.audio) context.generatedAssets.audio = [];
          context.generatedAssets.audio.push({
            url: toolResult.audioUrl,
            prompt: toolArgs.prompt || toolArgs.text_to_speak || toolArgs.text,
            timestamp: Date.now()
          });
        }
        if (toolResult.poll) {
          if (!context.generatedAssets.polls) context.generatedAssets.polls = [];
          context.generatedAssets.polls.push({
            question: toolResult.poll.question,
            options: toolResult.poll.options,
            topic: toolArgs.topic,
            timestamp: Date.now()
          });
        }
        
        return {
          functionResponse: {
            name: toolName,
            response: toolResult
          }
        };
      } catch (error) {
        console.error(`âŒ Error executing tool ${toolName}:`, error);
        
        // ğŸ§  Track failed tool call
        context.toolCalls.push({
          tool: toolName,
          args: toolArgs,
          success: false,
          error: error.message,
          timestamp: Date.now()
        });
        
        return {
          functionResponse: {
            name: toolName,
            response: {
              success: false,
              error: `Tool execution failed: ${error.message}`
            }
          }
        };
      }
    });
    
    // Wait for all tools to complete
    const functionResponses = await Promise.all(toolPromises);
    
    // Send function responses back to Gemini
    response = await chat.sendMessage(functionResponses);
  }
  
    // Max iterations reached
    console.warn(`âš ï¸ [Agent] Max iterations (${maxIterations}) reached`);
    return {
      success: false,
      error: '×”×’×¢×ª×™ ×œ××¡×¤×¨ ×”××§×¡×™××œ×™ ×©×œ × ×™×¡×™×•× ×•×ª. × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×¨×ª.',
      toolsUsed: Object.keys(context.previousToolResults),
      iterations: iterationCount,
      toolCalls: context.toolCalls,
      toolResults: context.previousToolResults
    };
  };
  
  // â±ï¸ Execute agent with timeout
  const timeoutPromise = new Promise((_, reject) => 
    setTimeout(() => reject(new Error('Agent timeout')), agentConfig.timeoutMs)
  );
  
  try {
    return await Promise.race([agentExecution(), timeoutPromise]);
  } catch (error) {
    if (error.message === 'Agent timeout') {
      console.error(`â±ï¸ [Agent] Timeout after ${agentConfig.timeoutMs}ms`);
      return {
        success: false,
        error: `â±ï¸ ×”×¤×¢×•×œ×” ××¨×›×” ×™×•×ª×¨ ××“×™. × ×¡×” ×‘×§×©×” ×¤×©×•×˜×” ×™×•×ª×¨ ××• × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.`,
        toolsUsed: Object.keys(context.previousToolResults),
        timeout: true,
        toolCalls: context.toolCalls,
        toolResults: context.previousToolResults
      };
    }
    throw error;
  }
}

/**
 * Check if a query should use the agent (vs regular routing)
 * @param {string} prompt - User's prompt
 * @param {Object} input - Normalized input
 * @returns {boolean} - True if should use agent
 */
function shouldUseAgent(prompt, input) {
  // Use agent for:
  // â€¢ Chat history/previous messages
  // â€¢ Multi-step requests (create + analyze)
  // â€¢ Conditional fallback ("if fails, try X")
  // â€¢ Complex retry requests
  
  const agentPatterns = [
    // History (Hebrew + English)
    /××”\s+(×××¨×ª×™|×××¨×ª|×›×ª×‘×ª×™|×›×ª×‘×ª|×©×œ×—×ª×™|×©×œ×—×ª|×“×™×‘×¨×ª×™|×“×™×‘×¨×ª)|×¢×œ\s+××”\s+(×“×™×‘×¨× ×•|×¢×¡×§× ×•|×©×•×—×—× ×•)|(××™×œ×•|××™×–×”|××”|×›××”)\s+(×ª××•× ×•×ª|×•×™×“××•|×”×•×“×¢×•×ª)\s+(×”×™×•|× ×©×œ×—×•|×›××Ÿ|×¤×”)?|(×ª×¨××”|×”×¨××”)\s+(×œ×™)?\s+××”\s+(×©×œ×—×ª×™|×”×™×”)|××”\s+(×”×™×”|×§×¨×”|×¢×‘×¨)\s+(×›××Ÿ|×¤×”|×‘×©×™×—×”)/i,
    /(×‘|×|×¢×œ)(×”)?(×ª××•× ×”|×•×™×“××•|×”×§×œ×˜×”|×”×•×“×¢×”|×©×™×—×”)\s+(×”××—×¨×•× ×”|×”×§×•×“××ª|××§×•×“×)/i,
    /what\s+(did\s+)?(I|we|you)\s+(say|write|mention|talk|discuss)|what\s+(images?|videos?|messages?)\s+(were|was)?\s+(sent|shared|here)?|(show|display)\s+me\s+what\s+(I|we|you)\s+(sent|shared)|about\s+the\s+(image|video|audio|message|conversation)|in\s+the\s+(previous|last|recent)\s+(message|conversation)/i,
    
    // Multi-step (Hebrew + English)
    // âš ï¸ IMPORTANT: Exclude simple "×¦×•×¨" verbs without multi-step indicators (e.g., "×¦×•×¨ ×¡×§×¨" alone)
    // Only match patterns with explicit multi-step indicators: "×•" (and), "××" (if), "×•××–" (then)
    // This prevents single "×¦×•×¨ X" commands from being caught by this pattern
    /(×¦×•×¨|× ×ª×—|×—×¤×©).+(×•|××|×•××–).+(× ×ª×—|×‘×“×•×§|×¢×¨×•×š|×©×¤×¨|×ª×Ÿ|×¦×•×¨|×¡×¤×¨)/i,
    /create.+(and|then).+(analyze|check|edit|improve)|analyze.+(and|then).+(edit|improve|enhance)|search.+(and|then).+(summarize|create|tell)/i,
    
    // Conditional fallback (Hebrew + English)
    /(××|×•?××).+(× ×›×©×œ|×œ×\s+×¢×‘×“|×œ×\s+×”×¦×œ×™×—).+(× ×¡×”|×¦×•×¨).+(×¢×|×‘)\s+(OpenAI|Gemini|Grok)|(××|if).+(×œ×|not).+(× ×¡×”|try).+(××—×¨|different|other)/i,
    /(if|and\s+if|when).+(fails?|doesn'?t\s+work|error|not\s+good).+(try|create|use).+(with|using|another|different|other)\s*(OpenAI|Gemini|Grok)?/i,
    
    // Smart retry (Hebrew + English)
    /(×–×”|×”\w+)\s+(×œ×\s+)?(×¢×‘×“|×¢×•×‘×“|×”×¦×œ×™×—|×™×•×¦×|×™×¦×)\s+(×›××•\s+×©×¦×¨×™×š|×˜×•×‘|× ×›×•×Ÿ)?|(× ×¡×”|×ª× ×¡×”)\s+(×©×•×‘|×¢×•×“ ×¤×¢×)\s+(×¢×|×‘|××‘×œ|×¨×§).+|(×¤×©×˜|×ª×¤×©×˜)\s+(××ª\s+)?(×–×”|×”×¤×¨×•××¤×˜|×”×‘×§×©×”)/i,
    /(this|it)\s+(didn'?t|doesn'?t)\s+(work|come\s+out|turn\s+out)|try\s+(again|once\s+more)\s+(with|but|using).+|(simplify|make\s+it\s+simpler)|too\s+(complex|complicated|detailed)/i
  ];
  
  for (const pattern of agentPatterns) {
    if (pattern.test(prompt)) {
      console.log(`ğŸ¤– [Agent] Detected agent-suitable query, will use agent`);
      return true;
    }
  }
  
  return false;
}

module.exports = {
  executeAgentQuery,
  shouldUseAgent
};

